{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Luna SDK Docs Welcome to Luna SDK Documentation Site.","title":"Home"},{"location":"#luna-sdk-docs","text":"Welcome to Luna SDK Documentation Site.","title":"Luna SDK Docs"},{"location":"license/","text":"License Luna SDK is licensed under the zlib/libpng license. Here is a copy of the full text of the license: Copyright (c) 2018-2023 Jixiang Zhou (JXMaster) The software is supplied \"as is\", without warranty of any kind, express or implied, including, without limitation, the warranties of merchantability, fitness for a particular purpose, title, and non-infringement. In no event shall the Copyright owners, or anyone distributing the software, be liable for any damages or other liability, whether in contract, tort or otherwise, arising from, out of, or in connection with the software, or the use or other dealings in the software, even if advised of the possibility of such damage. Permission is hereby granted to use, copy, modify, and distribute this software, or portions hereof, for any purpose, without fee, subject to the following restrictions: The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated, but is not required. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. This Copyright notice may not be removed or altered from any source or altered source distribution.","title":"License"},{"location":"license/#license","text":"Luna SDK is licensed under the zlib/libpng license. Here is a copy of the full text of the license: Copyright (c) 2018-2023 Jixiang Zhou (JXMaster) The software is supplied \"as is\", without warranty of any kind, express or implied, including, without limitation, the warranties of merchantability, fitness for a particular purpose, title, and non-infringement. In no event shall the Copyright owners, or anyone distributing the software, be liable for any damages or other liability, whether in contract, tort or otherwise, arising from, out of, or in connection with the software, or the use or other dealings in the software, even if advised of the possibility of such damage. Permission is hereby granted to use, copy, modify, and distribute this software, or portions hereof, for any purpose, without fee, subject to the following restrictions: The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated, but is not required. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. This Copyright notice may not be removed or altered from any source or altered source distribution.","title":"License"},{"location":"manual/basics/","text":"Basics This chapter describes basic concepts and features that the user should understand in order to use Luna SDK correctly and efficiently. All feathers described in this chapter are provided by the Runtime module of Luna SDK, which is the base module of Luna SDK and is included by all other modules implicitly.","title":"Basics"},{"location":"manual/basics/#basics","text":"This chapter describes basic concepts and features that the user should understand in order to use Luna SDK correctly and efficiently. All feathers described in this chapter are provided by the Runtime module of Luna SDK, which is the base module of Luna SDK and is included by all other modules implicitly.","title":"Basics"},{"location":"manual/basics/assertions/","text":"Assertions #include <Luna/Runtime/Assertions.hpp> Assertions are used to detect programming mistakes (or \"bugs\") when developing complex systems and modules. Unlike error handling that is used for run-time errors, assertions are used for errors that should never happen on correctly behaved systems and are expected to interrupt the program immediately when such error occurs, so the developer can get into the code to check the error quickly when an debugger is attached to the process. After the application is fully tested, all assertions should be disabled to increase performance. In Luna SDK, we separate programming mistakes to internal programming mistakes and external programming mistakes, and use different macros to handle them. Prefer assertions to throwing error codes when possible, since it simplifies the implementation, reduces the runtime cost and makes the error obvious. Use error codes only when the error cannot be completely solved during the development period. Assertions for internal programming mistakes Internal programming mistakes are mistakes caused by incorrectly implementing functions. Such mistakes should never happen if the function is correctly used by the user. luassert can be used to handle such internal programming mistakes. luassert firstly evaluates the value of the given expression, if the evaluated value is 0 , it calls assert_fail to report one error message then interrupts the program. luassert_msg is similar to luassert , but it allows the user to specify the message reported by assert_fail . lupanic is equal to luassert(false) , it interrupts the program immediately when being executed. The user can use lupanic to mark one position in the code that should never be reached in normal condition. lupanic_msg is similar to lupanic , but it allows the user to specify the message reported by assert_fail . All those four assertion macros take effect only in debug version of the program or library (controlled by LUNA_DEBUG macro, which is configured by xmake). If you want these macros to work in profile and release builds, use macros with _always suffix, like luassert_always , lupanic_always , luassert_msg_always and lupanic_msg_always . Assertions for external programming mistakes External programming mistakes are mistakes caused by programmers who use the function. Most functions have constraints on arguments and calling time, calling such functions with bad arguments (like out-of-range index) or at improper time (using one service before it is initialized) will result in undefined behavior that is hard to debug. Unlike internal programming mistakes, these mistakes are caused by programmers who uses the function, thus is impossible to be solved when implementing the function. For such case, lucheck and lucheck_msg can be used to check external programming mistakes. lucheck and lucheck_msg behave the same as luassert and luassert_msg . However, these two macros are not controlled by LUNA_DEBUG , but another macro called LUNA_ENABLE_CONTRACT_ASSERTION , which can be enabled by specifying contract_assertion when building the module with xmake. The module developer can place lucheck and lucheck_msg at the beginning of the function implementation to validate function arguments and calling time, and interrupts the program if the function is improperly called. With these macros, the developer of the module may ship two versions of libraries to the user, one for developing with the module, and another for releasing with the final product. The development version of the module can be compiled on release mode with contract_assertion switched on, so all luassert assertions get removed, but lucheck assertions are retained for the user, while the release version of the module will remove both luassert and lucheck for maximum performance.","title":"Assertions"},{"location":"manual/basics/assertions/#assertions","text":"#include <Luna/Runtime/Assertions.hpp> Assertions are used to detect programming mistakes (or \"bugs\") when developing complex systems and modules. Unlike error handling that is used for run-time errors, assertions are used for errors that should never happen on correctly behaved systems and are expected to interrupt the program immediately when such error occurs, so the developer can get into the code to check the error quickly when an debugger is attached to the process. After the application is fully tested, all assertions should be disabled to increase performance. In Luna SDK, we separate programming mistakes to internal programming mistakes and external programming mistakes, and use different macros to handle them. Prefer assertions to throwing error codes when possible, since it simplifies the implementation, reduces the runtime cost and makes the error obvious. Use error codes only when the error cannot be completely solved during the development period.","title":"Assertions"},{"location":"manual/basics/assertions/#assertions-for-internal-programming-mistakes","text":"Internal programming mistakes are mistakes caused by incorrectly implementing functions. Such mistakes should never happen if the function is correctly used by the user. luassert can be used to handle such internal programming mistakes. luassert firstly evaluates the value of the given expression, if the evaluated value is 0 , it calls assert_fail to report one error message then interrupts the program. luassert_msg is similar to luassert , but it allows the user to specify the message reported by assert_fail . lupanic is equal to luassert(false) , it interrupts the program immediately when being executed. The user can use lupanic to mark one position in the code that should never be reached in normal condition. lupanic_msg is similar to lupanic , but it allows the user to specify the message reported by assert_fail . All those four assertion macros take effect only in debug version of the program or library (controlled by LUNA_DEBUG macro, which is configured by xmake). If you want these macros to work in profile and release builds, use macros with _always suffix, like luassert_always , lupanic_always , luassert_msg_always and lupanic_msg_always .","title":"Assertions for internal programming mistakes"},{"location":"manual/basics/assertions/#assertions-for-external-programming-mistakes","text":"External programming mistakes are mistakes caused by programmers who use the function. Most functions have constraints on arguments and calling time, calling such functions with bad arguments (like out-of-range index) or at improper time (using one service before it is initialized) will result in undefined behavior that is hard to debug. Unlike internal programming mistakes, these mistakes are caused by programmers who uses the function, thus is impossible to be solved when implementing the function. For such case, lucheck and lucheck_msg can be used to check external programming mistakes. lucheck and lucheck_msg behave the same as luassert and luassert_msg . However, these two macros are not controlled by LUNA_DEBUG , but another macro called LUNA_ENABLE_CONTRACT_ASSERTION , which can be enabled by specifying contract_assertion when building the module with xmake. The module developer can place lucheck and lucheck_msg at the beginning of the function implementation to validate function arguments and calling time, and interrupts the program if the function is improperly called. With these macros, the developer of the module may ship two versions of libraries to the user, one for developing with the module, and another for releasing with the final product. The development version of the module can be compiled on release mode with contract_assertion switched on, so all luassert assertions get removed, but lucheck assertions are retained for the user, while the release version of the module will remove both luassert and lucheck for maximum performance.","title":"Assertions for external programming mistakes"},{"location":"manual/basics/basic_types/","text":"Basic Types Primitive types The following table lists all primitive typed designed by Luna SDK. Type Description C++ STD Equivalent u8 Unsigned 8-bit integer. std::uint8_t i8 Signed 8-bit integer. std::int8_t u16 Unsigned 16-bit integer. std::uint16_t i16 Signed 16-bit integer. std::int16_t u32 Unsigned 32-bit integer. std::uint32_t i32 Signed 32-bit integer. std::int32_t u64 Unsigned 64-bit integer. std::uint64_t i64 Signed 64-bit integer. std::int64_t usize Unsigned machine-sized integer. std::size_t isize Signed machine-sized integer. std::ptrdiff_t f32 32-bit floating-point number. float f64 64-bit floating-point number. double c8 8-bit character. char c16 16-bit character. chat16_t c32 32-bit character. char32_t Aliasing types of primitive types byte_t is an aliasing type of u8 that indicates one byte. You should use byte_t instead of u8 if you want to be clear that you are talking about bytes, not numbers, for example, in a binary stream ( byte_t* ). opaque_t is an aliasing type of void* that indicated one opaque pointer that should not be dereferenced by the user. Such pointers are usually used as handles to internal data structures, the user should pass opaque_t to functions provided by the system to manipulate it. InitializerList<T> is an aliasing type of std::initializer_list<_Ty> in Luna SDK. VarList is an aliasing type of va_list in Luna SDK. Containers #include <Luna/Runtime/Vector.hpp> #include <Luna/Runtime/List.hpp> #include <Luna/Runtime/HashMap.hpp> #include <Luna/Runtime/HashSet.hpp> #include <Luna/Runtime/UnorderedMap.hpp> #include <Luna/Runtime/UnorderedSet.hpp> #include <Luna/Runtime/UnorderedMultiMap.hpp> #include <Luna/Runtime/UnorderedMultiSet.hpp> #include <Luna/Runtime/SelfIndexedHashMap.hpp> #include <Luna/Runtime/SelfIndexedUnorderedMap.hpp> #include <Luna/Runtime/SelfIndexedUnorderedMultiMap.hpp> #include <Luna/Runtime/RingDeque.hpp> For compatibility and cross-platform consistency reasons, Luna SDK does not use C++ Standard Template Library (STD), but implements its own container types using APIs similar to those of STD. The following table lists all containers provided by Luna SDK. Container Type Description C++ STD Equivalent Vector<T> Dynamic array type. std::vector<T> List<T> Dynamic double-linked list type. std::list<T> HashMap<K, V> Closed hash map type using Robinhood Hashing. N/A HashSet<V> Closed hash set type using Robinhood Hashing. N/A UnorderedMap<K, V> Open hash map type. std::unordered_map<K, V> UnorderedSet<V> Open hash set type. std::unordered_set<V> UnorderedMultiMap<K, V> Open hash map type that allows elements with the same key. std::unordered_multimap<K, V> UnorderedMultiSet<V> Open hash map type that allows multiple insertions of the same elements. std::unordered_multiset<K, V> SelfIndexedHashMap<K, V, E> Closed hash map whose key type can be extracted from the value type. N/A SelfIndexedUnorderedMap<K, V, E> Open hash map whose key type can be extracted from the value type. N/A SelfIndexedUnorderedMultiMap<K, V, E> Open hash map whose key type can be extracted from the value type, and allows multiple insertions of the same elements. N/A RingDeque<T> Double-ended queue using ring buffering. std::deque<T> Self indexed map containers Self indexed map containers are used for elements whose key is a part of the value object. For example, given the following structure: struct Player { Name name; i32 hp; i32 mp; }; Now we want to use one map to store all player records using their name as the key. If we use normal HashMap or UnorderedMap container, every entry in the container will be saved as Pair<const Name, Player> , thus stores the player name twice. In such case, we can use SelfIndexedHashMap and SelfIndexedUnorderedMap instead. The self indexed hash map container does not store the key object directly, instead, it requires the user to provide a special functional object E , which will be called when the key is needed. The functional object E takes a reference to the value object of the map element, and should returns a value or reference to the key object of the element. In our example, we can implement E as below: struct PlayerExtractKey { const Name& operator()(const Player& val) const { return val.name; } }; Then we can define the self indexed map like so: #include <Luna/Runtime/SelfIndexedHashMap.hpp> namespace Luna { SelfIndexedHashMap<Name, Player, PlayerExtractKey> players; } When using self indexed map containers, the user must ensure that the key object is immutable for all elements in the container, or the behavior is undefined. BLOB #include <Luna/Runtime/Blob.hpp> BLOB refers to Binary Large OBject, which is a memory block with arbitrary data. In Luna SDK, we use Blob structure to represent one BLOB object. Blob can be used in many ways, but the common use for it is to store and transfer binary data. For example, load_file_data function returns a Blob object, which contains the data of the file. Span #include <Luna/Runtime/Span.hpp> Span is a template type that refers to one continuous sequence of instances. There are two types of spans in Luna SDK: fixed span and variable span. Fixed spans are spans whose size is decided at compile time, and cannot be changed. Such span only requires one pointer to the object range to be well defined, and the number of elements in the span should be declared as part of the type: i32 data[] = {3, 4, 5, 6, 7}; Span<i32, 3> range(data + 1); debug_printf(\"%d\", range.size()); // 3 for (i32 i : range) debug_printf(\"%d, \", i); // 4, 5, 6, range = Span<i32, 3>(data + 2); debug_printf(\"%d\", range.size()); // 3 for (i32 i : range) debug_printf(\"%d, \", i); // 5, 6, 7, Variable spans are spans whose size may change at run time. Such span requires both the pointer to the object range and the size of the range to be well defined: i32 data[] = {3, 4, 5, 6, 7}; Span<i32> range(data + 1), 3; debug_printf(\"%d\", range.size()); // 3 for (i32 i : range) debug_printf(\"%d, \", i); // 4, 5, 6, range = Span<i32>(data + 2, 2); debug_printf(\"%d\", range.size()); // 2 for (i32 i : range) debug_printf(\"%d, \", i); // 5, 6, Note that spans are NOT containers, they don't allocate memory to store the data, only stores pointers to the objects provided by the user. So use spans only when the original object sequence is valid. Prefer using Span<T> instead of C-style pointer and size pair when referring memory ranges. GUID #include <Luna/Runtime/Base.hpp> Globally Unique Identifier (GUID) is a algorithm-generated 128-bit integer identifier. In Luna SDK, GUIDs are represented by Guid type: struct Guid { u64 high; u64 low; }; Luna SDK supports generating GUID instances from the registry form ( xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx or {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx} ) at compile time: constexpr Guid test_id(\"{5cf28858-60b0-49f2-9674-5888fa7ad027}\"); static_assert(test_id.low == 10841387548328775719Ui64, \"Incorrect GUID values.\"); static_assert(test_id.high == 6697565509014014450Ui64, \"Incorrect GUID values.\"); GUIDs are used widely in Luna SDK for identifying assets, types, interfaces, objects and many other entities. Version type #include <Luna/Runtime/Base.hpp> Version represent the version of one application, module or any version-controlled entity. Every version is composed by three numbers: major , minor and patch : struct Version { u32 major; u32 minor; u32 patch; }; We suggest using the following rules to manage the version number: An increment of major version indicates a breaking change to the interface of the entity, so that existing codes, programs and services using the entity must be explicitly modified to use the newer version of the entity correctly. An increment of minor version indicates a non-breaking change to the interface of the entity, so that existing codes, programs and services can use the newer version of the entity correctly without any source-level modification. An increment of patch version indicates a internal change of the entity and should not affect the entity interface, so that existing codes, programs and services can use the newer version of the entity correctly without any source-level modification. Pair and tuple types #include <Luna/Runtime/Base.hpp> // For Pair. #include <Luna/Runtime/Tuple.hpp> // For Tuple. Pair<T1, T2> encapsulates one pair of elements with T1 and T2 type as the first and second element of the pair. Pair is mainly used by map containers to represent elements. Tuple<Tys...> is a generalization of Pair and may contain one or multiple elements. Elements in Tuple can be fetched by calling get<N>(tuple) function. This type is mainly used to store function arguments in functional programming. Path #include <Luna/Runtime/Path.hpp> Path is one kind of string that describes the location of one node in a hierarchical-based node tree, given that each node in the tree can be identified by a name string. One common use of Path is to represent the location of one file or directory in the file system. Path is represented by a root name (like C: ), plus a Vector of Name that stores nodes of the path. One path can be absolute or relative, which is identified by PathFlag::absolute . One relative path can be calculated by two paths, it can also be appended to another path to create a new path. Path can be created form one string, it can also be encoded to one string using the user-specified path separator.","title":"Basic Types"},{"location":"manual/basics/basic_types/#basic-types","text":"","title":"Basic Types"},{"location":"manual/basics/basic_types/#primitive-types","text":"The following table lists all primitive typed designed by Luna SDK. Type Description C++ STD Equivalent u8 Unsigned 8-bit integer. std::uint8_t i8 Signed 8-bit integer. std::int8_t u16 Unsigned 16-bit integer. std::uint16_t i16 Signed 16-bit integer. std::int16_t u32 Unsigned 32-bit integer. std::uint32_t i32 Signed 32-bit integer. std::int32_t u64 Unsigned 64-bit integer. std::uint64_t i64 Signed 64-bit integer. std::int64_t usize Unsigned machine-sized integer. std::size_t isize Signed machine-sized integer. std::ptrdiff_t f32 32-bit floating-point number. float f64 64-bit floating-point number. double c8 8-bit character. char c16 16-bit character. chat16_t c32 32-bit character. char32_t","title":"Primitive types"},{"location":"manual/basics/basic_types/#aliasing-types-of-primitive-types","text":"byte_t is an aliasing type of u8 that indicates one byte. You should use byte_t instead of u8 if you want to be clear that you are talking about bytes, not numbers, for example, in a binary stream ( byte_t* ). opaque_t is an aliasing type of void* that indicated one opaque pointer that should not be dereferenced by the user. Such pointers are usually used as handles to internal data structures, the user should pass opaque_t to functions provided by the system to manipulate it. InitializerList<T> is an aliasing type of std::initializer_list<_Ty> in Luna SDK. VarList is an aliasing type of va_list in Luna SDK.","title":"Aliasing types of primitive types"},{"location":"manual/basics/basic_types/#containers","text":"#include <Luna/Runtime/Vector.hpp> #include <Luna/Runtime/List.hpp> #include <Luna/Runtime/HashMap.hpp> #include <Luna/Runtime/HashSet.hpp> #include <Luna/Runtime/UnorderedMap.hpp> #include <Luna/Runtime/UnorderedSet.hpp> #include <Luna/Runtime/UnorderedMultiMap.hpp> #include <Luna/Runtime/UnorderedMultiSet.hpp> #include <Luna/Runtime/SelfIndexedHashMap.hpp> #include <Luna/Runtime/SelfIndexedUnorderedMap.hpp> #include <Luna/Runtime/SelfIndexedUnorderedMultiMap.hpp> #include <Luna/Runtime/RingDeque.hpp> For compatibility and cross-platform consistency reasons, Luna SDK does not use C++ Standard Template Library (STD), but implements its own container types using APIs similar to those of STD. The following table lists all containers provided by Luna SDK. Container Type Description C++ STD Equivalent Vector<T> Dynamic array type. std::vector<T> List<T> Dynamic double-linked list type. std::list<T> HashMap<K, V> Closed hash map type using Robinhood Hashing. N/A HashSet<V> Closed hash set type using Robinhood Hashing. N/A UnorderedMap<K, V> Open hash map type. std::unordered_map<K, V> UnorderedSet<V> Open hash set type. std::unordered_set<V> UnorderedMultiMap<K, V> Open hash map type that allows elements with the same key. std::unordered_multimap<K, V> UnorderedMultiSet<V> Open hash map type that allows multiple insertions of the same elements. std::unordered_multiset<K, V> SelfIndexedHashMap<K, V, E> Closed hash map whose key type can be extracted from the value type. N/A SelfIndexedUnorderedMap<K, V, E> Open hash map whose key type can be extracted from the value type. N/A SelfIndexedUnorderedMultiMap<K, V, E> Open hash map whose key type can be extracted from the value type, and allows multiple insertions of the same elements. N/A RingDeque<T> Double-ended queue using ring buffering. std::deque<T>","title":"Containers"},{"location":"manual/basics/basic_types/#self-indexed-map-containers","text":"Self indexed map containers are used for elements whose key is a part of the value object. For example, given the following structure: struct Player { Name name; i32 hp; i32 mp; }; Now we want to use one map to store all player records using their name as the key. If we use normal HashMap or UnorderedMap container, every entry in the container will be saved as Pair<const Name, Player> , thus stores the player name twice. In such case, we can use SelfIndexedHashMap and SelfIndexedUnorderedMap instead. The self indexed hash map container does not store the key object directly, instead, it requires the user to provide a special functional object E , which will be called when the key is needed. The functional object E takes a reference to the value object of the map element, and should returns a value or reference to the key object of the element. In our example, we can implement E as below: struct PlayerExtractKey { const Name& operator()(const Player& val) const { return val.name; } }; Then we can define the self indexed map like so: #include <Luna/Runtime/SelfIndexedHashMap.hpp> namespace Luna { SelfIndexedHashMap<Name, Player, PlayerExtractKey> players; } When using self indexed map containers, the user must ensure that the key object is immutable for all elements in the container, or the behavior is undefined.","title":"Self indexed map containers"},{"location":"manual/basics/basic_types/#blob","text":"#include <Luna/Runtime/Blob.hpp> BLOB refers to Binary Large OBject, which is a memory block with arbitrary data. In Luna SDK, we use Blob structure to represent one BLOB object. Blob can be used in many ways, but the common use for it is to store and transfer binary data. For example, load_file_data function returns a Blob object, which contains the data of the file.","title":"BLOB"},{"location":"manual/basics/basic_types/#span","text":"#include <Luna/Runtime/Span.hpp> Span is a template type that refers to one continuous sequence of instances. There are two types of spans in Luna SDK: fixed span and variable span. Fixed spans are spans whose size is decided at compile time, and cannot be changed. Such span only requires one pointer to the object range to be well defined, and the number of elements in the span should be declared as part of the type: i32 data[] = {3, 4, 5, 6, 7}; Span<i32, 3> range(data + 1); debug_printf(\"%d\", range.size()); // 3 for (i32 i : range) debug_printf(\"%d, \", i); // 4, 5, 6, range = Span<i32, 3>(data + 2); debug_printf(\"%d\", range.size()); // 3 for (i32 i : range) debug_printf(\"%d, \", i); // 5, 6, 7, Variable spans are spans whose size may change at run time. Such span requires both the pointer to the object range and the size of the range to be well defined: i32 data[] = {3, 4, 5, 6, 7}; Span<i32> range(data + 1), 3; debug_printf(\"%d\", range.size()); // 3 for (i32 i : range) debug_printf(\"%d, \", i); // 4, 5, 6, range = Span<i32>(data + 2, 2); debug_printf(\"%d\", range.size()); // 2 for (i32 i : range) debug_printf(\"%d, \", i); // 5, 6, Note that spans are NOT containers, they don't allocate memory to store the data, only stores pointers to the objects provided by the user. So use spans only when the original object sequence is valid. Prefer using Span<T> instead of C-style pointer and size pair when referring memory ranges.","title":"Span"},{"location":"manual/basics/basic_types/#guid","text":"#include <Luna/Runtime/Base.hpp> Globally Unique Identifier (GUID) is a algorithm-generated 128-bit integer identifier. In Luna SDK, GUIDs are represented by Guid type: struct Guid { u64 high; u64 low; }; Luna SDK supports generating GUID instances from the registry form ( xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx or {xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx} ) at compile time: constexpr Guid test_id(\"{5cf28858-60b0-49f2-9674-5888fa7ad027}\"); static_assert(test_id.low == 10841387548328775719Ui64, \"Incorrect GUID values.\"); static_assert(test_id.high == 6697565509014014450Ui64, \"Incorrect GUID values.\"); GUIDs are used widely in Luna SDK for identifying assets, types, interfaces, objects and many other entities.","title":"GUID"},{"location":"manual/basics/basic_types/#version-type","text":"#include <Luna/Runtime/Base.hpp> Version represent the version of one application, module or any version-controlled entity. Every version is composed by three numbers: major , minor and patch : struct Version { u32 major; u32 minor; u32 patch; }; We suggest using the following rules to manage the version number: An increment of major version indicates a breaking change to the interface of the entity, so that existing codes, programs and services using the entity must be explicitly modified to use the newer version of the entity correctly. An increment of minor version indicates a non-breaking change to the interface of the entity, so that existing codes, programs and services can use the newer version of the entity correctly without any source-level modification. An increment of patch version indicates a internal change of the entity and should not affect the entity interface, so that existing codes, programs and services can use the newer version of the entity correctly without any source-level modification.","title":"Version type"},{"location":"manual/basics/basic_types/#pair-and-tuple-types","text":"#include <Luna/Runtime/Base.hpp> // For Pair. #include <Luna/Runtime/Tuple.hpp> // For Tuple. Pair<T1, T2> encapsulates one pair of elements with T1 and T2 type as the first and second element of the pair. Pair is mainly used by map containers to represent elements. Tuple<Tys...> is a generalization of Pair and may contain one or multiple elements. Elements in Tuple can be fetched by calling get<N>(tuple) function. This type is mainly used to store function arguments in functional programming.","title":"Pair and tuple types"},{"location":"manual/basics/basic_types/#path","text":"#include <Luna/Runtime/Path.hpp> Path is one kind of string that describes the location of one node in a hierarchical-based node tree, given that each node in the tree can be identified by a name string. One common use of Path is to represent the location of one file or directory in the file system. Path is represented by a root name (like C: ), plus a Vector of Name that stores nodes of the path. One path can be absolute or relative, which is identified by PathFlag::absolute . One relative path can be calculated by two paths, it can also be appended to another path to create a new path. Path can be created form one string, it can also be encoded to one string using the user-specified path separator.","title":"Path"},{"location":"manual/basics/boxed_objects/","text":"Boxed objects Boxed objects are dynamic allocated objects managed by Luna SDK, so that they have the following features: The lifetime of boxed objects are managed by reference-counting. Real-time type identification (RTTI) can be used to check the type of boxed objects, and can be used to perform dynamic type casting safely. Boxed objects can implement interfaces . To implement such features, every boxed object will have one Object Header allocated along with the object data, and is used to record the object metadata like type and reference counter. Boxed objects should also be property referred using smart pointers ( Ref<T> for typed boxed object and ObjRef for type-less boxed object) so that their reference counter can be properly maintained. Registering boxed type #include <Luna/Runtime/Object.hpp> One type must be registered to the type system to be used for creating boxed objects. If you want to register one type solely for creating boxed objects, you may use register_boxed_type instead of calling register_struct_type directly. Managing boxed object manually #include <Luna/Runtime/Object.hpp> Use object_alloc to allocate one boxed object. This call will allocate memory for the boxed object and the object header, initialize the object header, and returns one pointer to the allocated boxed object as object_t , which is an aliasing type of void* . The return pointer can be reinterpreted to the pointer of the required type directly, and it should be passed to all other boxed object management APIs. The object returned by object_alloc is not initialized, the user should then call constructors of the specified type manually to construct the object. Boxed objects implement both strong reference counting and weak reference counting. Use object_retain , object_release to increase and decrease the strong reference counter, and object_retain_weak , object_release_weak to increase and decrease the weak reference counter. One object will have 1 strong reference and 0 weak reference when allocated. If the strong reference counter value drops to 0 , the destructor of the object will be called. If the weak reference counter is not 0 when the object is being destructed, the object will be marked as expired , you can call object_expired to check whether one object is expired. One expired object cannot be used, the only valid operation for it is to release its weak references. The memory for one boxed object will be freed if both the strong and weak reference counter values drop to 0 . Managing boxed object automatically #include <Luna/Runtime/Ref.hpp> In most of the time, you don't need to manage boxed object manually. You can use new_object to create one boxed object directly like memnew , this function allocates one boxed object, and initializes it using user-provided arguments. new_object returns one Ref<T> smart pointer, which represents one strong reference to the object. There are four smart pointers provided by Luna SDK: Ref<T> for strong references to typed boxed objects. ObjRef for strong references to type-less boxed objects, which can refer to any boxed object. WeakRef<T> for weak references to typed boxed objects. WeakObjRef for weak references to type-less boxed objects. All smart pointers decrease the reference counter value automatically when being destructed, so the user does not need to handle this manually. Coping one smart pointer object only increase the reference counter value of the object, the object itself is not copied. You can create one weak reference smart pointer object by casting from one strong reference smart pointer directly, but you should call pin on one weak reference smart pointer to fetch one strong reference smart pointer from it, which will return nullptr if failed. The weak smart pointer will be reset to nullptr automatically when the object is expired and the user calls get on the smart pointer. Run-time type identification and dynamic casting #include <Luna/Runtime/Object.hpp> Luna SDK uses object_t to represent one type-less pointer to one boxed object. It is not safe to cast one typeinfo_t to one concrete typed pointer without checking whether the object type conforms to the pointer type specified. Luna SDK provides run-time type identification (RTTI) for all boxed objects to perform type casting safely at run time. Use get_object_type on object_t to fetch the real type of the object. This function returns one typeinfo_t directly, so it is suitable if you want to inspect the type to perform some special operations. Use object_is_type to check whether the given object conforms to the specified type, that is, either the object is the specified type, or the object is one type that derives from the specified type. Use this function if you want to perform dynamic casting safely like dynamic_cast (which cannot be used in Luna SDK). Any typed pointer to one boxed object can be casted to object_t without any run-time cost.","title":"Boxed Objects"},{"location":"manual/basics/boxed_objects/#boxed-objects","text":"Boxed objects are dynamic allocated objects managed by Luna SDK, so that they have the following features: The lifetime of boxed objects are managed by reference-counting. Real-time type identification (RTTI) can be used to check the type of boxed objects, and can be used to perform dynamic type casting safely. Boxed objects can implement interfaces . To implement such features, every boxed object will have one Object Header allocated along with the object data, and is used to record the object metadata like type and reference counter. Boxed objects should also be property referred using smart pointers ( Ref<T> for typed boxed object and ObjRef for type-less boxed object) so that their reference counter can be properly maintained.","title":"Boxed objects"},{"location":"manual/basics/boxed_objects/#registering-boxed-type","text":"#include <Luna/Runtime/Object.hpp> One type must be registered to the type system to be used for creating boxed objects. If you want to register one type solely for creating boxed objects, you may use register_boxed_type instead of calling register_struct_type directly.","title":"Registering boxed type"},{"location":"manual/basics/boxed_objects/#managing-boxed-object-manually","text":"#include <Luna/Runtime/Object.hpp> Use object_alloc to allocate one boxed object. This call will allocate memory for the boxed object and the object header, initialize the object header, and returns one pointer to the allocated boxed object as object_t , which is an aliasing type of void* . The return pointer can be reinterpreted to the pointer of the required type directly, and it should be passed to all other boxed object management APIs. The object returned by object_alloc is not initialized, the user should then call constructors of the specified type manually to construct the object. Boxed objects implement both strong reference counting and weak reference counting. Use object_retain , object_release to increase and decrease the strong reference counter, and object_retain_weak , object_release_weak to increase and decrease the weak reference counter. One object will have 1 strong reference and 0 weak reference when allocated. If the strong reference counter value drops to 0 , the destructor of the object will be called. If the weak reference counter is not 0 when the object is being destructed, the object will be marked as expired , you can call object_expired to check whether one object is expired. One expired object cannot be used, the only valid operation for it is to release its weak references. The memory for one boxed object will be freed if both the strong and weak reference counter values drop to 0 .","title":"Managing boxed object manually"},{"location":"manual/basics/boxed_objects/#managing-boxed-object-automatically","text":"#include <Luna/Runtime/Ref.hpp> In most of the time, you don't need to manage boxed object manually. You can use new_object to create one boxed object directly like memnew , this function allocates one boxed object, and initializes it using user-provided arguments. new_object returns one Ref<T> smart pointer, which represents one strong reference to the object. There are four smart pointers provided by Luna SDK: Ref<T> for strong references to typed boxed objects. ObjRef for strong references to type-less boxed objects, which can refer to any boxed object. WeakRef<T> for weak references to typed boxed objects. WeakObjRef for weak references to type-less boxed objects. All smart pointers decrease the reference counter value automatically when being destructed, so the user does not need to handle this manually. Coping one smart pointer object only increase the reference counter value of the object, the object itself is not copied. You can create one weak reference smart pointer object by casting from one strong reference smart pointer directly, but you should call pin on one weak reference smart pointer to fetch one strong reference smart pointer from it, which will return nullptr if failed. The weak smart pointer will be reset to nullptr automatically when the object is expired and the user calls get on the smart pointer.","title":"Managing boxed object automatically"},{"location":"manual/basics/boxed_objects/#run-time-type-identification-and-dynamic-casting","text":"#include <Luna/Runtime/Object.hpp> Luna SDK uses object_t to represent one type-less pointer to one boxed object. It is not safe to cast one typeinfo_t to one concrete typed pointer without checking whether the object type conforms to the pointer type specified. Luna SDK provides run-time type identification (RTTI) for all boxed objects to perform type casting safely at run time. Use get_object_type on object_t to fetch the real type of the object. This function returns one typeinfo_t directly, so it is suitable if you want to inspect the type to perform some special operations. Use object_is_type to check whether the given object conforms to the specified type, that is, either the object is the specified type, or the object is one type that derives from the specified type. Use this function if you want to perform dynamic casting safely like dynamic_cast (which cannot be used in Luna SDK). Any typed pointer to one boxed object can be casted to object_t without any run-time cost.","title":"Run-time type identification and dynamic casting"},{"location":"manual/basics/coding_convention/","text":"Coding Convention This section discusses the coding conventions used in Luna SDK. All users using Luna SDK should follow these conventions to achieve a consistent code style and prevent programming errors. Disabled C++ features The following C++ features are disabled in Luna SDK: Exceptions ( try , throw , catch ). Real-time type identification (RTTI, dynamic_cast and typeid for objects). The use of typeid for static types is allowed. In rare cases, if you have to use these features (like integrating one third-party library that uses these features), make sure these features are used internally in your module, and not cross the module interface, or they may not be handled correctly. The noexcept decorator is not used in Luna SDK, since exceptions are disabled by default. File naming conventions Use .hpp file extension name for C++ header files, use .cpp file extension name for C++ source files, use .inl file extension name for inlined C++ source files. Use Pascal case for file and folder names, like FileIterator.hpp . Do not add interface prefix I to the filename. Add the following comments at the beginning of every C++ header, source or inlined source file if you want to contribute it as part of Luna SDK. /*! * This file is a portion of Luna SDK. * For conditions of distribution and use, see the disclaimer * and license in LICENSE.txt * * @file {The filename of this file} * @author {Author name} * @date {The file creation date, YYYY/MM/DD} */ Lexical formats Indents One indent can be represented by one tab character or four whitespace characters. Both forms are allowed. Scopes In most cases, scope opening and closing brackets should occupy a whole line. Nested scopes should be properly indented. namesapce A { namespace B { class C { }; } } However, if the scope is empty or contains simple statements, you may write the opening and coding brackets without beginning a new line: class A { i32 n; public: A() {} // Empty scope. i32 get_n() { return n; } // Simple scope. } Always use the form that maximizes the readability when deciding scoping forms. Documenting comments Use doxygen comment blocks for documenting comments (comments that exists in the header file as the documentation of function, type or object). //! Resets the task context and begins a new task. //! @param[in] world The world to run the task on. //! @param[in] exec_mode The task execution mode. //! @param[in] read_components If task mode is `shared`, specify components that will be read by this task. //! @param[in] write_components If task mode is `shared`, specify components that will be read and written by //! this task. //! @remark This call may block the current thread until all components required by this task can be safely //! accessed by this task, or until all other tasks are finished if this is a exclusive task. virtual void begin( IWorld* world, TaskExecutionMode exec_mode, Span<typeinfo_t> read_components, Span<typeinfo_t> write_components ) = 0; Naming conventions Primitive types Primitive types (numbers, characters, pointers) and the aliasing primitive types are named using the underscore case: u8 i32 usize For all user-defined aliasing types of primitive types, uses _t suffix: using opaque_t = void* Enumeration types Use enum classs instead of enum for all enumerations. All enumeration types are named using the Pascal case. Options of the enumeration are named using the underscore case. enum class ResourceType : u8 { buffer, texture_1d, texture_2d, texture_3d }; If the enumeration represents a single-value type, the use of Type or Kind suffix is suggested, but not required; if the enumeration represents a bit-OR-combined multi-value type, the use of Flag suffix is suggested, but not required. For all multi-value enumeration types, always provides one option none with the value 0 . Using hexadecimal form to represent multi-value enumeration option values is suggested, but not required. enum class ResourceUsageFlag : u32 { none = 0x00, shader_resource = 0x01, constant_buffer = 0x02, unordered_access = 0x04, render_target = 0x08, depth_stencil = 0x10, vertex_buffer = 0x20, index_buffer = 0x40, stream_output = 0x80, indirect_buffer = 0x100, }; Structure and class types Types defined by struct and class are considered the same in Luna SDK, we use \"structure type\" to refer both. Most structure types are named using the Pascal case. struct ResourceDesc { ResourceType type; ResourceHeapType heap_type; Format pixel_format; ResourceUsageFlag usages; u64 width_or_buffer_size; u32 height; u32 depth_or_array_size; u32 mip_levels; u32 sample_count; u32 sample_quality; ResourceFlag flags; }; The only exception is the structure type that: contains only one primitive typed member object. can be trivially constructed, destructed, copied and moved. can be constructed by providing one value with the same type of its member variable, and the behavior is assigning its member object with the provided value. In such case, we consider the structure type as a aliasing type of the primitive type, thus use the underscore case with _t suffix for the type: struct asset_t { opaque_t handle; asset_t() : handle(nullptr) {} constexpr asset_t(opaque_t handle) : handle(handle) {} constexpr bool operator==(const asset_t& rhs) const { return handle == rhs.handle; } constexpr bool operator!=(const asset_t& rhs) const { return handle != rhs.handle; } operator bool() const { return handle != nullptr; } }; Note that using the Pascal case for such structure type is also allowed. Interface structure types If the structure type represents an interface, append I prefix to the structure type name. struct IStream : virtual Interface { luiid(\"{0345f636-ca5c-4b4d-8416-29834377d239}\"); virtual RV read(void* buffer, usize size, usize* read_bytes = nullptr) = 0; virtual RV write(const void* buffer, usize size, usize* write_bytes = nullptr) = 0; }; Functions All functions, including member functions of structure types, are named using the underscore case. Function parameters are also named using the underscore case. RV read_file(opaque_t file, void* buffer, usize size, usize* read_bytes = nullptr); For functions with long parameter lists, you can separate parameter lists into multiple lines, providing the parameter list line is correctly indented. void draw_shape(u32 begin_command, u32 num_commands, const Float2U& min_position, const Float2U& max_position, const Float2U& min_shapecoord, const Float2U& max_shapecoord, u32 color = 0xFFFFFFFF, const Float2U& min_texcoord = Float2U(0.0f), const Float2U& max_texcoord = Float2U(0.0f)); These rules are also applied to member functions. Objects All objects except global constants are named using the underscore case, including member object of structure types. Float2U origin_point; For member objects of structure types that are not exposed as part of module interface, the prefix m_ is suggested, but not required. struct ComponentBuffer { typeinfo_t m_type; void* m_data = nullptr; usize m_size = 0; usize m_capacity = 0; }; For global variables that are not exposed as part of module interface, the prefix g_ is suggested, but not required. Ref<IFontFile> g_default_font; Global constants are named using uppercase words separated by underscores, and is decorated by constexpr . constexpr f32 PI = 3.141592654f; constexpr entity_id_t NULL_ENTITY(0); Prevent defining global constants using macros. Namespace All namespaces are named using the Pascal case. namespace Luna { namespace RHI { } } All Luna SDK components are defined in Luna namespace, every Luna SDK module except Runtime should have its own namespace under Luna containing its own components. Macros Macros can be declared using two forms. The first form is uppercase words separated by underscores, with LUNA_ prefix. These macros are usually used for conditional compiling and replacing some platform-dependent keywords. #define LUNA_DEBUG 1 #define LUNA_PROFILE 1 #define LUNA_RELEASE 1 #if defined(LUNA_COMPILER_MSVC) #define LUNA_DLL_EXPORT __declspec(dllexport) #else #define LUNA_DLL_EXPORT __attribute__ ((visibility(\"default\"))) #endif The second form is the underscore case with lu prefix. These macros are usually used to replace some code patterns to improve coding efficiency. #define luassert(_condition) //... #define luassert_msg(_condition, _message) //... #define lustruct(_name, _guid) //... #define luproperty(_struct, _type, _name) //... #define luenum(_type, _name, _guid) //... #define luoption(_enum, _item) //... #define lucatchret //... Macro parameters are allowed for both macro forms. Macro parameter names should be prefixed with one underscore character. Templates Template type parameters should be decorated with typename instead of class , and should be prefixed with one underscore character. template <typename _Ty> struct less { constexpr bool operator()(const _Ty& lhs, const _Ty& rhs) const { return lhs < rhs; } };","title":"Coding Convention"},{"location":"manual/basics/coding_convention/#coding-convention","text":"This section discusses the coding conventions used in Luna SDK. All users using Luna SDK should follow these conventions to achieve a consistent code style and prevent programming errors.","title":"Coding Convention"},{"location":"manual/basics/coding_convention/#disabled-c-features","text":"The following C++ features are disabled in Luna SDK: Exceptions ( try , throw , catch ). Real-time type identification (RTTI, dynamic_cast and typeid for objects). The use of typeid for static types is allowed. In rare cases, if you have to use these features (like integrating one third-party library that uses these features), make sure these features are used internally in your module, and not cross the module interface, or they may not be handled correctly. The noexcept decorator is not used in Luna SDK, since exceptions are disabled by default.","title":"Disabled C++ features"},{"location":"manual/basics/coding_convention/#file-naming-conventions","text":"Use .hpp file extension name for C++ header files, use .cpp file extension name for C++ source files, use .inl file extension name for inlined C++ source files. Use Pascal case for file and folder names, like FileIterator.hpp . Do not add interface prefix I to the filename. Add the following comments at the beginning of every C++ header, source or inlined source file if you want to contribute it as part of Luna SDK. /*! * This file is a portion of Luna SDK. * For conditions of distribution and use, see the disclaimer * and license in LICENSE.txt * * @file {The filename of this file} * @author {Author name} * @date {The file creation date, YYYY/MM/DD} */","title":"File naming conventions"},{"location":"manual/basics/coding_convention/#lexical-formats","text":"","title":"Lexical formats"},{"location":"manual/basics/coding_convention/#indents","text":"One indent can be represented by one tab character or four whitespace characters. Both forms are allowed.","title":"Indents"},{"location":"manual/basics/coding_convention/#scopes","text":"In most cases, scope opening and closing brackets should occupy a whole line. Nested scopes should be properly indented. namesapce A { namespace B { class C { }; } } However, if the scope is empty or contains simple statements, you may write the opening and coding brackets without beginning a new line: class A { i32 n; public: A() {} // Empty scope. i32 get_n() { return n; } // Simple scope. } Always use the form that maximizes the readability when deciding scoping forms.","title":"Scopes"},{"location":"manual/basics/coding_convention/#documenting-comments","text":"Use doxygen comment blocks for documenting comments (comments that exists in the header file as the documentation of function, type or object). //! Resets the task context and begins a new task. //! @param[in] world The world to run the task on. //! @param[in] exec_mode The task execution mode. //! @param[in] read_components If task mode is `shared`, specify components that will be read by this task. //! @param[in] write_components If task mode is `shared`, specify components that will be read and written by //! this task. //! @remark This call may block the current thread until all components required by this task can be safely //! accessed by this task, or until all other tasks are finished if this is a exclusive task. virtual void begin( IWorld* world, TaskExecutionMode exec_mode, Span<typeinfo_t> read_components, Span<typeinfo_t> write_components ) = 0;","title":"Documenting comments"},{"location":"manual/basics/coding_convention/#naming-conventions","text":"","title":"Naming conventions"},{"location":"manual/basics/coding_convention/#primitive-types","text":"Primitive types (numbers, characters, pointers) and the aliasing primitive types are named using the underscore case: u8 i32 usize For all user-defined aliasing types of primitive types, uses _t suffix: using opaque_t = void*","title":"Primitive types"},{"location":"manual/basics/coding_convention/#enumeration-types","text":"Use enum classs instead of enum for all enumerations. All enumeration types are named using the Pascal case. Options of the enumeration are named using the underscore case. enum class ResourceType : u8 { buffer, texture_1d, texture_2d, texture_3d }; If the enumeration represents a single-value type, the use of Type or Kind suffix is suggested, but not required; if the enumeration represents a bit-OR-combined multi-value type, the use of Flag suffix is suggested, but not required. For all multi-value enumeration types, always provides one option none with the value 0 . Using hexadecimal form to represent multi-value enumeration option values is suggested, but not required. enum class ResourceUsageFlag : u32 { none = 0x00, shader_resource = 0x01, constant_buffer = 0x02, unordered_access = 0x04, render_target = 0x08, depth_stencil = 0x10, vertex_buffer = 0x20, index_buffer = 0x40, stream_output = 0x80, indirect_buffer = 0x100, };","title":"Enumeration types"},{"location":"manual/basics/coding_convention/#structure-and-class-types","text":"Types defined by struct and class are considered the same in Luna SDK, we use \"structure type\" to refer both. Most structure types are named using the Pascal case. struct ResourceDesc { ResourceType type; ResourceHeapType heap_type; Format pixel_format; ResourceUsageFlag usages; u64 width_or_buffer_size; u32 height; u32 depth_or_array_size; u32 mip_levels; u32 sample_count; u32 sample_quality; ResourceFlag flags; }; The only exception is the structure type that: contains only one primitive typed member object. can be trivially constructed, destructed, copied and moved. can be constructed by providing one value with the same type of its member variable, and the behavior is assigning its member object with the provided value. In such case, we consider the structure type as a aliasing type of the primitive type, thus use the underscore case with _t suffix for the type: struct asset_t { opaque_t handle; asset_t() : handle(nullptr) {} constexpr asset_t(opaque_t handle) : handle(handle) {} constexpr bool operator==(const asset_t& rhs) const { return handle == rhs.handle; } constexpr bool operator!=(const asset_t& rhs) const { return handle != rhs.handle; } operator bool() const { return handle != nullptr; } }; Note that using the Pascal case for such structure type is also allowed.","title":"Structure and class types"},{"location":"manual/basics/coding_convention/#interface-structure-types","text":"If the structure type represents an interface, append I prefix to the structure type name. struct IStream : virtual Interface { luiid(\"{0345f636-ca5c-4b4d-8416-29834377d239}\"); virtual RV read(void* buffer, usize size, usize* read_bytes = nullptr) = 0; virtual RV write(const void* buffer, usize size, usize* write_bytes = nullptr) = 0; };","title":"Interface structure types"},{"location":"manual/basics/coding_convention/#functions","text":"All functions, including member functions of structure types, are named using the underscore case. Function parameters are also named using the underscore case. RV read_file(opaque_t file, void* buffer, usize size, usize* read_bytes = nullptr); For functions with long parameter lists, you can separate parameter lists into multiple lines, providing the parameter list line is correctly indented. void draw_shape(u32 begin_command, u32 num_commands, const Float2U& min_position, const Float2U& max_position, const Float2U& min_shapecoord, const Float2U& max_shapecoord, u32 color = 0xFFFFFFFF, const Float2U& min_texcoord = Float2U(0.0f), const Float2U& max_texcoord = Float2U(0.0f)); These rules are also applied to member functions.","title":"Functions"},{"location":"manual/basics/coding_convention/#objects","text":"All objects except global constants are named using the underscore case, including member object of structure types. Float2U origin_point; For member objects of structure types that are not exposed as part of module interface, the prefix m_ is suggested, but not required. struct ComponentBuffer { typeinfo_t m_type; void* m_data = nullptr; usize m_size = 0; usize m_capacity = 0; }; For global variables that are not exposed as part of module interface, the prefix g_ is suggested, but not required. Ref<IFontFile> g_default_font; Global constants are named using uppercase words separated by underscores, and is decorated by constexpr . constexpr f32 PI = 3.141592654f; constexpr entity_id_t NULL_ENTITY(0); Prevent defining global constants using macros.","title":"Objects"},{"location":"manual/basics/coding_convention/#namespace","text":"All namespaces are named using the Pascal case. namespace Luna { namespace RHI { } } All Luna SDK components are defined in Luna namespace, every Luna SDK module except Runtime should have its own namespace under Luna containing its own components.","title":"Namespace"},{"location":"manual/basics/coding_convention/#macros","text":"Macros can be declared using two forms. The first form is uppercase words separated by underscores, with LUNA_ prefix. These macros are usually used for conditional compiling and replacing some platform-dependent keywords. #define LUNA_DEBUG 1 #define LUNA_PROFILE 1 #define LUNA_RELEASE 1 #if defined(LUNA_COMPILER_MSVC) #define LUNA_DLL_EXPORT __declspec(dllexport) #else #define LUNA_DLL_EXPORT __attribute__ ((visibility(\"default\"))) #endif The second form is the underscore case with lu prefix. These macros are usually used to replace some code patterns to improve coding efficiency. #define luassert(_condition) //... #define luassert_msg(_condition, _message) //... #define lustruct(_name, _guid) //... #define luproperty(_struct, _type, _name) //... #define luenum(_type, _name, _guid) //... #define luoption(_enum, _item) //... #define lucatchret //... Macro parameters are allowed for both macro forms. Macro parameter names should be prefixed with one underscore character.","title":"Macros"},{"location":"manual/basics/coding_convention/#templates","text":"Template type parameters should be decorated with typename instead of class , and should be prefixed with one underscore character. template <typename _Ty> struct less { constexpr bool operator()(const _Ty& lhs, const _Ty& rhs) const { return lhs < rhs; } };","title":"Templates"},{"location":"manual/basics/error_handling/","text":"Error Handling Luna SDK does not use the exception mechanism provided by C++. Instead, it adopts a more light-weight error-handling mechanism by returning error codes. Compared to other error-code based solutions, Luna SDK manages error codes and the relationship between error codes, so the user can extend the error handling mechanism easily. Error code #include <Luna/Runtime/Error.hpp> ErrCode represents one error code, which is a machine-sized unsigned integer ( usize ). ErrCode is defined as a dedicated structure type to distinguish from normal return values, the actual error code value can be fetched by code property of ErrCode . We use error code 0 to represent a successful operation (no error), and any non-zero error code value represents one error. The error code value is not defined directly. Instead, the user should call get_error_code_by_name to fetch the error code for one specific error. The error code is generated by the system on the first call to get_error_code_by_name , and is cached and returned directly on succeeding calls to get_error_code_by_name with the same arguments. The error code for the same error will change in different processes, so do not store the error code directly, store its name and category (which will be explained in the following section) instead. Error name and category #include <Luna/Runtime/Error.hpp> Every ErrCode is described by two properties: error name and error category, which is required when calling get_error_code_by_name , and can be fetched by get_error_code_name and get_error_code_category . Error name is a UTF-8 string that briefly describes the error, while error category is used to hold one set of error codes in the same domain. For example, the Runtime module of Luna SDK defines one error category called BasicError , which contains error codes like bad_arguments , out_of_memory , not_supported , etc. The error category is represented by errcat_t , and is identified by one UTF-8 name string. You can get errcat_t from its name by calling get_error_category_by_name , and get the name of one errcat_t by calling get_error_category_name . Error categories can also contain sub-categories, for example, BasicError may contains one IOError sub-category that contains all error codes related to IO errors. In such case, the error category name and sub-category name should both be specified for sub-categories, separated by double colons ( :: ), like BasicError::IOError . You can call get_all_error_codes_of_category to get all error codes of one specific error category, and get_all_error_subcategories_of_category to get all error sub-categories of one specific error category. Declaring error codes Error codes can be declared by specifying error categories as namespaces, and error codes as functions that return the corresponding ErrCode instances. All error categories should be declared directly in Luna namespace. Every error category should have one errtype function that returns the errcat_t instance of the specified error category. namespace Luna { namespace MyError { //! Gets the error category object of `MyError`. LUNA_MYMODULE_API errcat_t errtype(); LUNA_MYMODULE_API ErrCode my_error_1(); LUNA_MYMODULE_API ErrCode my_error_2(); LUNA_MYMODULE_API ErrCode my_error_3(); //... namespace MySubError { //! Gets the error category object of `MySubError`. LUNA_MYMODULE_API errcat_t errtype(); LUNA_MYMODULE_API ErrCode my_error_4(); LUNA_MYMODULE_API ErrCode my_error_5(); //... } } } When implementing such functions, you may use static local variables to prevent fetching the error code every time it is called: namespace Luna { namespace MyError { LUNA_MYMODULE_API errcat_t errtype() { static errcat_t e = get_error_category_by_name(\"MyError\"); return e; } LUNA_MYMODULE_API ErrCode my_error_1(); { static ErrCode e = get_error_code_by_name(\"MyError\", \"my_error_1\"); return e; } //... namespace MySubError { LUNA_MYMODULE_API errcat_t errtype() { static errcat_t e = get_error_category_by_name(\"MyError::MySubError\"); return e; } LUNA_MYMODULE_API ErrCode my_error_4() { static ErrCode e = get_error_code_by_name(\"MyError::MySubError\", \"my_error_4\"); return e; } //... } } } Built-in errors Runtime/Error.hpp contains a list of error codes that covers most common error types, like bad_arguments , bad_platform_call , out_of_memory , not_found , already_exists , etc. All these error codes are declared in BasicError error category, and can be used directly. Besides error codes in BasicError , some built-in modules of Luna SDK declare their own error codes. For example, RHI module declares device_lost in RHIError error category to indicate one graphic device removal error. You can check module documentations and interface files for error codes defined by such modules. Result object #include <Luna/Runtime/Result.hpp> To represent one function that may throw errors, you should wrap the return type of the function with the result object type R<T> , which encapsulates the returned value of the function as well as one error code. The result object can be constructed by passing normal return values (which indicates a successful function call) or error codes (which indicates one error). If the result object is constructed by error, its result object will not be initialized. The following example shows how to declare and implement one function that may throw errors: R<u64> get_file_size(File* file) { u64 size; BOOL succeeded = system_get_file_size(file, &size); if(succeeded) return size; // Return the return value means success. else return BasicError::bad_platform_call(); // Return the error code means failure. } If the return type of the function is R<void> , you can return ok to indicate one successful function call. Note that using ok is allowed only if the function return value is R<void> . You can also use RV to replace of R<void> for convenience. RV reset_file_cursor(File* file) { BOOL succeeded = system_reset_file_cursor(file); if(succeeded) return ok; else return BasicError::bad_platform_call(); } On the caller side, we can use succeeded and failed to test whether one result object represents one valid return value or one error code: auto res = reset_file_cursor(file); if(failed(res)) { // Gets the error code stored in `R<T>`. ErrCode err = res.errcode(); // Handle the error. // ... } Error objects #include <Luna/Runtime/Error.hpp> Error codes indicate only the type of the error, without any further information, which can be inconvenient for the user to indicating the error. For such purpose, Luna SDK provides error objects that extend error codes to provide more detailed information about the error. One error object is represented by Error and contains three members: code : The error code. message : One UTF-8 short description of the error. info : One Variant that may contain any additional error information provided. To return one error object instead of one error code, first set the error object by calling get_error , then returns BasicError::error_object as the returned error code of the function: Error& err = get_error(); err = Error(BasicError::not_found(), \"The specified file %s is not found.\", file_name); return BasicError::error_object(); The error object fetched by get_error is a thread-local object attached to the current thread, so error objects in different threads are independent to each other. If you want to pass error objects between different threads, you can always store one Error instance down and pass it using your own methods. You can also use set_error to simplify the process of creating and returning error objects. The above code can be rewritten by: return set_error(BasicError::not_found(), \"The specified file %s is not found.\", file_name); set_error always returns BasicError::error_object , so we can return it directly. On the caller side, if we find the error code of one function is BasicError::error_object , we should retrieve the real error code by checking the same error object set by the calling function: auto res = do_something(); if(failed(res)) { ErrCode err = res.errcode(); if(err == BasicError::error_object()) { err = get_error().code; } // Handle the error. // ... } We can use unwrap_errcode to simplify this process and retrieve the error code directly like so: auto res = do_something(); if(failed(res)) { ErrCode err = unwrap_errcode(res); // Handle the error. // ... } unwrap_errcode will retrieve the error code from R<T> result object, and if the error code is BasicError::error_object , it will then retrieve the real error code automatically from the error object of this thread. We can also call explain to fetch the message stored on the error object if the error code is BasicError::error_object , or the name of the error code if not: auto res = do_something(); if(failed(res)) { debug_printf(\"%s\", explain(res.errcode())); } Try-catch macros for error handling #include <Luna/Runtime/Result.hpp> Correctly handling functions that may throw errors requires a lot of if statements to judge whether every function call is successful, which takes a lot of effort. In order to ease this, Luna SDK provides macros that can be used to handle throwable functions using a try-catch syntax, much like those in C++. In order to catch error codes returned by throwable function, we firstly need to declare one pair of try-catch blocks using lutry and lucatch like so: lutry { } lucatch { } lutry block is the place where throwable functions are called. In this block, throwable functions are wrapped by luexp , lulet and luset macros: luexp is used if the return type of the function is R<void> . lulet creates a new local variable to hold the return value of the function. luset assigns the return value of the function to one existing variable. The user can also use luthrow to throw one directly. The following code shows the usage of these four macros: lutry { luexp(do_something_that_may_fail()); lulet(size, get_file_size(file)); // Creates one new local variable `size`. luexp(set_file_size(file, 1024)); u64 new_size; luset(new_size, get_file_size(file)); // Assigns to one existing variable `new_size`. if(new_size != 1024) { luthrow(BasicError::bad_platform_call()); // Throw errors directly. } } lucatch { //... } For all these four macros, if the calling function or luthrow throws errors, the execution flow will be interrupted and redirected to lucatch block by a internal goto jump. In lucatch block, the user should handle the error, or just return the error to the caller function. lures macro is used in this block to represent the error code. lucatch { ErrCode code = unwrap_errcode(lures); // To fetch the real error code if lures is `BasicError::error_object`. if(code == BasicError::bad_platform_call()) { // Do something... } else if(code == BasicError::bad_arguments()) { // Do something... } else return lures; // Forward the error to caller function if the error cannot be handled here. } If the user does not want to handle errors at all, she can use lucatchret instead of lucatch block, which will forward all errors caught to the caller function: lutry { //... } lucatchret; // Return all errors caught. In most cases, only one lutry - lucatch pair is needed for one function. If you need multiple lutry - lucatch pairs in the same function, add suffix numbers to macros of succeeding lutry - lucatch pairs after the first pair like so: RV func() { // First pair. lutry { luexp(...); lulet(a, ...); luset(a, ...); luthrow(...); } lucatch { return lures; } // Another pair. lutry2 { luexp2(...); lulet2(a, ...); luset2(a, ...); luthrow2(...); } lucatch2 { return lures2; } // Another pair. lutry3 { luexp3(...); lulet3(a, ...); luset3(a, ...); luthrow3(...); } lucatch3 { return lures3; } }","title":"Error Handling"},{"location":"manual/basics/error_handling/#error-handling","text":"Luna SDK does not use the exception mechanism provided by C++. Instead, it adopts a more light-weight error-handling mechanism by returning error codes. Compared to other error-code based solutions, Luna SDK manages error codes and the relationship between error codes, so the user can extend the error handling mechanism easily.","title":"Error Handling"},{"location":"manual/basics/error_handling/#error-code","text":"#include <Luna/Runtime/Error.hpp> ErrCode represents one error code, which is a machine-sized unsigned integer ( usize ). ErrCode is defined as a dedicated structure type to distinguish from normal return values, the actual error code value can be fetched by code property of ErrCode . We use error code 0 to represent a successful operation (no error), and any non-zero error code value represents one error. The error code value is not defined directly. Instead, the user should call get_error_code_by_name to fetch the error code for one specific error. The error code is generated by the system on the first call to get_error_code_by_name , and is cached and returned directly on succeeding calls to get_error_code_by_name with the same arguments. The error code for the same error will change in different processes, so do not store the error code directly, store its name and category (which will be explained in the following section) instead.","title":"Error code"},{"location":"manual/basics/error_handling/#error-name-and-category","text":"#include <Luna/Runtime/Error.hpp> Every ErrCode is described by two properties: error name and error category, which is required when calling get_error_code_by_name , and can be fetched by get_error_code_name and get_error_code_category . Error name is a UTF-8 string that briefly describes the error, while error category is used to hold one set of error codes in the same domain. For example, the Runtime module of Luna SDK defines one error category called BasicError , which contains error codes like bad_arguments , out_of_memory , not_supported , etc. The error category is represented by errcat_t , and is identified by one UTF-8 name string. You can get errcat_t from its name by calling get_error_category_by_name , and get the name of one errcat_t by calling get_error_category_name . Error categories can also contain sub-categories, for example, BasicError may contains one IOError sub-category that contains all error codes related to IO errors. In such case, the error category name and sub-category name should both be specified for sub-categories, separated by double colons ( :: ), like BasicError::IOError . You can call get_all_error_codes_of_category to get all error codes of one specific error category, and get_all_error_subcategories_of_category to get all error sub-categories of one specific error category.","title":"Error name and category"},{"location":"manual/basics/error_handling/#declaring-error-codes","text":"Error codes can be declared by specifying error categories as namespaces, and error codes as functions that return the corresponding ErrCode instances. All error categories should be declared directly in Luna namespace. Every error category should have one errtype function that returns the errcat_t instance of the specified error category. namespace Luna { namespace MyError { //! Gets the error category object of `MyError`. LUNA_MYMODULE_API errcat_t errtype(); LUNA_MYMODULE_API ErrCode my_error_1(); LUNA_MYMODULE_API ErrCode my_error_2(); LUNA_MYMODULE_API ErrCode my_error_3(); //... namespace MySubError { //! Gets the error category object of `MySubError`. LUNA_MYMODULE_API errcat_t errtype(); LUNA_MYMODULE_API ErrCode my_error_4(); LUNA_MYMODULE_API ErrCode my_error_5(); //... } } } When implementing such functions, you may use static local variables to prevent fetching the error code every time it is called: namespace Luna { namespace MyError { LUNA_MYMODULE_API errcat_t errtype() { static errcat_t e = get_error_category_by_name(\"MyError\"); return e; } LUNA_MYMODULE_API ErrCode my_error_1(); { static ErrCode e = get_error_code_by_name(\"MyError\", \"my_error_1\"); return e; } //... namespace MySubError { LUNA_MYMODULE_API errcat_t errtype() { static errcat_t e = get_error_category_by_name(\"MyError::MySubError\"); return e; } LUNA_MYMODULE_API ErrCode my_error_4() { static ErrCode e = get_error_code_by_name(\"MyError::MySubError\", \"my_error_4\"); return e; } //... } } }","title":"Declaring error codes"},{"location":"manual/basics/error_handling/#built-in-errors","text":"Runtime/Error.hpp contains a list of error codes that covers most common error types, like bad_arguments , bad_platform_call , out_of_memory , not_found , already_exists , etc. All these error codes are declared in BasicError error category, and can be used directly. Besides error codes in BasicError , some built-in modules of Luna SDK declare their own error codes. For example, RHI module declares device_lost in RHIError error category to indicate one graphic device removal error. You can check module documentations and interface files for error codes defined by such modules.","title":"Built-in errors"},{"location":"manual/basics/error_handling/#result-object","text":"#include <Luna/Runtime/Result.hpp> To represent one function that may throw errors, you should wrap the return type of the function with the result object type R<T> , which encapsulates the returned value of the function as well as one error code. The result object can be constructed by passing normal return values (which indicates a successful function call) or error codes (which indicates one error). If the result object is constructed by error, its result object will not be initialized. The following example shows how to declare and implement one function that may throw errors: R<u64> get_file_size(File* file) { u64 size; BOOL succeeded = system_get_file_size(file, &size); if(succeeded) return size; // Return the return value means success. else return BasicError::bad_platform_call(); // Return the error code means failure. } If the return type of the function is R<void> , you can return ok to indicate one successful function call. Note that using ok is allowed only if the function return value is R<void> . You can also use RV to replace of R<void> for convenience. RV reset_file_cursor(File* file) { BOOL succeeded = system_reset_file_cursor(file); if(succeeded) return ok; else return BasicError::bad_platform_call(); } On the caller side, we can use succeeded and failed to test whether one result object represents one valid return value or one error code: auto res = reset_file_cursor(file); if(failed(res)) { // Gets the error code stored in `R<T>`. ErrCode err = res.errcode(); // Handle the error. // ... }","title":"Result object"},{"location":"manual/basics/error_handling/#error-objects","text":"#include <Luna/Runtime/Error.hpp> Error codes indicate only the type of the error, without any further information, which can be inconvenient for the user to indicating the error. For such purpose, Luna SDK provides error objects that extend error codes to provide more detailed information about the error. One error object is represented by Error and contains three members: code : The error code. message : One UTF-8 short description of the error. info : One Variant that may contain any additional error information provided. To return one error object instead of one error code, first set the error object by calling get_error , then returns BasicError::error_object as the returned error code of the function: Error& err = get_error(); err = Error(BasicError::not_found(), \"The specified file %s is not found.\", file_name); return BasicError::error_object(); The error object fetched by get_error is a thread-local object attached to the current thread, so error objects in different threads are independent to each other. If you want to pass error objects between different threads, you can always store one Error instance down and pass it using your own methods. You can also use set_error to simplify the process of creating and returning error objects. The above code can be rewritten by: return set_error(BasicError::not_found(), \"The specified file %s is not found.\", file_name); set_error always returns BasicError::error_object , so we can return it directly. On the caller side, if we find the error code of one function is BasicError::error_object , we should retrieve the real error code by checking the same error object set by the calling function: auto res = do_something(); if(failed(res)) { ErrCode err = res.errcode(); if(err == BasicError::error_object()) { err = get_error().code; } // Handle the error. // ... } We can use unwrap_errcode to simplify this process and retrieve the error code directly like so: auto res = do_something(); if(failed(res)) { ErrCode err = unwrap_errcode(res); // Handle the error. // ... } unwrap_errcode will retrieve the error code from R<T> result object, and if the error code is BasicError::error_object , it will then retrieve the real error code automatically from the error object of this thread. We can also call explain to fetch the message stored on the error object if the error code is BasicError::error_object , or the name of the error code if not: auto res = do_something(); if(failed(res)) { debug_printf(\"%s\", explain(res.errcode())); }","title":"Error objects"},{"location":"manual/basics/error_handling/#try-catch-macros-for-error-handling","text":"#include <Luna/Runtime/Result.hpp> Correctly handling functions that may throw errors requires a lot of if statements to judge whether every function call is successful, which takes a lot of effort. In order to ease this, Luna SDK provides macros that can be used to handle throwable functions using a try-catch syntax, much like those in C++. In order to catch error codes returned by throwable function, we firstly need to declare one pair of try-catch blocks using lutry and lucatch like so: lutry { } lucatch { } lutry block is the place where throwable functions are called. In this block, throwable functions are wrapped by luexp , lulet and luset macros: luexp is used if the return type of the function is R<void> . lulet creates a new local variable to hold the return value of the function. luset assigns the return value of the function to one existing variable. The user can also use luthrow to throw one directly. The following code shows the usage of these four macros: lutry { luexp(do_something_that_may_fail()); lulet(size, get_file_size(file)); // Creates one new local variable `size`. luexp(set_file_size(file, 1024)); u64 new_size; luset(new_size, get_file_size(file)); // Assigns to one existing variable `new_size`. if(new_size != 1024) { luthrow(BasicError::bad_platform_call()); // Throw errors directly. } } lucatch { //... } For all these four macros, if the calling function or luthrow throws errors, the execution flow will be interrupted and redirected to lucatch block by a internal goto jump. In lucatch block, the user should handle the error, or just return the error to the caller function. lures macro is used in this block to represent the error code. lucatch { ErrCode code = unwrap_errcode(lures); // To fetch the real error code if lures is `BasicError::error_object`. if(code == BasicError::bad_platform_call()) { // Do something... } else if(code == BasicError::bad_arguments()) { // Do something... } else return lures; // Forward the error to caller function if the error cannot be handled here. } If the user does not want to handle errors at all, she can use lucatchret instead of lucatch block, which will forward all errors caught to the caller function: lutry { //... } lucatchret; // Return all errors caught. In most cases, only one lutry - lucatch pair is needed for one function. If you need multiple lutry - lucatch pairs in the same function, add suffix numbers to macros of succeeding lutry - lucatch pairs after the first pair like so: RV func() { // First pair. lutry { luexp(...); lulet(a, ...); luset(a, ...); luthrow(...); } lucatch { return lures; } // Another pair. lutry2 { luexp2(...); lulet2(a, ...); luset2(a, ...); luthrow2(...); } lucatch2 { return lures2; } // Another pair. lutry3 { luexp3(...); lulet3(a, ...); luset3(a, ...); luthrow3(...); } lucatch3 { return lures3; } }","title":"Try-catch macros for error handling"},{"location":"manual/basics/file_management/","text":"File Management #include <Luna/Runtime/File.hpp> File IO IFile represents one system-level file handle that can be used to read and write file data. The user can create one IFile interface using open_file , and the file handle will be closed when its reference count drops to 0 . Data in the file can be read by IFile::read , and can be written by IFile::write . The current file cursor for IO operations can be fetched by IFile::tell , and can be set by IFile::seek . The whole size of the file can be fetched by IFile::get_size , and can be set by IFile::set_size . In most cases, file data written by IFile::write will not be written to storage media immediately, but being cached in driver buffer and written back to the storage in next hardware flush. The user can wait such flush by calling IFile::flush , which blocks the current thread until all written data is successfully written back to storage and visible to other processes. If you simply want to load file data after opening one file, you can pass IFile to load_file_data immediately after it is opened, which loads the whole file binary data and returns the data as one Blob object. File operations Use file_attribute to fetch the attribute of one specified file, like its creation time, last modified time, whether it is a directory, etc. Use copy_file and move_file for coping and moving files and directories. Use delete_file for deleting one file or directory. Use open_dir to create a file iterator ( IFileIterator ) that can be used to iterate over files and directories in the specified directory. Use create_dir to create a new empty directory on the specified directory. Use get_current_dir and set_current_dir to get and set the current working directory of the current process. Use get_process_path to get process executable file's absolute directory, ended with application executable name.","title":"File Management"},{"location":"manual/basics/file_management/#file-management","text":"#include <Luna/Runtime/File.hpp>","title":"File Management"},{"location":"manual/basics/file_management/#file-io","text":"IFile represents one system-level file handle that can be used to read and write file data. The user can create one IFile interface using open_file , and the file handle will be closed when its reference count drops to 0 . Data in the file can be read by IFile::read , and can be written by IFile::write . The current file cursor for IO operations can be fetched by IFile::tell , and can be set by IFile::seek . The whole size of the file can be fetched by IFile::get_size , and can be set by IFile::set_size . In most cases, file data written by IFile::write will not be written to storage media immediately, but being cached in driver buffer and written back to the storage in next hardware flush. The user can wait such flush by calling IFile::flush , which blocks the current thread until all written data is successfully written back to storage and visible to other processes. If you simply want to load file data after opening one file, you can pass IFile to load_file_data immediately after it is opened, which loads the whole file binary data and returns the data as one Blob object.","title":"File IO"},{"location":"manual/basics/file_management/#file-operations","text":"Use file_attribute to fetch the attribute of one specified file, like its creation time, last modified time, whether it is a directory, etc. Use copy_file and move_file for coping and moving files and directories. Use delete_file for deleting one file or directory. Use open_dir to create a file iterator ( IFileIterator ) that can be used to iterate over files and directories in the specified directory. Use create_dir to create a new empty directory on the specified directory. Use get_current_dir and set_current_dir to get and set the current working directory of the current process. Use get_process_path to get process executable file's absolute directory, ended with application executable name.","title":"File operations"},{"location":"manual/basics/initialization_and_shutdown/","text":"Initialization and Shutdown SDK Initialization #include <Luna/Runtime/Runtime.hpp> Call Luna::init to initialize Luna SDK. Most features provided by Luna SDK are only available after Luna SDK is initialized, so always initialize Luna SDK firstly on program startup. Luna::init returns one bool value, which indicates whether the initialization is succeeded. After the initialization is succeeded, following calls to Luna::init does nothing and returns true directly. Note that modules registered to Luna SDK will not be initialized by Luna::init , they should be initialized manually using functions like init_modules . See Modules for details. SDK shutdown #include <Luna/Runtime/Runtime.hpp> Call Luna::close to close Luna SDK. Most features provided by Luna SDK are not available after Luna SDK is closed. If Luna SDK is already closed, calling Luna::close does nothing and returns directly. Unlike SDK initialization, initialized modules will be closed by Luna::close in the reverse order of their initialization order, so they don't need to be closed manually. Release resources before closing SDK All dynamic memory allocated from memalloc , memrealloc and memnew must be freed before calling Luna::close . All boxed object created from new_object and object_alloc must be released before calling Luna::close . Calls to memfree , memdelete , object_release and other functions after Luna::close results in undefined behavior, and usually a program crash. This often happens when you declare global variables that hold dynamic allocated resources (such as Ref ) and memory blocks (such as UniquePtr , and containers like Vector , HashMap , etc.). Remember to clear such resources before calling Luna::close . For some containers, you should call clear then shrink_to_fit to eventually frees the internal memory buffer used by containers.","title":"Initialization and Shutdown"},{"location":"manual/basics/initialization_and_shutdown/#initialization-and-shutdown","text":"","title":"Initialization and Shutdown"},{"location":"manual/basics/initialization_and_shutdown/#sdk-initialization","text":"#include <Luna/Runtime/Runtime.hpp> Call Luna::init to initialize Luna SDK. Most features provided by Luna SDK are only available after Luna SDK is initialized, so always initialize Luna SDK firstly on program startup. Luna::init returns one bool value, which indicates whether the initialization is succeeded. After the initialization is succeeded, following calls to Luna::init does nothing and returns true directly. Note that modules registered to Luna SDK will not be initialized by Luna::init , they should be initialized manually using functions like init_modules . See Modules for details.","title":"SDK Initialization"},{"location":"manual/basics/initialization_and_shutdown/#sdk-shutdown","text":"#include <Luna/Runtime/Runtime.hpp> Call Luna::close to close Luna SDK. Most features provided by Luna SDK are not available after Luna SDK is closed. If Luna SDK is already closed, calling Luna::close does nothing and returns directly. Unlike SDK initialization, initialized modules will be closed by Luna::close in the reverse order of their initialization order, so they don't need to be closed manually.","title":"SDK shutdown"},{"location":"manual/basics/initialization_and_shutdown/#release-resources-before-closing-sdk","text":"All dynamic memory allocated from memalloc , memrealloc and memnew must be freed before calling Luna::close . All boxed object created from new_object and object_alloc must be released before calling Luna::close . Calls to memfree , memdelete , object_release and other functions after Luna::close results in undefined behavior, and usually a program crash. This often happens when you declare global variables that hold dynamic allocated resources (such as Ref ) and memory blocks (such as UniquePtr , and containers like Vector , HashMap , etc.). Remember to clear such resources before calling Luna::close . For some containers, you should call clear then shrink_to_fit to eventually frees the internal memory buffer used by containers.","title":"Release resources before closing SDK"},{"location":"manual/basics/interfaces/","text":"Interfaces Interfaces are C++ structures that only have pure virtual functions. Luna SDK provides most its functionalities through interfaces, so that the implementation detail can be encapsulated and may be different on different platforms. Declaring interfaces #include <Luna/Runtime/Interface.hpp> To declare one interface, declare one structure with I name prefix, and virtually inherit from Interface structure. Every interface should have one GUID, which can be declared using luiid macro. Methods of the interface is represented by pure virtual functions. struct IStream : virtual Interface { luiid(\"{0345f636-ca5c-4b4d-8416-29834377d239}\"); virtual RV read(void* buffer, usize size, usize* read_bytes = nullptr) = 0; virtual RV write(const void* buffer, usize size, usize* write_bytes = nullptr) = 0; }; One interface can inherit Interface directly, or it can inherit multiple other interfaces. The behavior is correctly defined since virtual inheritance is used. struct ISeekableStream : virtual IStream { luiid(\"{42F66080-C388-4EE0-9C4D-1EEC1B82F692}\"); virtual R<u64> tell() = 0; virtual RV seek(i64 offset, SeekMode mode) = 0; virtual u64 get_size() = 0; virtual RV set_size(u64 sz) = 0; }; Implementing interfaces Interfaces can be implemented by declaring structures that inherit from them. struct WindowsFile : ISeekableStream { lustruct(\"WindowsFile\", \"{95a2e5b2-d48a-4f19-bfb8-22c273c0ad4b}\"); luiimpl(); HANDLE m_file; virtual RV read(void* buffer, usize size, usize* read_bytes) override; virtual RV write(const void* buffer, usize size, usize* write_bytes) override; virtual R<u64> tell() override; virtual RV seek(i64 offset, SeekMode mode) override; virtual u64 get_size() override; virtual RV set_size(u64 sz) override; }; Note that interfaces only work for boxed objects . So the structure type that implements the interface should be registered to the type system either by register_boxed_type or by register_struct_type , and the object that implements the interface should only be created as boxed objects using new_object . Luna SDK also requires you to register interface implementation information to the system, so the registration code for the type above may looks like this: register_boxed_type<WindowsFile>(); impl_interface_for_type<WindowsFile, ISeekableStream, IStream>(); You can always use is_interface_implemented_by_type to check whether one interface is implemented by the specified type. Interface conversion Besides the dynamic casting functionality provided by boxed objects, Luna SDK provides additional functionalities for casting between interface pointers and boxed object pointers safely at run time. Casting typed object pointers to interface pointers Casting typed object pointers to interface pointers can be done directly using static_cast or C-style pointer casting, since the boxed type inherits from the interface type by declaration. Casting object_t to interface pointers If the underlying type of the interface is not exposed to the user, the user can use query_interface to fetch one pointer interface from object_t . This function will check whether the specified interface is implemented by the type of the specified object, and returns nullptr if not. The returned pointer can be casting to the specified interface type safely by using static_cast or C-style pointer casting. Casting interface pointers to object_t Casting interface pointers to object_t can be done by calling get_object function of the interface. This function is declared in Interface structure, and is implemented by luiimpl macro, so all interfaces support this function. The returned type of get_object is object_t , which is a type-less pointer, the user can then casting the pointer to one typed pointer using dynamic casting . Smart pointer for interface types #include <Luna/Runtime/Ref.hpp> Ref<T> and WeakRef<T> support interface types. You can use Ref<IStream> to refer one boxed object that comforms to IStream interface directly. Ref<T> handles type conversions automatically, so you can assign Ref of any type to each other, and the destination pointer will be set to nullptr if type casting fails.","title":"Interfaces"},{"location":"manual/basics/interfaces/#interfaces","text":"Interfaces are C++ structures that only have pure virtual functions. Luna SDK provides most its functionalities through interfaces, so that the implementation detail can be encapsulated and may be different on different platforms.","title":"Interfaces"},{"location":"manual/basics/interfaces/#declaring-interfaces","text":"#include <Luna/Runtime/Interface.hpp> To declare one interface, declare one structure with I name prefix, and virtually inherit from Interface structure. Every interface should have one GUID, which can be declared using luiid macro. Methods of the interface is represented by pure virtual functions. struct IStream : virtual Interface { luiid(\"{0345f636-ca5c-4b4d-8416-29834377d239}\"); virtual RV read(void* buffer, usize size, usize* read_bytes = nullptr) = 0; virtual RV write(const void* buffer, usize size, usize* write_bytes = nullptr) = 0; }; One interface can inherit Interface directly, or it can inherit multiple other interfaces. The behavior is correctly defined since virtual inheritance is used. struct ISeekableStream : virtual IStream { luiid(\"{42F66080-C388-4EE0-9C4D-1EEC1B82F692}\"); virtual R<u64> tell() = 0; virtual RV seek(i64 offset, SeekMode mode) = 0; virtual u64 get_size() = 0; virtual RV set_size(u64 sz) = 0; };","title":"Declaring interfaces"},{"location":"manual/basics/interfaces/#implementing-interfaces","text":"Interfaces can be implemented by declaring structures that inherit from them. struct WindowsFile : ISeekableStream { lustruct(\"WindowsFile\", \"{95a2e5b2-d48a-4f19-bfb8-22c273c0ad4b}\"); luiimpl(); HANDLE m_file; virtual RV read(void* buffer, usize size, usize* read_bytes) override; virtual RV write(const void* buffer, usize size, usize* write_bytes) override; virtual R<u64> tell() override; virtual RV seek(i64 offset, SeekMode mode) override; virtual u64 get_size() override; virtual RV set_size(u64 sz) override; }; Note that interfaces only work for boxed objects . So the structure type that implements the interface should be registered to the type system either by register_boxed_type or by register_struct_type , and the object that implements the interface should only be created as boxed objects using new_object . Luna SDK also requires you to register interface implementation information to the system, so the registration code for the type above may looks like this: register_boxed_type<WindowsFile>(); impl_interface_for_type<WindowsFile, ISeekableStream, IStream>(); You can always use is_interface_implemented_by_type to check whether one interface is implemented by the specified type.","title":"Implementing interfaces"},{"location":"manual/basics/interfaces/#interface-conversion","text":"Besides the dynamic casting functionality provided by boxed objects, Luna SDK provides additional functionalities for casting between interface pointers and boxed object pointers safely at run time.","title":"Interface conversion"},{"location":"manual/basics/interfaces/#casting-typed-object-pointers-to-interface-pointers","text":"Casting typed object pointers to interface pointers can be done directly using static_cast or C-style pointer casting, since the boxed type inherits from the interface type by declaration.","title":"Casting typed object pointers to interface pointers"},{"location":"manual/basics/interfaces/#casting-object_t-to-interface-pointers","text":"If the underlying type of the interface is not exposed to the user, the user can use query_interface to fetch one pointer interface from object_t . This function will check whether the specified interface is implemented by the type of the specified object, and returns nullptr if not. The returned pointer can be casting to the specified interface type safely by using static_cast or C-style pointer casting.","title":"Casting object_t to interface pointers"},{"location":"manual/basics/interfaces/#casting-interface-pointers-to-object_t","text":"Casting interface pointers to object_t can be done by calling get_object function of the interface. This function is declared in Interface structure, and is implemented by luiimpl macro, so all interfaces support this function. The returned type of get_object is object_t , which is a type-less pointer, the user can then casting the pointer to one typed pointer using dynamic casting .","title":"Casting interface pointers to object_t"},{"location":"manual/basics/interfaces/#smart-pointer-for-interface-types","text":"#include <Luna/Runtime/Ref.hpp> Ref<T> and WeakRef<T> support interface types. You can use Ref<IStream> to refer one boxed object that comforms to IStream interface directly. Ref<T> handles type conversions automatically, so you can assign Ref of any type to each other, and the destination pointer will be set to nullptr if type casting fails.","title":"Smart pointer for interface types"},{"location":"manual/basics/logs/","text":"Logs #include <Luna/Runtime/Log.hpp> Luna SDK contains a log system that can be used for logging and debugging purposes. Log message LogMessage structure represents one log entry. Every log message contains four properties: sender : The name of the function or module that emits this log, which can be used to filter logs. message : The log message, which is a UTF-8 string. verbosity : The verbosity level of the log, which can be used to filter logs based on verbosity level. extra : Extra arguments attached to the log entry, represented by one Variant object. One log message can be submitted to the log system by constructing one LogMessage object and passing it to log function manually. It can also be submitted conveniently by calling log_verbose , log_info , log_warning and log_error based on the verbosity level of your log message. Log handler Log handlers are entities that handle log messages to display or save them. For example, you may implement a log handler to display the log message on your game HUD or editor window. When one log is submitted to the log system, it will be dispatched to all handlers, the handler should decide whether to handle or skip this log by its filter and verbosity level settings. One log handler can be registered to the log system by register_log_callback , and unregistered from the log system by unregister_log_callback . When one log handler callback function is invoked, the same LogMessage object passed by the user or generated by the system will be provided, but is read-only to the handler. Built-in log handlers The log system includes two built-in log handlers: the STD log handler and the file log handler. STD log handler STD log handler outputs log messages to the standard output ( stdout ) of the program using printf . The STD log handler is disabled by default, the user can call set_log_std_enabled to enable/disable it at any time. The verbosity level of STD log handler can be configured by set_log_std_verbosity . File log handler File log handler outputs log messages to the file specified by the user. The file log handler is disabled by default, the user can call set_log_file_enabled to enable/disable it at any time. The user can call set_log_file to set the destination file of the log messages. If no file is set by the user, the handler will output logs to Log.txt file on the current working directory. For performance reasons, log messages will not be written to file immediately when being handled, but will be buffered internally and written to the file only when the buffer is full. You can also call flush_log_to_file manually if you want the buffer to be flushed immediately.","title":"Logs"},{"location":"manual/basics/logs/#logs","text":"#include <Luna/Runtime/Log.hpp> Luna SDK contains a log system that can be used for logging and debugging purposes.","title":"Logs"},{"location":"manual/basics/logs/#log-message","text":"LogMessage structure represents one log entry. Every log message contains four properties: sender : The name of the function or module that emits this log, which can be used to filter logs. message : The log message, which is a UTF-8 string. verbosity : The verbosity level of the log, which can be used to filter logs based on verbosity level. extra : Extra arguments attached to the log entry, represented by one Variant object. One log message can be submitted to the log system by constructing one LogMessage object and passing it to log function manually. It can also be submitted conveniently by calling log_verbose , log_info , log_warning and log_error based on the verbosity level of your log message.","title":"Log message"},{"location":"manual/basics/logs/#log-handler","text":"Log handlers are entities that handle log messages to display or save them. For example, you may implement a log handler to display the log message on your game HUD or editor window. When one log is submitted to the log system, it will be dispatched to all handlers, the handler should decide whether to handle or skip this log by its filter and verbosity level settings. One log handler can be registered to the log system by register_log_callback , and unregistered from the log system by unregister_log_callback . When one log handler callback function is invoked, the same LogMessage object passed by the user or generated by the system will be provided, but is read-only to the handler.","title":"Log handler"},{"location":"manual/basics/logs/#built-in-log-handlers","text":"The log system includes two built-in log handlers: the STD log handler and the file log handler.","title":"Built-in log handlers"},{"location":"manual/basics/logs/#std-log-handler","text":"STD log handler outputs log messages to the standard output ( stdout ) of the program using printf . The STD log handler is disabled by default, the user can call set_log_std_enabled to enable/disable it at any time. The verbosity level of STD log handler can be configured by set_log_std_verbosity .","title":"STD log handler"},{"location":"manual/basics/logs/#file-log-handler","text":"File log handler outputs log messages to the file specified by the user. The file log handler is disabled by default, the user can call set_log_file_enabled to enable/disable it at any time. The user can call set_log_file to set the destination file of the log messages. If no file is set by the user, the handler will output logs to Log.txt file on the current working directory. For performance reasons, log messages will not be written to file immediately when being handled, but will be buffered internally and written to the file only when the buffer is full. You can also call flush_log_to_file manually if you want the buffer to be flushed immediately.","title":"File log handler"},{"location":"manual/basics/math_library/","text":"Math Library Luna SDK comes with a math library that contains most math types and functions commonly-used in 3D applications. The math library contains the following parts: #include <Luna/Runtime/Math/Math.hpp> // For basic math types and functions. #include <Luna/Runtime/Math/Vector.hpp> // For vector types and functions. #include <Luna/Runtime/Math/Matrix.hpp> // For matrix types and functions. #include <Luna/Runtime/Math/Quaternion.hpp> // For Quaternion type and functions. #include <Luna/Runtime/Math/Transform.hpp> // For transform operations. The math library use SIMD instructions for vector and matrix calculations when possible. If SIMD instructions are not available on the target platform, we also have non-SIMD implementations for all math operations for compatibility. The SIMD instructions support of math library includes support of SSE/SSE2, SSE3, SSE4, AVX, AVX2, FMA3 and SVML instruction sets on x86/x64 processors, and NEON instruction set on arm/arm64 processors. Vectors #include <Luna/Runtime/Math/Vector.hpp> Float2 , Float3 and Float4 represent 2D, 3D and 4D vectors. These three types are 16-bytes aligned for maximizing SIMD performance. Luna SDK also provides unaligned vector types, these types are Vec2U<T> , Vec3U<T> and Vec4U<T> . The unaligned types are used mainly for storing and transferring vectors, such types should be converted to aligned types before they can be used for calculations. Luna SDK also defines Float2U , Int2U , UInt2U , Float3U , Int3U , UInt3U , Float4U , Int4U , UInt4U as aliasing types of Vec2U<T> , Vec3U<T> , Vec24U<T> for convenience. Components of these vector types can be fetched by their x , y , z and w properties. Aligned vector types can be compared( == and != ), added ( + ), subtracted ( - ), multiplied ( * ) and divided ( / ) like normal scalar types. These calculations are performed as performing the same calculation on each component element of the vector individually. When performing mathematical calculations between vector types and scalar types, the scaler number will be applied to all components of the vector. Luna SDK defines a series of functions to perform basic vector calculations. All these functions provide overloaded versions for handling 2D, 3D and 4D vector types. The following table lists all vector functions. Function Description in_bounds(a, min, max) Tests if a is in [min, max] bounds. length(a) Returns the length of vector a . length_squared(a) Returns the squared length of vector a . This is faster than length . dot(a, b) Returns the dot product of vector a and vector b . cross(a, b) Returns the cross product of vector a and vector b . normalize(a) Returns the normalized vector of vector a . clamp(a, min, max) Clamps vector a in [min, max] range. distance(a, b) Returns the Euclidean distance from vector a to vector b . distance_squared(a, b) Returns the squared Euclidean distance from vector a to vector b . This is faster than `distance . min(a, b) Returns one vector composed by the smaller component of each component in a and b . max(a, b) Returns one vector composed by the larger component of each component in a and b . lerp(a, b, t) Performs Linear interpolation between vector a and vector b according to one scalar factor t . smoothstep(a, b, t) Performs Smoothstep between vector a and vector b according to one scalar factor t . barycentric(a, b, c, x, y) Performs Barycentric triangle interpolation using three vector points a , b , c according to two scalar factors x and y . catmull_rom(a, b, c, d, t) Performs Catmull-Rom spline interpolation using four vector points a , b , c , d according to one scalar factor t . hermite(a, t1, b, t2, t) Performs Cubic Hermite spline interpolation using two vector points a , b , two vector tangents t1 , t2 according to one scalar factor t . reflect(i, n) Computes the reflection vector of the incident vector i using the normal vector n . refract(i, n, r) Computes the refraction vector of the incident vector i using the normal vector n and refraction index r . Matrices #include <Luna/Runtime/Math/Matrix.hpp> Float3x3 and Float4x4 represent 3x3 and 4x4 32-bit floating-point matrices. These two types are 16-bytes aligned for maximizing SIMD performance. Luna SDK also provides unaligned matrix types, these types are Float3x2U , Float3x3U , Float4x3U and Float4x4U . The unaligned types are used for storing and transferring matrices, and should be converted to aligned types ( Float3x2U to Float3x3 , Float4x3U to Float4x4 ) before they can be used for calculation. Rows in one matrix can be fetched by the m property of the matrix type, which is an array of Float3 or Float4 for Float3x3 and Float4x4 , or an two-dimensional f32 array for any unaligned matrix type. Aligned matrix types can be compared( == and != ), added ( + ), subtracted ( - ), multiplied ( * ) and divided ( / ) like normal scalar types. These calculations are performed as performing the same calculation on each component element of the matrix individually. When performing mathematical calculations between matrix types and scalar types, the scaler number will be applied to all components of the matrix. Luna SDK defines a series of functions to perform basic matrix calculations. All these functions provide overloaded versions for handling different matrix types. The following table lists all matrix functions. Function Description mul(a, b) Performs matrix multiplication between a and b , where a and b can be vector or matrix types. determinant(m) Computes determinant of one matrix m . transpose(m) Computes the transpose matrix of one matrix m . inverse(m) Computes the inversed matrix of one matrix m . Quaternions #include <Luna/Runtime/Math/Quaternion.hpp> Quaternion represents one Quaternion that can be used to represent a rotating operation in 3D space. Every Quaternion contains four f32 components, and is 16-bytes aligned for maximizing SIMD performance. The user can convert one Quaternion to Float4U for storing and transferring the Quaternion. Quaternion can be compared( == and != ), added ( + ), subtracted ( - ), multiplied ( * ) and divided ( / ) like normal scalar types. The addition and subtraction behavior of one Quaternion is the same as those of Float4 . The multiplication operation concatenates two Quaternions, while the division operation decomposes one Quaternion into two. Luna SDK defines a series of functions to perform Quaternion calculations. The following table lists all Quaternion functions. Function Description length(q) Returns the length of one Quaternion . Same as length for Float4 . length_squared(q) Returns the squared length of one Quaternion . Same as length_squared for Float4 . normalize(q) Normalizes one Quaternion . Same as normalize for Float4 . conjugate(q) Computes the conjugate of one Quaternion . inverse(q) Computes the inverse of one Quaternion . dot(q1, q2) Computes the dot product of two Quaternion s q1 and q2 . Same as dot for Float4 . lerp(q1, q2, t) Performs linear interpolation on two Quaternion s q1 and q2 according to one scalar factor t . slerp(q1, q2, t) Performs spherical linear interpolation on two Quaternion s q1 and q2 according to one scalar factor t . Transform #include <Luna/Runtime/Math/Transform.hpp> The transform header file does not include any new type. Instead, it defines a set of functions that can be useful for constructing affine matrices and projection matrices that are used in 2D and 3D transformations. Affine matrix operations 2D affine matrices and 3D affine matrices are presented by Float3x3 and Float4x4 . The +x axis of one affine matrix points to right, the +y axis of one affine matrix points to top, the +z axis of one affine matrix points to forward. The following table lists all functions for operating affine matrices. All functions are declared in AffineMatrix namespace. Function Description make(p, r, s) Constructs one 2D or 3D affine matrix from position vector p , rotation scalar or Quaternion r and scaling vector s . up(m) Extracts the up vector from one 2D or 3D affine matrix. down(m) Extracts the down vector from one 2D or 3D affine matrix. left(m) Extracts the left vector from one 2D or 3D affine matrix. right(m) Extracts the right vector from one 2D or 3D affine matrix. forward Extracts the forward vector from one 3D affine matrix. backward Extracts the backward vector from one 2D or 3D affine matrix. translation(m) Extracts the translation vector from one 2D or 3D affine matrix. rotation(m) Extracts the rotation scalar or Quaternion from one 2D or 3D affine matrix. euler_angles(m) Extracts the rotation vector that uses stores the rotation in Euler angles (pitch, yaw, roll) from one 3D affine matrix. scaling(m) Extracts the scaling vector from one 2D or 3D affine matrix. translation_matrix(m) Extracts the translation matrix from one 2D or 3D affine matrix. rotation_matrix(m) Extracts the rotation matrix from one 2D or 3D affine matrix. scaling_matrix(m) Extracts the scaling matrix from one 2D or 3D affine matrix. make_translation(t) Constructs one 2D or 3D translation matrix from position vector p . make_rotation(r) Constructs one 2D or 3D rotation matrix from rotation scalar or Quaternion r . make_rotation_x(r) Constructs one 3D rotation matrix that represents one rotation alone x axis. make_rotation_y(r) Constructs one 3D rotation matrix that represents one rotation alone y axis. make_rotation_z(r) Constructs one 3D rotation matrix that represents one rotation alone z axis. make_rotation_axis_angle(axis, angle) Constructs one 3D rotation matrix by specifying the rotation axis and rotation angle. make_rotation_euler_angles Constructs one 3D rotation matrix from Euler angles (pitch, yaw, roll). make_scaling(s) Constructs one 2D or 3D scaling matrix from scaling vector s . make_look_at(eye, target, up) Constructs one view matrix that targets the specified position. make_look_to(eye, dir, up) Constructs one view matrix that targets the specified direction. Projection matrix operations The following table lists all functions for operating projection matrices. All functions are declared in ProjectionMatrix namespace. Function Description make_perspective(width, height, near_z, far_z) Constructs a perspective projection matrix using width and height of the frustum. make_perspective_fov(fov, aspect_ratio, near_z, far_z) Constructs a perspective projection matrix using field-of-view and aspect_ratio of the frustum. make_perspective_off_center(left, right, bottom, top, near_z, far_z) Constructs a perspective projection matrix using offsets of the four sides of the frustum from the camera center. make_orthographic(width, height, near_z, far_z) Constructs a orthographic projection matrix using width and height of the frustum. make_orthographic_off_center(f32 left, f32 right, f32 bottom, f32 top, f32 near_z, f32 far_z) Constructs a orthographic projection matrix using offsets of the four sides of the frustum from the camera center.","title":"Math Library"},{"location":"manual/basics/math_library/#math-library","text":"Luna SDK comes with a math library that contains most math types and functions commonly-used in 3D applications. The math library contains the following parts: #include <Luna/Runtime/Math/Math.hpp> // For basic math types and functions. #include <Luna/Runtime/Math/Vector.hpp> // For vector types and functions. #include <Luna/Runtime/Math/Matrix.hpp> // For matrix types and functions. #include <Luna/Runtime/Math/Quaternion.hpp> // For Quaternion type and functions. #include <Luna/Runtime/Math/Transform.hpp> // For transform operations. The math library use SIMD instructions for vector and matrix calculations when possible. If SIMD instructions are not available on the target platform, we also have non-SIMD implementations for all math operations for compatibility. The SIMD instructions support of math library includes support of SSE/SSE2, SSE3, SSE4, AVX, AVX2, FMA3 and SVML instruction sets on x86/x64 processors, and NEON instruction set on arm/arm64 processors.","title":"Math Library"},{"location":"manual/basics/math_library/#vectors","text":"#include <Luna/Runtime/Math/Vector.hpp> Float2 , Float3 and Float4 represent 2D, 3D and 4D vectors. These three types are 16-bytes aligned for maximizing SIMD performance. Luna SDK also provides unaligned vector types, these types are Vec2U<T> , Vec3U<T> and Vec4U<T> . The unaligned types are used mainly for storing and transferring vectors, such types should be converted to aligned types before they can be used for calculations. Luna SDK also defines Float2U , Int2U , UInt2U , Float3U , Int3U , UInt3U , Float4U , Int4U , UInt4U as aliasing types of Vec2U<T> , Vec3U<T> , Vec24U<T> for convenience. Components of these vector types can be fetched by their x , y , z and w properties. Aligned vector types can be compared( == and != ), added ( + ), subtracted ( - ), multiplied ( * ) and divided ( / ) like normal scalar types. These calculations are performed as performing the same calculation on each component element of the vector individually. When performing mathematical calculations between vector types and scalar types, the scaler number will be applied to all components of the vector. Luna SDK defines a series of functions to perform basic vector calculations. All these functions provide overloaded versions for handling 2D, 3D and 4D vector types. The following table lists all vector functions. Function Description in_bounds(a, min, max) Tests if a is in [min, max] bounds. length(a) Returns the length of vector a . length_squared(a) Returns the squared length of vector a . This is faster than length . dot(a, b) Returns the dot product of vector a and vector b . cross(a, b) Returns the cross product of vector a and vector b . normalize(a) Returns the normalized vector of vector a . clamp(a, min, max) Clamps vector a in [min, max] range. distance(a, b) Returns the Euclidean distance from vector a to vector b . distance_squared(a, b) Returns the squared Euclidean distance from vector a to vector b . This is faster than `distance . min(a, b) Returns one vector composed by the smaller component of each component in a and b . max(a, b) Returns one vector composed by the larger component of each component in a and b . lerp(a, b, t) Performs Linear interpolation between vector a and vector b according to one scalar factor t . smoothstep(a, b, t) Performs Smoothstep between vector a and vector b according to one scalar factor t . barycentric(a, b, c, x, y) Performs Barycentric triangle interpolation using three vector points a , b , c according to two scalar factors x and y . catmull_rom(a, b, c, d, t) Performs Catmull-Rom spline interpolation using four vector points a , b , c , d according to one scalar factor t . hermite(a, t1, b, t2, t) Performs Cubic Hermite spline interpolation using two vector points a , b , two vector tangents t1 , t2 according to one scalar factor t . reflect(i, n) Computes the reflection vector of the incident vector i using the normal vector n . refract(i, n, r) Computes the refraction vector of the incident vector i using the normal vector n and refraction index r .","title":"Vectors"},{"location":"manual/basics/math_library/#matrices","text":"#include <Luna/Runtime/Math/Matrix.hpp> Float3x3 and Float4x4 represent 3x3 and 4x4 32-bit floating-point matrices. These two types are 16-bytes aligned for maximizing SIMD performance. Luna SDK also provides unaligned matrix types, these types are Float3x2U , Float3x3U , Float4x3U and Float4x4U . The unaligned types are used for storing and transferring matrices, and should be converted to aligned types ( Float3x2U to Float3x3 , Float4x3U to Float4x4 ) before they can be used for calculation. Rows in one matrix can be fetched by the m property of the matrix type, which is an array of Float3 or Float4 for Float3x3 and Float4x4 , or an two-dimensional f32 array for any unaligned matrix type. Aligned matrix types can be compared( == and != ), added ( + ), subtracted ( - ), multiplied ( * ) and divided ( / ) like normal scalar types. These calculations are performed as performing the same calculation on each component element of the matrix individually. When performing mathematical calculations between matrix types and scalar types, the scaler number will be applied to all components of the matrix. Luna SDK defines a series of functions to perform basic matrix calculations. All these functions provide overloaded versions for handling different matrix types. The following table lists all matrix functions. Function Description mul(a, b) Performs matrix multiplication between a and b , where a and b can be vector or matrix types. determinant(m) Computes determinant of one matrix m . transpose(m) Computes the transpose matrix of one matrix m . inverse(m) Computes the inversed matrix of one matrix m .","title":"Matrices"},{"location":"manual/basics/math_library/#quaternions","text":"#include <Luna/Runtime/Math/Quaternion.hpp> Quaternion represents one Quaternion that can be used to represent a rotating operation in 3D space. Every Quaternion contains four f32 components, and is 16-bytes aligned for maximizing SIMD performance. The user can convert one Quaternion to Float4U for storing and transferring the Quaternion. Quaternion can be compared( == and != ), added ( + ), subtracted ( - ), multiplied ( * ) and divided ( / ) like normal scalar types. The addition and subtraction behavior of one Quaternion is the same as those of Float4 . The multiplication operation concatenates two Quaternions, while the division operation decomposes one Quaternion into two. Luna SDK defines a series of functions to perform Quaternion calculations. The following table lists all Quaternion functions. Function Description length(q) Returns the length of one Quaternion . Same as length for Float4 . length_squared(q) Returns the squared length of one Quaternion . Same as length_squared for Float4 . normalize(q) Normalizes one Quaternion . Same as normalize for Float4 . conjugate(q) Computes the conjugate of one Quaternion . inverse(q) Computes the inverse of one Quaternion . dot(q1, q2) Computes the dot product of two Quaternion s q1 and q2 . Same as dot for Float4 . lerp(q1, q2, t) Performs linear interpolation on two Quaternion s q1 and q2 according to one scalar factor t . slerp(q1, q2, t) Performs spherical linear interpolation on two Quaternion s q1 and q2 according to one scalar factor t .","title":"Quaternions"},{"location":"manual/basics/math_library/#transform","text":"#include <Luna/Runtime/Math/Transform.hpp> The transform header file does not include any new type. Instead, it defines a set of functions that can be useful for constructing affine matrices and projection matrices that are used in 2D and 3D transformations.","title":"Transform"},{"location":"manual/basics/math_library/#affine-matrix-operations","text":"2D affine matrices and 3D affine matrices are presented by Float3x3 and Float4x4 . The +x axis of one affine matrix points to right, the +y axis of one affine matrix points to top, the +z axis of one affine matrix points to forward. The following table lists all functions for operating affine matrices. All functions are declared in AffineMatrix namespace. Function Description make(p, r, s) Constructs one 2D or 3D affine matrix from position vector p , rotation scalar or Quaternion r and scaling vector s . up(m) Extracts the up vector from one 2D or 3D affine matrix. down(m) Extracts the down vector from one 2D or 3D affine matrix. left(m) Extracts the left vector from one 2D or 3D affine matrix. right(m) Extracts the right vector from one 2D or 3D affine matrix. forward Extracts the forward vector from one 3D affine matrix. backward Extracts the backward vector from one 2D or 3D affine matrix. translation(m) Extracts the translation vector from one 2D or 3D affine matrix. rotation(m) Extracts the rotation scalar or Quaternion from one 2D or 3D affine matrix. euler_angles(m) Extracts the rotation vector that uses stores the rotation in Euler angles (pitch, yaw, roll) from one 3D affine matrix. scaling(m) Extracts the scaling vector from one 2D or 3D affine matrix. translation_matrix(m) Extracts the translation matrix from one 2D or 3D affine matrix. rotation_matrix(m) Extracts the rotation matrix from one 2D or 3D affine matrix. scaling_matrix(m) Extracts the scaling matrix from one 2D or 3D affine matrix. make_translation(t) Constructs one 2D or 3D translation matrix from position vector p . make_rotation(r) Constructs one 2D or 3D rotation matrix from rotation scalar or Quaternion r . make_rotation_x(r) Constructs one 3D rotation matrix that represents one rotation alone x axis. make_rotation_y(r) Constructs one 3D rotation matrix that represents one rotation alone y axis. make_rotation_z(r) Constructs one 3D rotation matrix that represents one rotation alone z axis. make_rotation_axis_angle(axis, angle) Constructs one 3D rotation matrix by specifying the rotation axis and rotation angle. make_rotation_euler_angles Constructs one 3D rotation matrix from Euler angles (pitch, yaw, roll). make_scaling(s) Constructs one 2D or 3D scaling matrix from scaling vector s . make_look_at(eye, target, up) Constructs one view matrix that targets the specified position. make_look_to(eye, dir, up) Constructs one view matrix that targets the specified direction.","title":"Affine matrix operations"},{"location":"manual/basics/math_library/#projection-matrix-operations","text":"The following table lists all functions for operating projection matrices. All functions are declared in ProjectionMatrix namespace. Function Description make_perspective(width, height, near_z, far_z) Constructs a perspective projection matrix using width and height of the frustum. make_perspective_fov(fov, aspect_ratio, near_z, far_z) Constructs a perspective projection matrix using field-of-view and aspect_ratio of the frustum. make_perspective_off_center(left, right, bottom, top, near_z, far_z) Constructs a perspective projection matrix using offsets of the four sides of the frustum from the camera center. make_orthographic(width, height, near_z, far_z) Constructs a orthographic projection matrix using width and height of the frustum. make_orthographic_off_center(f32 left, f32 right, f32 bottom, f32 top, f32 near_z, f32 far_z) Constructs a orthographic projection matrix using offsets of the four sides of the frustum from the camera center.","title":"Projection matrix operations"},{"location":"manual/basics/memory_management/","text":"Memory Management Luna SDK defines its own memory management functions instead of using those provided by standard libraries. The user should use functions provided by Luna SDK to manage memory when programming with Luna SDK. Heap memory allocation and deallocation #include <Luna/Runtime/Memory.hpp> The following functions allocate memory blocks in heaps. Function Description C++ STD Equivalent memalloc(size, alignment) Allocates memory block. malloc(size) memfree(ptr, alignment) Frees memory block. free(ptr) memrealloc(ptr, size, alignment) Reallocates memory block. realloc(ptr, size) memsize(ptr, alignment) Gets the size of the allocated memory block. N/A You may notice that all heap memory allocation functions provided by Luna SDK takes an alignment parameter, which can be used to allocate memory blocks with special address alignment requirements. If you don't have such requirement, simply specify alignment as 0 and Luna SDK will use the default alignment requirement for allocating memory blocks, which is 8 on 32-bit platforms and 16 on 64-bit platforms. Memory leak detection Luna SDK comes with an memory leak detection layer that tracks all memory blocks allocated from memalloc or memrealloc . The memory leak detection layer is disabled by default, you may enable it on xmake menus, or passing --check_memory_leak=true when building the SDK. You can use LUNA_RUNTIME_CHECK_MEMORY_LEAK macro to determine whether the memory leak detection layer is enabled. If memory leak detection layer is enabled and unfreed memory blocks are detected when Luna SDK is closing, Luna SDK will print warning messages for each unfreed memory block, including the size and the memory address of the block. If these blocks were allocated using memnew , the type of the block will also be printed, so that the user can detect the problem quickly. Dynamic object creation and destruction #include <Luna/Runtime/Memory.hpp> The following functions creates and destroys dynamic objects. Function Description C++ STD Equivalent memnew<T>(args...) Creates a dynamic object. new T(args...) memdelete(ptr) Destroys a dynamic object. delete ptr Out of memory (OOM) Although memalloc and memnew returns nullptr to indicate a failed memory allocation, most functions in Luna SDK do not handle OOM and assumes that the memory allocation will never fail. We treat OOM as an unrecoverable error for the following reasons: Dynamic memory allocation is used in throughout Luna SDK. If we need to handle OOM correctly, the SDK code will become much complex and redundant. It is not worthwhile to pay such effort to handle one error that seldom happens in normal cases. OOM actually never happens on some operating systems, if such system fails to allocate memory, it will simply kill the current process or let the user kill another process to free up some memory. We consider OOM as an optimization problem, not a programming error, so it is improper to \"handle\" it. If your program suffers from OOM on the target platform, the best thing to do is reducing the memory size consumed by your program, rather than trying to recover from OOM. Memory utility library #include <Luna/Runtime/MemoryUtils.hpp> Memory utility library provides functions that can be used to manipulate memory data easily. You can check the docs for each function for their usages. _kb , _mb , _gb , _tb are integer literals that can be used to define byte sizes clearly. For example, you can use 100_mb to represent 100 * 1024 * 1024 , and they have the same meaning. memcpy , memcmp , memset , memmove are memory manipulating functions provided by the C/C++ standard library. They can be used in Luna SDK as well. memzero is used to fill one range of memory with value 0 , it is equivalent to calling memset with value 0 . memcpy_bitmap and memcpy_bitmap3d are used to copy binary data between two row-major 2D and 3D bitmaps. pixel_offset is used to fetch the address of one particular pixel in a row-major 2D or 3D bitmap. These functions can be useful when dealing with bitmap data. align_upper increases the input size or address number to the nearest number that is a multiple of the alignment number. bit_test , bit_set , bit_reset tests, sets and resets one specific bit on the given memory address. These functions can be useful when performing bitwise operations. addressof returns the real address of one object, even if the operator& of the object has been overloaded. default_construct , value_construct , copy_construct , move_construct and direct_construct performs object initialization on the object pointed by the specified iterator/pointer. destruct performs object destruction on the object pointed by the specified iterator/pointer. copy_assign and move_assign perform copy assignment and move assignment on two objects pointed by the specified iterators/pointers. default_construct_range , value_construct_range , copy_construct_range and move_construct_range performs object initialization on objects in the range specified by two iterators/pointers. destruct_range performs object destruction on objects in the range specified by two iterators/pointers. copy_assign_range , move_assign_range and move_assign_range_backward performs copy assignment and move assignment on objects in the range specified by two iterators/pointers. fill_construct_range and fill_assign_range calls the copy constructor and copy assignment operator on objects with the specified instance. copy_relocate_range , copy_relocate , move_relocate_range and move_relocate_range_backward relocates objects in the range specified by two iterators/pointers to another continuous range, preserving the order of objects. If the object is trivially relocatable, this function will perform memory copy and does not invoke any move constructor; if the object is not trivially relocatable, this call performs move construction on the new address, and destruction on the old address.","title":"Memory Management"},{"location":"manual/basics/memory_management/#memory-management","text":"Luna SDK defines its own memory management functions instead of using those provided by standard libraries. The user should use functions provided by Luna SDK to manage memory when programming with Luna SDK.","title":"Memory Management"},{"location":"manual/basics/memory_management/#heap-memory-allocation-and-deallocation","text":"#include <Luna/Runtime/Memory.hpp> The following functions allocate memory blocks in heaps. Function Description C++ STD Equivalent memalloc(size, alignment) Allocates memory block. malloc(size) memfree(ptr, alignment) Frees memory block. free(ptr) memrealloc(ptr, size, alignment) Reallocates memory block. realloc(ptr, size) memsize(ptr, alignment) Gets the size of the allocated memory block. N/A You may notice that all heap memory allocation functions provided by Luna SDK takes an alignment parameter, which can be used to allocate memory blocks with special address alignment requirements. If you don't have such requirement, simply specify alignment as 0 and Luna SDK will use the default alignment requirement for allocating memory blocks, which is 8 on 32-bit platforms and 16 on 64-bit platforms.","title":"Heap memory allocation and deallocation"},{"location":"manual/basics/memory_management/#memory-leak-detection","text":"Luna SDK comes with an memory leak detection layer that tracks all memory blocks allocated from memalloc or memrealloc . The memory leak detection layer is disabled by default, you may enable it on xmake menus, or passing --check_memory_leak=true when building the SDK. You can use LUNA_RUNTIME_CHECK_MEMORY_LEAK macro to determine whether the memory leak detection layer is enabled. If memory leak detection layer is enabled and unfreed memory blocks are detected when Luna SDK is closing, Luna SDK will print warning messages for each unfreed memory block, including the size and the memory address of the block. If these blocks were allocated using memnew , the type of the block will also be printed, so that the user can detect the problem quickly.","title":"Memory leak detection"},{"location":"manual/basics/memory_management/#dynamic-object-creation-and-destruction","text":"#include <Luna/Runtime/Memory.hpp> The following functions creates and destroys dynamic objects. Function Description C++ STD Equivalent memnew<T>(args...) Creates a dynamic object. new T(args...) memdelete(ptr) Destroys a dynamic object. delete ptr","title":"Dynamic object creation and destruction"},{"location":"manual/basics/memory_management/#out-of-memory-oom","text":"Although memalloc and memnew returns nullptr to indicate a failed memory allocation, most functions in Luna SDK do not handle OOM and assumes that the memory allocation will never fail. We treat OOM as an unrecoverable error for the following reasons: Dynamic memory allocation is used in throughout Luna SDK. If we need to handle OOM correctly, the SDK code will become much complex and redundant. It is not worthwhile to pay such effort to handle one error that seldom happens in normal cases. OOM actually never happens on some operating systems, if such system fails to allocate memory, it will simply kill the current process or let the user kill another process to free up some memory. We consider OOM as an optimization problem, not a programming error, so it is improper to \"handle\" it. If your program suffers from OOM on the target platform, the best thing to do is reducing the memory size consumed by your program, rather than trying to recover from OOM.","title":"Out of memory (OOM)"},{"location":"manual/basics/memory_management/#memory-utility-library","text":"#include <Luna/Runtime/MemoryUtils.hpp> Memory utility library provides functions that can be used to manipulate memory data easily. You can check the docs for each function for their usages. _kb , _mb , _gb , _tb are integer literals that can be used to define byte sizes clearly. For example, you can use 100_mb to represent 100 * 1024 * 1024 , and they have the same meaning. memcpy , memcmp , memset , memmove are memory manipulating functions provided by the C/C++ standard library. They can be used in Luna SDK as well. memzero is used to fill one range of memory with value 0 , it is equivalent to calling memset with value 0 . memcpy_bitmap and memcpy_bitmap3d are used to copy binary data between two row-major 2D and 3D bitmaps. pixel_offset is used to fetch the address of one particular pixel in a row-major 2D or 3D bitmap. These functions can be useful when dealing with bitmap data. align_upper increases the input size or address number to the nearest number that is a multiple of the alignment number. bit_test , bit_set , bit_reset tests, sets and resets one specific bit on the given memory address. These functions can be useful when performing bitwise operations. addressof returns the real address of one object, even if the operator& of the object has been overloaded. default_construct , value_construct , copy_construct , move_construct and direct_construct performs object initialization on the object pointed by the specified iterator/pointer. destruct performs object destruction on the object pointed by the specified iterator/pointer. copy_assign and move_assign perform copy assignment and move assignment on two objects pointed by the specified iterators/pointers. default_construct_range , value_construct_range , copy_construct_range and move_construct_range performs object initialization on objects in the range specified by two iterators/pointers. destruct_range performs object destruction on objects in the range specified by two iterators/pointers. copy_assign_range , move_assign_range and move_assign_range_backward performs copy assignment and move assignment on objects in the range specified by two iterators/pointers. fill_construct_range and fill_assign_range calls the copy constructor and copy assignment operator on objects with the specified instance. copy_relocate_range , copy_relocate , move_relocate_range and move_relocate_range_backward relocates objects in the range specified by two iterators/pointers to another continuous range, preserving the order of objects. If the object is trivially relocatable, this function will perform memory copy and does not invoke any move constructor; if the object is not trivially relocatable, this call performs move construction on the new address, and destruction on the old address.","title":"Memory utility library"},{"location":"manual/basics/modules/","text":"Modules Luna SDK is a modular framework, every function of Luna SDK is provided by one or more modules. The fundamental functions of Luna SDK are provided by Runtime module, which will be initialized along with Luna SDK and is can be used anywhere. Other functions are provided by dedicated modules and should be added to Luna SDK explicitly when required. Module files Every Luna SDK module should have its own directory under ${ROOT_DIR}/Modules directory, with the module name as the directory name. Under the module root directory, every module must have one xmake.lua script defining the building rules of the module. The user can use the following code as the starting point for new modules: target(\"MyModule\") set_luna_sdk_module() add_headerfiles(\"*.hpp\", \"Source/**.hpp\") add_files(\"Source/**.cpp\") add_deps(\"Runtime\", \"MuDepModule1\", \"MyDepModule2\") target_end() set_luna_sdk_module() tells xmake to import all Luna SDK module global options and specifications to the current module, including one set_kind call to properly set the module target file kind. One module may be built into one static library ( .lib or .o ) or one shared library ( .dll or .so ) based on build_shared_lib xmake config of Luna SDK. add_headerfiles and add_files imports module header files ( .h , .hpp and .inl ) and module source files ( .c , .cpp ) to the module. add_deps adds dependency modules for the current module, so that they can be linked correctly. Every module should have one Source directory under the module root directory that contains all private files and directories only visible to the current module. All files and directories that are not in Source directory will be considered as module public files and should not contain module source files ( .c , .cpp files). Luna SDK sets ${ROOT_DIR}/Modules as the global include directory for all modules and programs, so you can simply include module interface files by #include <Luna/ModuleName/FileName.hpp> , like #include <Luna/RHI/RHI.hpp> . Module namespace Every module should declare all entities under its own namespace under Luna namespace. The namespace name for the module should be concise and is may not be equal to the name of the module. Do not declare using namespace under the module interface header files. namespace Luna { namespace MyModule { // Your declarations goes here... } } Module API declaration Module API functions and variables should have special linkage and codec specifications to be exported and linked correctly when compiled to shared or static libraries. Every module should use LUNA_XXX_API macro to decorate all APIs of the module, where XXX is the name of your module. LUNA_XXX_API should be defined like so in the module header files: #ifndef LUNA_XXX_API #define LUNA_XXX_API #endif // Your API. LUNA_XXX_API void do_something(); When you need to provide definitions for APIs on module source files, define LUNA_XXX_API before including header files like so: #include <Luna/Runtime/PlatformDefines.hpp> #define LUNA_XXX_API LUNA_EXPORT // Include your header files... This will overwrite LUNA_XXX_API with LUNA_EXPORT , which is a predefined platform-specific macro to append linkage and codec declarations for API functions and objects. Module registration #include <Luna/Runtime/Module.hpp> One module must be registered to Luna SDK before it can be initialized and used by your program or other modules. Modules are described by ModuleDesc structure, you can fill this structure and call add_module to add one module to Luna SDK. ModuleDesc desc; desc.name = \"MyModule\"; desc.dependencies = \"MuDepModule1;MyDepModule2\"; // `Runtime` is always included and should not be listed here. desc.init_func = my_module_init; // Can be `nullptr` if not needed. desc.close_func = my_module_close; // Can be `nullptr` if not needed. add_module(&desc); add_module is one of few functions that can be called before Luna SDK is initialized. StaticRegisterModule uses this behavior to register modules automatically by calling add_module in its constructor. We can simply declare it as a global object for our module to register our module automatically when the module library is loaded. StaticRegisterModule my_module(\"MyModule\", \"MuDepModule1;MyDepModule2\", my_module_init, my_module_close); Module initialization #include <Luna/Runtime/Module.hpp> Modules are not initialized along with Luna SDK and should be manually initialized after Luna SDK is initialized. This behavior enables the user to have a precisely control over module initialization time and can perform some extra operations before the module is initialized. Module system provides three methods to initialize modules: init_modules , init_module and init_module_dependencies . init_modules initialize all uninitialized modules registered to Luna SDK, by their dependency order. This is the simplest way to initialize all modules in one call, but the user does not have much control during the module initialization process. init_module initializes one specific module and all its recursively dependency modules of that module by their dependency order, while init_module_dependencies only initializes all recursively dependency modules of the specified module by their dependency order, but not the specified module. These two functions let the user pause the module initialization process to perform some extra tasks (like choosing the default graphic device), then continue to initialize other modules, which make the module initialization process more flexible. Module closing Modules are closed along with Luna SDK in the reverse order of their initialization order. There is no approach to close modules manually.","title":"Modules"},{"location":"manual/basics/modules/#modules","text":"Luna SDK is a modular framework, every function of Luna SDK is provided by one or more modules. The fundamental functions of Luna SDK are provided by Runtime module, which will be initialized along with Luna SDK and is can be used anywhere. Other functions are provided by dedicated modules and should be added to Luna SDK explicitly when required.","title":"Modules"},{"location":"manual/basics/modules/#module-files","text":"Every Luna SDK module should have its own directory under ${ROOT_DIR}/Modules directory, with the module name as the directory name. Under the module root directory, every module must have one xmake.lua script defining the building rules of the module. The user can use the following code as the starting point for new modules: target(\"MyModule\") set_luna_sdk_module() add_headerfiles(\"*.hpp\", \"Source/**.hpp\") add_files(\"Source/**.cpp\") add_deps(\"Runtime\", \"MuDepModule1\", \"MyDepModule2\") target_end() set_luna_sdk_module() tells xmake to import all Luna SDK module global options and specifications to the current module, including one set_kind call to properly set the module target file kind. One module may be built into one static library ( .lib or .o ) or one shared library ( .dll or .so ) based on build_shared_lib xmake config of Luna SDK. add_headerfiles and add_files imports module header files ( .h , .hpp and .inl ) and module source files ( .c , .cpp ) to the module. add_deps adds dependency modules for the current module, so that they can be linked correctly. Every module should have one Source directory under the module root directory that contains all private files and directories only visible to the current module. All files and directories that are not in Source directory will be considered as module public files and should not contain module source files ( .c , .cpp files). Luna SDK sets ${ROOT_DIR}/Modules as the global include directory for all modules and programs, so you can simply include module interface files by #include <Luna/ModuleName/FileName.hpp> , like #include <Luna/RHI/RHI.hpp> .","title":"Module files"},{"location":"manual/basics/modules/#module-namespace","text":"Every module should declare all entities under its own namespace under Luna namespace. The namespace name for the module should be concise and is may not be equal to the name of the module. Do not declare using namespace under the module interface header files. namespace Luna { namespace MyModule { // Your declarations goes here... } }","title":"Module namespace"},{"location":"manual/basics/modules/#module-api-declaration","text":"Module API functions and variables should have special linkage and codec specifications to be exported and linked correctly when compiled to shared or static libraries. Every module should use LUNA_XXX_API macro to decorate all APIs of the module, where XXX is the name of your module. LUNA_XXX_API should be defined like so in the module header files: #ifndef LUNA_XXX_API #define LUNA_XXX_API #endif // Your API. LUNA_XXX_API void do_something(); When you need to provide definitions for APIs on module source files, define LUNA_XXX_API before including header files like so: #include <Luna/Runtime/PlatformDefines.hpp> #define LUNA_XXX_API LUNA_EXPORT // Include your header files... This will overwrite LUNA_XXX_API with LUNA_EXPORT , which is a predefined platform-specific macro to append linkage and codec declarations for API functions and objects.","title":"Module API declaration"},{"location":"manual/basics/modules/#module-registration","text":"#include <Luna/Runtime/Module.hpp> One module must be registered to Luna SDK before it can be initialized and used by your program or other modules. Modules are described by ModuleDesc structure, you can fill this structure and call add_module to add one module to Luna SDK. ModuleDesc desc; desc.name = \"MyModule\"; desc.dependencies = \"MuDepModule1;MyDepModule2\"; // `Runtime` is always included and should not be listed here. desc.init_func = my_module_init; // Can be `nullptr` if not needed. desc.close_func = my_module_close; // Can be `nullptr` if not needed. add_module(&desc); add_module is one of few functions that can be called before Luna SDK is initialized. StaticRegisterModule uses this behavior to register modules automatically by calling add_module in its constructor. We can simply declare it as a global object for our module to register our module automatically when the module library is loaded. StaticRegisterModule my_module(\"MyModule\", \"MuDepModule1;MyDepModule2\", my_module_init, my_module_close);","title":"Module registration"},{"location":"manual/basics/modules/#module-initialization","text":"#include <Luna/Runtime/Module.hpp> Modules are not initialized along with Luna SDK and should be manually initialized after Luna SDK is initialized. This behavior enables the user to have a precisely control over module initialization time and can perform some extra operations before the module is initialized. Module system provides three methods to initialize modules: init_modules , init_module and init_module_dependencies . init_modules initialize all uninitialized modules registered to Luna SDK, by their dependency order. This is the simplest way to initialize all modules in one call, but the user does not have much control during the module initialization process. init_module initializes one specific module and all its recursively dependency modules of that module by their dependency order, while init_module_dependencies only initializes all recursively dependency modules of the specified module by their dependency order, but not the specified module. These two functions let the user pause the module initialization process to perform some extra tasks (like choosing the default graphic device), then continue to initialize other modules, which make the module initialization process more flexible.","title":"Module initialization"},{"location":"manual/basics/modules/#module-closing","text":"Modules are closed along with Luna SDK in the reverse order of their initialization order. There is no approach to close modules manually.","title":"Module closing"},{"location":"manual/basics/serialization_and_deserialization/","text":"Serialization and Deserialization #include <Luna/Runtime/Serialization.hpp> Luna SDK comes with a built-in serialization and deserialization library that can serialize objects of serializable types to Variant objects, with can then be encoded to byte streams using JSON or other text and binary formats. One type must meets the following requirements to be a serializable type: This type has been registered to the type system . This type is marked as serializable by calling set_serializable . set_serializable accepts one optional SerializableTypeDesc structure, which let the user set serialization and deserialization callback functions for the type. If this structure is not provided, the default serialization and deserialization procedure will be used. For generic structure types, set_serializable will be applied to all instanced types of that generic type. The user can also call set_serializable on one specific instanced type to override the serialization and deserialization behavior set on the generic type. For any serializable objects, the user can call serialize to serialize one object to one Variant , and call deserialize to deserialize one object from one Variant . Default serialization and deserialization behavior The default serialization procedure checks the type of the object, then returns one Variant object based on the following rules: For structure types, the returned Variant will be an object of serializable properties, indexed by their property names. The data of every property is generated by another serialize call. Unserializable properties will be ignored. For single enumeration types, the returned Variant will be the name of the option that matches the underlying value of the object. If no option matches the underlying value, the serialization function will throw BasicError::bad_data error. For multiple enumeration types, the returned Variant will be an array that contains names of all selected options. If no option is selected, an empty Variant array will be returned. The default deserialization procedure checks the type of the object, then assigns the data of the object based on the following rules: For structure types, deserialize is called for every serializable property of the object with the data of that property. Properties without data in Variant and unrecognized properties will be ignored. For single enumeration types, the default deserialization function reads the name string stored in Variant , and assigns the enumeration object with the value whose option name matches the data. If no option matches the name string stored in Variant , the deserialization function will throw BasicError::bad_data error. For multiple enumeration types, the default deserialization function firstly clears the object to 0 , then reads the array of strings stored in Variant , and sets corresponding bits in the target object. Unrecognized options will be ignored.","title":"Serialization and Deserialization"},{"location":"manual/basics/serialization_and_deserialization/#serialization-and-deserialization","text":"#include <Luna/Runtime/Serialization.hpp> Luna SDK comes with a built-in serialization and deserialization library that can serialize objects of serializable types to Variant objects, with can then be encoded to byte streams using JSON or other text and binary formats. One type must meets the following requirements to be a serializable type: This type has been registered to the type system . This type is marked as serializable by calling set_serializable . set_serializable accepts one optional SerializableTypeDesc structure, which let the user set serialization and deserialization callback functions for the type. If this structure is not provided, the default serialization and deserialization procedure will be used. For generic structure types, set_serializable will be applied to all instanced types of that generic type. The user can also call set_serializable on one specific instanced type to override the serialization and deserialization behavior set on the generic type. For any serializable objects, the user can call serialize to serialize one object to one Variant , and call deserialize to deserialize one object from one Variant .","title":"Serialization and Deserialization"},{"location":"manual/basics/serialization_and_deserialization/#default-serialization-and-deserialization-behavior","text":"The default serialization procedure checks the type of the object, then returns one Variant object based on the following rules: For structure types, the returned Variant will be an object of serializable properties, indexed by their property names. The data of every property is generated by another serialize call. Unserializable properties will be ignored. For single enumeration types, the returned Variant will be the name of the option that matches the underlying value of the object. If no option matches the underlying value, the serialization function will throw BasicError::bad_data error. For multiple enumeration types, the returned Variant will be an array that contains names of all selected options. If no option is selected, an empty Variant array will be returned. The default deserialization procedure checks the type of the object, then assigns the data of the object based on the following rules: For structure types, deserialize is called for every serializable property of the object with the data of that property. Properties without data in Variant and unrecognized properties will be ignored. For single enumeration types, the default deserialization function reads the name string stored in Variant , and assigns the enumeration object with the value whose option name matches the data. If no option matches the name string stored in Variant , the deserialization function will throw BasicError::bad_data error. For multiple enumeration types, the default deserialization function firstly clears the object to 0 , then reads the array of strings stored in Variant , and sets corresponding bits in the target object. Unrecognized options will be ignored.","title":"Default serialization and deserialization behavior"},{"location":"manual/basics/strings/","text":"Strings Strings are sequences of characters represented by c8 , c16 and c32 , terminated by a null terminator ( \\0 ). Luna SDK provides various string types and libraries, they will be discussed in this section. String types #include <Luna/Runtime/String.hpp> // For String, String16 and String32. #include <Luna/Runtime/Name.hpp> // For Name. Luna SDK provides two kinds of string types: String and Name . The String type is a sequence of c8 characters ended with \\0 . We designed String as a replacement of std::string in Luna SDK, so most methods used for std::string should work find with our String type. Besides the String type, we also have String16 and String32 as replacements for std::u16string and std::u32string that holds character sequences of c16 and c32 types. The Name type represents one immutable c8 string that is usually used as an identifier. We implemented a global name registry in Luna SDK so that every unique name will have only one data copy in the registry, and all Name objects with the same string data refers to that copy, thus can be compared for equality quickly. The name string data is reference counted, and will be freed when the last Name object that refers to the data is destructed. Strings stored in Name cannot be changed, if the user assigns Name with another string, the Name object will refer to another string data entry, remaining the original string entry unchanged. Name and String can be converted to each other implicitly. There is no enforced encoding format for string types, but most text processing APIs in Luna SDK expects UTF-8 encoded strings for String and Name types. String utility library #include <Luna/Runtime/StringUtils.hpp> The string utility library provides functions for processing characters and strings. Luna SDK imports the following string and character processing functions from C standard library that can be used directly in Luna SDK: strncpy strcat strncat strxfrm strncmp strcoll strchr strrchr strspn strpbrk strstr strtok isalnum isalpha islower isupper tolower toupper isdigit isxdigit iscntrl isgraph isspace isblank isprint ispunct strlen , strcpy and strcmp are compatible to C standard library, but are extended by Luna SDK so they handles all character types. strcmp_prefix checks whether one string is the prefix string of another string, and returns 0 if is. strtoi64 , strtou64 and strtof64 interprets one number value presented the by string, and returns the value. Unicode encoding library #include <Luna/Runtime/UTF8.hpp> Unicode is a text encoding standard that is widely used in modern computers, programs and websites. Luna SDK comes with a built-in Unicode library for processing strings encoded in commonly-used Unicode formats, including UTF-8, UTF-16 (LE and GE) and UTF-32. Luna SDK uses 32-bit character type ( c32 ) to represent one Unicode character, the value of the character object represents the codepoint of the character in Unicode character table. One Unicode character can be encoded to 1 c32 character in UTF-32, 1 to 2 c16 characters in UTF-16, and 1 to 6 c8 characters in UTF-8. By definition, one Unicode character represented by c32 differs from one Unicode character encoded using UTF-32 (the first bit of one UTF-32 character must be 0, so only 2^32 Unicode codepoints can be represented in UTF-32). But in practice, all existing Unicode characters can be converted to their UTF-32 representation without any modification, so we do not differ one Unicode character from one UTF-32 character in this manual. utf8_charspan and utf16_charspan take one Unicode character, and return the number of c8 or c16 characters required to represent that character in UTF-8 or UTF-16 encoding. utf8_charlen and utf16_charlen take the first c8 or c16 character of one UTF-8 or UTF-16 encoded Unicode character, and return the number of bytes used for that character. These functions can be used to measure the size of one UTF-32 character in UTF-8 and UTF-16 encoding. utf8_strlen and utf16_strlen calculate the number of Unicode characters contained by a UTF-8 or UTF-16 encoded string, utf8_index and utf16_index return the index of the first c8 or c16 character of the n th Unicode character in a UTF-8 or UTF-16 ebcided string. These functions can be used to calculate the length of Unicode-encoded strings. utf8_encode_char and utf16_encode_char encode one Unicode character into multiple c8 or c16 characters using UTF-8 or UTF-16 encoding, write the encoded characters to the user-provided buffer, and return the number of characters written. utf8_decode_char and utf16_decode_char , on the other side, read multiple c8 or c16 characters from the user-provided buffer, and returns the Unicode character represented by these characters. utf16_to_utf8 converts a UTF-8 encoded string to a UTF-16 encoded string, and utf8_to_utf16 converts a UTF-16 encoded string to a UTF-8 encoded string. Both functions write result strings in a user-provided buffer, utf16_to_utf8_len and utf8_to_utf16_len can be used to calculate the minimum size (measured in number of c8 or c16 characters, not including the null terminator) required for the buffer to hold the result string. Base64 encoding library #include <Luna/Runtime/Base64.hpp> Base64 is an encoding format that represents arbitrary binary data using 64 printable characters, plus one character ( = ) for paddings. It is useful to store binary data in a text-based file. Luna SDK comes with a built-in Base64 library for encoding and decoding binary data using Base64. base64_encode encodes the binary data in the user-provided source buffer to a Base64 encoded string, and writes the string to the user-provided destination buffer. To determine the size of the destination buffer required, call base64_get_encoded_size with the size of the row binary data. base64_decode decodes the Base64 string in the user-provided source buffer to original binary data, and writes the binary data to the user-provided destination buffer. To determine the size of the destination buffer required, call base64_get_decoded_size with the size of the Base64 string, excluding the null terminator.","title":"Strings"},{"location":"manual/basics/strings/#strings","text":"Strings are sequences of characters represented by c8 , c16 and c32 , terminated by a null terminator ( \\0 ). Luna SDK provides various string types and libraries, they will be discussed in this section.","title":"Strings"},{"location":"manual/basics/strings/#string-types","text":"#include <Luna/Runtime/String.hpp> // For String, String16 and String32. #include <Luna/Runtime/Name.hpp> // For Name. Luna SDK provides two kinds of string types: String and Name . The String type is a sequence of c8 characters ended with \\0 . We designed String as a replacement of std::string in Luna SDK, so most methods used for std::string should work find with our String type. Besides the String type, we also have String16 and String32 as replacements for std::u16string and std::u32string that holds character sequences of c16 and c32 types. The Name type represents one immutable c8 string that is usually used as an identifier. We implemented a global name registry in Luna SDK so that every unique name will have only one data copy in the registry, and all Name objects with the same string data refers to that copy, thus can be compared for equality quickly. The name string data is reference counted, and will be freed when the last Name object that refers to the data is destructed. Strings stored in Name cannot be changed, if the user assigns Name with another string, the Name object will refer to another string data entry, remaining the original string entry unchanged. Name and String can be converted to each other implicitly. There is no enforced encoding format for string types, but most text processing APIs in Luna SDK expects UTF-8 encoded strings for String and Name types.","title":"String types"},{"location":"manual/basics/strings/#string-utility-library","text":"#include <Luna/Runtime/StringUtils.hpp> The string utility library provides functions for processing characters and strings. Luna SDK imports the following string and character processing functions from C standard library that can be used directly in Luna SDK: strncpy strcat strncat strxfrm strncmp strcoll strchr strrchr strspn strpbrk strstr strtok isalnum isalpha islower isupper tolower toupper isdigit isxdigit iscntrl isgraph isspace isblank isprint ispunct strlen , strcpy and strcmp are compatible to C standard library, but are extended by Luna SDK so they handles all character types. strcmp_prefix checks whether one string is the prefix string of another string, and returns 0 if is. strtoi64 , strtou64 and strtof64 interprets one number value presented the by string, and returns the value.","title":"String utility library"},{"location":"manual/basics/strings/#unicode-encoding-library","text":"#include <Luna/Runtime/UTF8.hpp> Unicode is a text encoding standard that is widely used in modern computers, programs and websites. Luna SDK comes with a built-in Unicode library for processing strings encoded in commonly-used Unicode formats, including UTF-8, UTF-16 (LE and GE) and UTF-32. Luna SDK uses 32-bit character type ( c32 ) to represent one Unicode character, the value of the character object represents the codepoint of the character in Unicode character table. One Unicode character can be encoded to 1 c32 character in UTF-32, 1 to 2 c16 characters in UTF-16, and 1 to 6 c8 characters in UTF-8. By definition, one Unicode character represented by c32 differs from one Unicode character encoded using UTF-32 (the first bit of one UTF-32 character must be 0, so only 2^32 Unicode codepoints can be represented in UTF-32). But in practice, all existing Unicode characters can be converted to their UTF-32 representation without any modification, so we do not differ one Unicode character from one UTF-32 character in this manual. utf8_charspan and utf16_charspan take one Unicode character, and return the number of c8 or c16 characters required to represent that character in UTF-8 or UTF-16 encoding. utf8_charlen and utf16_charlen take the first c8 or c16 character of one UTF-8 or UTF-16 encoded Unicode character, and return the number of bytes used for that character. These functions can be used to measure the size of one UTF-32 character in UTF-8 and UTF-16 encoding. utf8_strlen and utf16_strlen calculate the number of Unicode characters contained by a UTF-8 or UTF-16 encoded string, utf8_index and utf16_index return the index of the first c8 or c16 character of the n th Unicode character in a UTF-8 or UTF-16 ebcided string. These functions can be used to calculate the length of Unicode-encoded strings. utf8_encode_char and utf16_encode_char encode one Unicode character into multiple c8 or c16 characters using UTF-8 or UTF-16 encoding, write the encoded characters to the user-provided buffer, and return the number of characters written. utf8_decode_char and utf16_decode_char , on the other side, read multiple c8 or c16 characters from the user-provided buffer, and returns the Unicode character represented by these characters. utf16_to_utf8 converts a UTF-8 encoded string to a UTF-16 encoded string, and utf8_to_utf16 converts a UTF-16 encoded string to a UTF-8 encoded string. Both functions write result strings in a user-provided buffer, utf16_to_utf8_len and utf8_to_utf16_len can be used to calculate the minimum size (measured in number of c8 or c16 characters, not including the null terminator) required for the buffer to hold the result string.","title":"Unicode encoding library"},{"location":"manual/basics/strings/#base64-encoding-library","text":"#include <Luna/Runtime/Base64.hpp> Base64 is an encoding format that represents arbitrary binary data using 64 printable characters, plus one character ( = ) for paddings. It is useful to store binary data in a text-based file. Luna SDK comes with a built-in Base64 library for encoding and decoding binary data using Base64. base64_encode encodes the binary data in the user-provided source buffer to a Base64 encoded string, and writes the string to the user-provided destination buffer. To determine the size of the destination buffer required, call base64_get_encoded_size with the size of the row binary data. base64_decode decodes the Base64 string in the user-provided source buffer to original binary data, and writes the binary data to the user-provided destination buffer. To determine the size of the destination buffer required, call base64_get_decoded_size with the size of the Base64 string, excluding the null terminator.","title":"Base64 encoding library"},{"location":"manual/basics/thread_and_synchronization_objects/","text":"Thread and Synchronization Objects Threads #include <Luna/Runtime/Thread.hpp> new_thread creates one system-level thread, which is represented by IThread . The user can wait for the thread to exit by calling IThread::wait , and check whether the thread is exited by calling IThread::try_wait . When the last reference to IThread is releasing, the system blocks the current thread until the thread quits. Every thread uses a thread-local variable to record the current thread's handle, which can be retrieved by get_current_thread . The main thread's handle is also recorded and can be retrieved from any thread by get_main_thread . The user can delay the execution of the current thread by calling sleep or fast_sleep , the second function is more accurate and will not suspend the current thread if the time specified is smaller than several milliseconds. The user can call yield_current_thread to yield the remain time slice of the current thread and let OS to schedule other threads. This is useful for reducing CPU cycles if the current thread is waiting for another operation to finish by hardware or another thread. Thread local storage (TLS) #include <Luna/Runtime/Thread.hpp> Thread local storage is a set of pointer-sized memory slots that contains unique data for every thread. This can be useful to store thread-local data and is efficient since reading such data does not require synchronization between threads. Use tls_alloc to create a new thread local storage slot. The slot is allocated for every thread in the current process, including threads that are not yet created. Every thread local storage slot may accept an optional destructor function, which will be called to clean up the thread local object when one thread with one non-zero thread local value on the specified slot is exiting. The TLS destructor function works only for threads created by new_thread on Windows. tls_alloc returns one opaque_t -typed handle, which will be used to get the pointer stored in the thread local storage by tls_get , and set the pointer stored in the thread local storage by tls_set . The stored pointer will be set to 0 by system before it is set by the user for the first time on one particular thread. tls_free frees one thread local storage slot allocated by tls_alloc . Note that freeing one TLS slot will not call destructors registered by tls_alloc , so make sure to clean up such resources manually. Signals #include <Luna/Runtime/Signal.hpp> Signal ( ISignal ) is a synchronization object for execution synchronization between threads. Every signal has two states: triggered and untriggered. When one signal is in untriggered state, all threads that wait for the signal will be blocked until the signal is switched to triggered state. When one signal is in triggered state, all threads that wait for the signal will be resumed. One signal can be created by new_signal , the signal is in untriggered state when created. One signal can be monitored by ISignal::wait and ISignal::try_wait , the second form returns false instead of blocking the current thread if the signal is in untriggered state. One signal can be triggered by ISignal::trigger , which transfers the signal to triggered state. One signal can be reset back to untriggered state manually or automatically, which is specified by manual_reset when creating the signal. If manual_reset is true , one ISignal::trigger call will resume all threads waiting for the signal, and the signal stays in triggered state until ISignal::reset is called; if manual_reset is false , every ISignal::trigger call will only resume exact one thread waiting for the signal, and the signal will be reset back to untriggered state automatically. The resuming order of threads waiting for the signal is unspecified in both modes. Mutex #include <Luna/Runtime/Mutex.hpp> Mutex ( IMutex ) is a synchronization object for granting exclusive access of one entity to at most one thread. Every mutex have two states: locked and unlocked. When one mutex is in unlocked state, the first thread that tries to acquire the lock succeeds and transfers the mutex to locked state. When one mutex is in locked state, all other threads that try to acquire the mutex will get blocked until the mutex is released by its owning thread and is transferred to unlocked state. The mutex lock is recursive, acquiring the lock multiple times from the same thread is allowed, but the user should release the lock the same times as she acquires the lock to finally release the lock. One mutex can be created by new_mutex , the mutex is in unlocked state when created. One mutex can be locked by IMutex::wait and IMutex::try_wait , the second form returns false instead of blocking the current thread if failed to acquire the lock. One mutex can be unlocked by IMutex::unlock . The user can use MutexGuard helper object to lock one mutex in one function scope and release it automatically when MutexGuard is expired. Spin lock #include <Luna/Runtime/SpinLock.hpp> A spin lock ( SpinLock or RecursiveSpinLock ) is a light-weight version of IMutex with the following differences: The spin lock is implemented purely in user-mode by C++, while the mutex is implemented by the underlying platform/OS and is usually implemented in kernel-mode as an OS component, which means locking and releasing one spin lock is much faster than locking and releasing one mutex, since the later is usually performed through a system call. The spin lock will never suspend one thread, nor will it yield the time slice of the waiting thread. If one spin lock is already locked, the waiting thread will keep checking (busy-waiting) until it obtains the lock. In the other side, the mutex will usually suspends or yields the current thread if the mutex is already locked to let other threads use the processor. This makes the spin lock suitable for locking the resource for a very short period of time (hundreds or thousands of CPU-cycles), but not suitable if the lock will be obtained for a long time (>100us). Creating one spin lock creation consumes much less memory than creating one mutex (only 4 bytes for non-recursive spin lock). Meanwhile, creating one spin lock does not need to allocate any dynamic memory, just declare and use it, which makes it suitable for embedding into other objects. One spin lock can be acquired by lock and try_lock , and can be released by unlock . Recursive locking from the same thread is supported only by RecursiveSpinLock , not SpinLock . The user can use LockGuard helper object to acquire one spin lock in one function scope and release it automatically when LockGuard is expired. LockGuard works for both SpinLock and RecursiveSpinLock . Semaphore #include <Luna/Runtime/Semaphore.hpp> Semaphore ( ISemaphore ) is a synchronization object which allows at most max_count number of threads to access the same resource. Every semaphore maintains one counter value between 0 and max_count , when the semaphore is acquired by one thread, its counter value is decreased by one; when the semaphore is released by one thread, its counter value is increased by one. If the counter value is 0 when one thread wants to acquire the semaphore, the thread will be blocked until another thread releases the semaphore to increase the counter value. The counter value of one semaphore will never go below 0 . One semaphore can be created by new_semaphore . When creating the semaphore, the user can specify the initial counter value and maximum counter value of the semaphore. One semaphore can be acquired by ISemaphore::wait and ISemaphore::try_wait , the second form returns false instead of blocking the current thread if failed to acquire the semaphore. One semaphore can be released by ISemaphore::release . Read write lock #include <Luna/Runtime/ReadWriteLock.hpp> A read write lock ( IReadWriteLock ) is a special mutex that allows unlimited number of read locks, but only one write lock at the same time. Every read write lock have three states: unlocked, read locked and write locked. When the read write lock is in unlocked state, the user can acquire both read and write lock from the object, which transfers the object into read locked or write locked state. When the read write lock is in read locked state, only read locks can be acquired, which increases the internal read count of the lock. The read locked state will be transferred back to unlocked state when all read locks are released. When the object is in write locked state, neither read lock nor write lock can be acquired. The write locked state will be transferred back to unlocked state when the unique write lock is released. One read write lock can be acquired by new_read_write_lock . The read lock of one read write lock can be acquired by acquire_read and try_acquire_read , and can be released by release_read . The write lock of one read write lock can be acquired by acquire_write and try_acquire_write , and can be released by release_write . try_acquire_read and try_acquire_write return false instead of blocking the current thread if failed to acquire the lock.","title":"Thread and Synchronization Objects"},{"location":"manual/basics/thread_and_synchronization_objects/#thread-and-synchronization-objects","text":"","title":"Thread and Synchronization Objects"},{"location":"manual/basics/thread_and_synchronization_objects/#threads","text":"#include <Luna/Runtime/Thread.hpp> new_thread creates one system-level thread, which is represented by IThread . The user can wait for the thread to exit by calling IThread::wait , and check whether the thread is exited by calling IThread::try_wait . When the last reference to IThread is releasing, the system blocks the current thread until the thread quits. Every thread uses a thread-local variable to record the current thread's handle, which can be retrieved by get_current_thread . The main thread's handle is also recorded and can be retrieved from any thread by get_main_thread . The user can delay the execution of the current thread by calling sleep or fast_sleep , the second function is more accurate and will not suspend the current thread if the time specified is smaller than several milliseconds. The user can call yield_current_thread to yield the remain time slice of the current thread and let OS to schedule other threads. This is useful for reducing CPU cycles if the current thread is waiting for another operation to finish by hardware or another thread.","title":"Threads"},{"location":"manual/basics/thread_and_synchronization_objects/#thread-local-storage-tls","text":"#include <Luna/Runtime/Thread.hpp> Thread local storage is a set of pointer-sized memory slots that contains unique data for every thread. This can be useful to store thread-local data and is efficient since reading such data does not require synchronization between threads. Use tls_alloc to create a new thread local storage slot. The slot is allocated for every thread in the current process, including threads that are not yet created. Every thread local storage slot may accept an optional destructor function, which will be called to clean up the thread local object when one thread with one non-zero thread local value on the specified slot is exiting. The TLS destructor function works only for threads created by new_thread on Windows. tls_alloc returns one opaque_t -typed handle, which will be used to get the pointer stored in the thread local storage by tls_get , and set the pointer stored in the thread local storage by tls_set . The stored pointer will be set to 0 by system before it is set by the user for the first time on one particular thread. tls_free frees one thread local storage slot allocated by tls_alloc . Note that freeing one TLS slot will not call destructors registered by tls_alloc , so make sure to clean up such resources manually.","title":"Thread local storage (TLS)"},{"location":"manual/basics/thread_and_synchronization_objects/#signals","text":"#include <Luna/Runtime/Signal.hpp> Signal ( ISignal ) is a synchronization object for execution synchronization between threads. Every signal has two states: triggered and untriggered. When one signal is in untriggered state, all threads that wait for the signal will be blocked until the signal is switched to triggered state. When one signal is in triggered state, all threads that wait for the signal will be resumed. One signal can be created by new_signal , the signal is in untriggered state when created. One signal can be monitored by ISignal::wait and ISignal::try_wait , the second form returns false instead of blocking the current thread if the signal is in untriggered state. One signal can be triggered by ISignal::trigger , which transfers the signal to triggered state. One signal can be reset back to untriggered state manually or automatically, which is specified by manual_reset when creating the signal. If manual_reset is true , one ISignal::trigger call will resume all threads waiting for the signal, and the signal stays in triggered state until ISignal::reset is called; if manual_reset is false , every ISignal::trigger call will only resume exact one thread waiting for the signal, and the signal will be reset back to untriggered state automatically. The resuming order of threads waiting for the signal is unspecified in both modes.","title":"Signals"},{"location":"manual/basics/thread_and_synchronization_objects/#mutex","text":"#include <Luna/Runtime/Mutex.hpp> Mutex ( IMutex ) is a synchronization object for granting exclusive access of one entity to at most one thread. Every mutex have two states: locked and unlocked. When one mutex is in unlocked state, the first thread that tries to acquire the lock succeeds and transfers the mutex to locked state. When one mutex is in locked state, all other threads that try to acquire the mutex will get blocked until the mutex is released by its owning thread and is transferred to unlocked state. The mutex lock is recursive, acquiring the lock multiple times from the same thread is allowed, but the user should release the lock the same times as she acquires the lock to finally release the lock. One mutex can be created by new_mutex , the mutex is in unlocked state when created. One mutex can be locked by IMutex::wait and IMutex::try_wait , the second form returns false instead of blocking the current thread if failed to acquire the lock. One mutex can be unlocked by IMutex::unlock . The user can use MutexGuard helper object to lock one mutex in one function scope and release it automatically when MutexGuard is expired.","title":"Mutex"},{"location":"manual/basics/thread_and_synchronization_objects/#spin-lock","text":"#include <Luna/Runtime/SpinLock.hpp> A spin lock ( SpinLock or RecursiveSpinLock ) is a light-weight version of IMutex with the following differences: The spin lock is implemented purely in user-mode by C++, while the mutex is implemented by the underlying platform/OS and is usually implemented in kernel-mode as an OS component, which means locking and releasing one spin lock is much faster than locking and releasing one mutex, since the later is usually performed through a system call. The spin lock will never suspend one thread, nor will it yield the time slice of the waiting thread. If one spin lock is already locked, the waiting thread will keep checking (busy-waiting) until it obtains the lock. In the other side, the mutex will usually suspends or yields the current thread if the mutex is already locked to let other threads use the processor. This makes the spin lock suitable for locking the resource for a very short period of time (hundreds or thousands of CPU-cycles), but not suitable if the lock will be obtained for a long time (>100us). Creating one spin lock creation consumes much less memory than creating one mutex (only 4 bytes for non-recursive spin lock). Meanwhile, creating one spin lock does not need to allocate any dynamic memory, just declare and use it, which makes it suitable for embedding into other objects. One spin lock can be acquired by lock and try_lock , and can be released by unlock . Recursive locking from the same thread is supported only by RecursiveSpinLock , not SpinLock . The user can use LockGuard helper object to acquire one spin lock in one function scope and release it automatically when LockGuard is expired. LockGuard works for both SpinLock and RecursiveSpinLock .","title":"Spin lock"},{"location":"manual/basics/thread_and_synchronization_objects/#semaphore","text":"#include <Luna/Runtime/Semaphore.hpp> Semaphore ( ISemaphore ) is a synchronization object which allows at most max_count number of threads to access the same resource. Every semaphore maintains one counter value between 0 and max_count , when the semaphore is acquired by one thread, its counter value is decreased by one; when the semaphore is released by one thread, its counter value is increased by one. If the counter value is 0 when one thread wants to acquire the semaphore, the thread will be blocked until another thread releases the semaphore to increase the counter value. The counter value of one semaphore will never go below 0 . One semaphore can be created by new_semaphore . When creating the semaphore, the user can specify the initial counter value and maximum counter value of the semaphore. One semaphore can be acquired by ISemaphore::wait and ISemaphore::try_wait , the second form returns false instead of blocking the current thread if failed to acquire the semaphore. One semaphore can be released by ISemaphore::release .","title":"Semaphore"},{"location":"manual/basics/thread_and_synchronization_objects/#read-write-lock","text":"#include <Luna/Runtime/ReadWriteLock.hpp> A read write lock ( IReadWriteLock ) is a special mutex that allows unlimited number of read locks, but only one write lock at the same time. Every read write lock have three states: unlocked, read locked and write locked. When the read write lock is in unlocked state, the user can acquire both read and write lock from the object, which transfers the object into read locked or write locked state. When the read write lock is in read locked state, only read locks can be acquired, which increases the internal read count of the lock. The read locked state will be transferred back to unlocked state when all read locks are released. When the object is in write locked state, neither read lock nor write lock can be acquired. The write locked state will be transferred back to unlocked state when the unique write lock is released. One read write lock can be acquired by new_read_write_lock . The read lock of one read write lock can be acquired by acquire_read and try_acquire_read , and can be released by release_read . The write lock of one read write lock can be acquired by acquire_write and try_acquire_write , and can be released by release_write . try_acquire_read and try_acquire_write return false instead of blocking the current thread if failed to acquire the lock.","title":"Read write lock"},{"location":"manual/basics/time/","text":"Time #include <Luna/Runtime/Time.hpp> High-resolution CPU timer All modern CPUs contain high-resolution timers whose values will increase constantly and monotonically after CPU is powered or reset, usually once per several nanoseconds. The value of this timer can be used to measure time interval at a high resolution. Use get_ticks to read the current value of the high-resolution CPU timer. The time value is an u64 integer measured in CPU ticks, which is a platform-dependent small unit. The user can then call get_ticks_per_second to get the number of ticks per second on the current platform, and use this number to convert ticks to seconds. Remember to use f64 instead of f32 when performing high-resolution time calculation measured in seconds., since f32 does not provide enough precision for representing such a tiny value. System time Besides the high-resolution CPU timer, the underlying platform/OS also contains a timer that tracks the system time on the current platform, which can usually be changed by the user. Unlike CPU time, the system time is affected by the time zone and daylight saving time (DST) settings on the platform, so requires additional care when we're handling it. In Luna SDK, the system time is represented by a i64 UNIX timestamp (number of seconds from Jan 1st, 1970, UTC). The user can call get_local_timestamp to get the current system time shifted by the time zone and DST settings on the current platform, or call get_utc_timestamp to get the current system time in UTC. The local and UTC timestamp can be converted to each other by local_timestamp_to_utc_timestamp and utc_timestamp_to_local_timestamp . To convert one timestamp to one calendar form, the user can call timestamp_to_datetime , which returns one DateTime structure that contains the year, month, day, hour, minute, second and day of week of the timestamp. The user can also call datetime_to_timestamp to convert one DateTime to its corresponding timestamp.","title":"Time"},{"location":"manual/basics/time/#time","text":"#include <Luna/Runtime/Time.hpp>","title":"Time"},{"location":"manual/basics/time/#high-resolution-cpu-timer","text":"All modern CPUs contain high-resolution timers whose values will increase constantly and monotonically after CPU is powered or reset, usually once per several nanoseconds. The value of this timer can be used to measure time interval at a high resolution. Use get_ticks to read the current value of the high-resolution CPU timer. The time value is an u64 integer measured in CPU ticks, which is a platform-dependent small unit. The user can then call get_ticks_per_second to get the number of ticks per second on the current platform, and use this number to convert ticks to seconds. Remember to use f64 instead of f32 when performing high-resolution time calculation measured in seconds., since f32 does not provide enough precision for representing such a tiny value.","title":"High-resolution CPU timer"},{"location":"manual/basics/time/#system-time","text":"Besides the high-resolution CPU timer, the underlying platform/OS also contains a timer that tracks the system time on the current platform, which can usually be changed by the user. Unlike CPU time, the system time is affected by the time zone and daylight saving time (DST) settings on the platform, so requires additional care when we're handling it. In Luna SDK, the system time is represented by a i64 UNIX timestamp (number of seconds from Jan 1st, 1970, UTC). The user can call get_local_timestamp to get the current system time shifted by the time zone and DST settings on the current platform, or call get_utc_timestamp to get the current system time in UTC. The local and UTC timestamp can be converted to each other by local_timestamp_to_utc_timestamp and utc_timestamp_to_local_timestamp . To convert one timestamp to one calendar form, the user can call timestamp_to_datetime , which returns one DateTime structure that contains the year, month, day, hour, minute, second and day of week of the timestamp. The user can also call datetime_to_timestamp to convert one DateTime to its corresponding timestamp.","title":"System time"},{"location":"manual/basics/type_system/","text":"Type system Type reflection is the ability of a program to introspect type name, size, layout and other information in the program. Such ability can be used to write code that can operate on different types. Luna SDK comes with a run-time type reflection system that tracks most types used in the framework, it can also be extended to accept user-defined new types, including enumeration types, structure types and generic structure types. Type object #include <Luna/Runtime/TypeInfo.hpp> typeinfo_t represents one type object that stores the type information for one type registered to type reflection system. You can get the type object of one specified type by calling typeof<T>() . If the specified type is not registered, the program may fail to compile or nullptr will be returned. Type name and GUID #include <Luna/Runtime/Reflection.hpp> Every registered type can be identified by name or by GUID, you can get one type object from its name by calling get_type_by_name , and from its GUID by calling get_type_by_guid . The name and GUID of one type object can be fetched by calling get_type_name and get_type_guid . Every type must have one unique GUID, but multiple types may have the same name. If multiple types have the same name, each of them should have one unique alias so that it can be differed from others. If the type is defined in namespaces, its namespace should be appended before the type name, separated by double colons ( :: ). Type size and alignment #include <Luna/Runtime/Reflection.hpp> Every registered type except generic structure type will have one specific size and alignment value, which can be fetched by get_type_size and get_type_alignment . Generic structure type is not a real type and will return 0 for both functions. Type class #include <Luna/Runtime/Reflection.hpp> There are different type classes in Luna SDK, including: Primitive type Structure type Enumeration type Generic structure type Generic structure instanced type Every registered type in Luna SDK belong to one type class. You can use is_primitive_type , is_struct_type , is_enum_type , is_generic_struct_type and is_generic_struct_instanced_type to check the class of one typeinfo_t object. Primitive type Primitive types are predefined simple types, including void , u8 , i8 , u16 , i16 , u32 , i32 , u64 , i64 , usize , isize , c8 , c16 , c32 , f32 , f64 and bool . void is a special type with size and alignment equal to 0 , and is mainly used as type parameters of generic types. Primitive types cannot be registered by users. Structure type Structure types are used to represent a set of data of different types. Structure types may have properties (member objects), they can also define special functions called meta functions to let Luna SDK handle these types correctly. If such meta function is not provided, Luna SDK will use the default meta function for the type. The following table lists all meta functions provided for one structure type T . Meta function Usage Default meta function Constructor Constructs one object of type T . Calls constructors for all properties of T . Destructor Destructs one object of type T . Calls destructors for all properties of T . Copy constructor Constructs one object of type T by coping data from another object of type T . Calls copy constructors for all properties of T . Move constructor Constructs one object of type T by moving data from another object of type T . Calls move constructors for all properties of T . Copy assignment operator Assigns data of one object of type T by coping data from another object of type T . Calls copy assignment operator for all properties of T . Move assignment operator Assigns data of one object of type T by moving data from another object of type T . Calls move assignment operator for all properties of T . Note that once the user-defined meta function is provided, the corresponding default meta function will not be called. Structure inheritance One structure type can inherit from another structure type. The structure type being inherited from is called base type or base structure , and the structure type derived from the base type is called derived type or derived structure . Every structure type can only have at most one base type, but may have multiple derived types. Enumeration type An enumeration type defines a group of options. Every enumeration have one integral underlying type, and every option of the enumeration is mapped to one specific value of that underlying type. Different options in the same enumeration must have different mapped values. Luna SDK supports multiple enumeration type , which enables the user to select multiple options instead of only one as the value of the enumeration. In such case, every option will take one bit of the underlying integral type, and the enumeration value is stored by bitwise OR combination of selected options. Generic structure type and generic structure instanced type Generic structure type represents one structure type with generic type parameters, such as Vector<T> . The number of generic type parameters can be uncertain, like Tuple<T1, T2, ...> . Generic structure types cannot be used directly, they must be instantiated to a generic structure instanced type by calling get_generic_instanced_type . The generic instantiation process is happened at run time, every generic instanced type with one particular set of generic structure type and generic type parameters will be instantiated only once, and the instantiated type will be reused. One generic structure instanced type can be used just as one normal structure type. Registering structure type #include <Luna/Runtime/Reflection.hpp> There are two methods to register one structure type. The first method is simpler and can be used for most cases, the second method is non-intrusive can be used if the structure is defined in another module or third-party library and cannot be changed directly. The first method The first method is to insert one lustruct macro in your structure definition, specifying the name and GUID of the structure. struct SpotLight { lustruct(\"SpotLight\", \"{2BB45396-E0E3-433E-8794-49BEE8BD1BB5}\"); Float3 intensity = { 0.5f, 0.5f, 0.5f }; f32 intensity_multiplier = 1.0f; f32 attenuation_power = 1.0f; f32 spot_power = 64.0f; }; Then you can call register_struct_type<T> to register the type. The properties of the type can be specified quickly using luproperty macro: register_struct_type<SpotLight>({ luproperty(SpotLight, Float3, intensity), luproperty(SpotLight, f32, intensity_multiplier), luproperty(SpotLight, f32, attenuation_power), luproperty(SpotLight, f32, spot_power) }); If the structure type has base type, the base type should be specified as the second argument, after the property list. The second method In the second method, the user should fill one StructureTypeDesc structure, then call register_struct_type to register the type. For example, the following code registers Name type into the system. StructureTypeDesc desc; desc.guid = Guid(\"{E5EEA2C6-2D51-4658-9B3F-C141DDE983D8}\"); desc.name = \"Name\"; desc.alias = \"\"; desc.size = sizeof(Name); desc.alignment = alignof(Name); desc.base_type = nullptr; desc.ctor = nullptr; desc.dtor = default_dtor<Name>; desc.copy_ctor = default_copy_ctor<Name>; desc.move_ctor = default_move_ctor<Name>; desc.copy_assign = default_copy_assign<Name>; desc.move_assign = default_move_assign<Name>; desc.trivially_relocatable = true; typeinfo_t type = register_struct_type(desc); After the type is registered, the user should also implement typeof_t<T> structure for the type like so: // In .hpp file: LUNA_MYMODULE_API typeinfo_t get_my_type(); template <> struct typeof_t<MyType> { typeinfo_t operator()() const { return get_my_type(); } }; // In .cpp file: typeinfo_t g_my_type; LUNA_XXX_API typeinfo_t get_my_type() { return g_my_type; } Registering enumeration type #include <Luna/Runtime/Reflection.hpp> The user can use register_enum_type function and luoption macro to register one enumeration type. For example, if we have the following type: enum class CameraType : u32 { perspective = 0, orthographic = 1, }; The registration code will be: register_enum_type<CameraType>({ luoption(CameraType, perspective), luoption(CameraType, orthographic) }); Since enumeration types cannot include static variables, the GUID of the enumeration type must be declared separately using luenum like so: luenum(CameraType, \"CameraType\", \"{920C8F7F-7CEC-4776-BF01-1F63A4C51D9F}\"); luenum must be defined directly in Luna namespace, not the sub-namespace of Luna namespace. Registering generic structure type #include <Luna/Runtime/Reflection.hpp> Generic structure type is not actually a real type, but a type generator for generic structure instance types. To register one generic structure type, the user should fill one GenericStructureTypeDesc structure, and call register_generic_struct_type to register the generic structure type. The most important property of GenericStructureTypeDesc is instantiate , which is a callback function that generates one generic structure instance type based on type arguments provided: GenericStructureInstantiateInfo instantiate(typeinfo_t generic_type, const typeinfo_t* generic_arguments, usize num_generic_arguments) This function should returns one GenericStructureInstantiateInfo structure, which is similar to StructureTypeDesc and describes one generic structure instanced type. The generic structure instanced type is then registered to the system can will be returned by get_generic_instanced_type . The instantiation function never fails, if the instantiation function cannot handle the input type arguments, it should call lupanic_msg to crash the program. The base generic structure type and all its instanced types will have the same name and GUID, but each of them will have a unique typeinfo_t handle. You can get the type arguments of one generic structure instanced type by calling count_struct_generic_arguments and get_struct_generic_argument . Implementing typeof_t<T> for generic structure types The user can implement typeof_t<T> using C++ partial template specification like so: LUNA_RUNTIME_API typeinfo_t vector_type(); // Returns the generic structure type. template <typename _Ty> struct typeof_t<Vector<_Ty>> { typeinfo_t operator()() const { return get_generic_instanced_type(vector_type(), { typeof<_Ty>() }); } // Returns the generic structure instanced type. };","title":"Type System"},{"location":"manual/basics/type_system/#type-system","text":"Type reflection is the ability of a program to introspect type name, size, layout and other information in the program. Such ability can be used to write code that can operate on different types. Luna SDK comes with a run-time type reflection system that tracks most types used in the framework, it can also be extended to accept user-defined new types, including enumeration types, structure types and generic structure types.","title":"Type system"},{"location":"manual/basics/type_system/#type-object","text":"#include <Luna/Runtime/TypeInfo.hpp> typeinfo_t represents one type object that stores the type information for one type registered to type reflection system. You can get the type object of one specified type by calling typeof<T>() . If the specified type is not registered, the program may fail to compile or nullptr will be returned.","title":"Type object"},{"location":"manual/basics/type_system/#type-name-and-guid","text":"#include <Luna/Runtime/Reflection.hpp> Every registered type can be identified by name or by GUID, you can get one type object from its name by calling get_type_by_name , and from its GUID by calling get_type_by_guid . The name and GUID of one type object can be fetched by calling get_type_name and get_type_guid . Every type must have one unique GUID, but multiple types may have the same name. If multiple types have the same name, each of them should have one unique alias so that it can be differed from others. If the type is defined in namespaces, its namespace should be appended before the type name, separated by double colons ( :: ).","title":"Type name and GUID"},{"location":"manual/basics/type_system/#type-size-and-alignment","text":"#include <Luna/Runtime/Reflection.hpp> Every registered type except generic structure type will have one specific size and alignment value, which can be fetched by get_type_size and get_type_alignment . Generic structure type is not a real type and will return 0 for both functions.","title":"Type size and alignment"},{"location":"manual/basics/type_system/#type-class","text":"#include <Luna/Runtime/Reflection.hpp> There are different type classes in Luna SDK, including: Primitive type Structure type Enumeration type Generic structure type Generic structure instanced type Every registered type in Luna SDK belong to one type class. You can use is_primitive_type , is_struct_type , is_enum_type , is_generic_struct_type and is_generic_struct_instanced_type to check the class of one typeinfo_t object.","title":"Type class"},{"location":"manual/basics/type_system/#primitive-type","text":"Primitive types are predefined simple types, including void , u8 , i8 , u16 , i16 , u32 , i32 , u64 , i64 , usize , isize , c8 , c16 , c32 , f32 , f64 and bool . void is a special type with size and alignment equal to 0 , and is mainly used as type parameters of generic types. Primitive types cannot be registered by users.","title":"Primitive type"},{"location":"manual/basics/type_system/#structure-type","text":"Structure types are used to represent a set of data of different types. Structure types may have properties (member objects), they can also define special functions called meta functions to let Luna SDK handle these types correctly. If such meta function is not provided, Luna SDK will use the default meta function for the type. The following table lists all meta functions provided for one structure type T . Meta function Usage Default meta function Constructor Constructs one object of type T . Calls constructors for all properties of T . Destructor Destructs one object of type T . Calls destructors for all properties of T . Copy constructor Constructs one object of type T by coping data from another object of type T . Calls copy constructors for all properties of T . Move constructor Constructs one object of type T by moving data from another object of type T . Calls move constructors for all properties of T . Copy assignment operator Assigns data of one object of type T by coping data from another object of type T . Calls copy assignment operator for all properties of T . Move assignment operator Assigns data of one object of type T by moving data from another object of type T . Calls move assignment operator for all properties of T . Note that once the user-defined meta function is provided, the corresponding default meta function will not be called.","title":"Structure type"},{"location":"manual/basics/type_system/#structure-inheritance","text":"One structure type can inherit from another structure type. The structure type being inherited from is called base type or base structure , and the structure type derived from the base type is called derived type or derived structure . Every structure type can only have at most one base type, but may have multiple derived types.","title":"Structure inheritance"},{"location":"manual/basics/type_system/#enumeration-type","text":"An enumeration type defines a group of options. Every enumeration have one integral underlying type, and every option of the enumeration is mapped to one specific value of that underlying type. Different options in the same enumeration must have different mapped values. Luna SDK supports multiple enumeration type , which enables the user to select multiple options instead of only one as the value of the enumeration. In such case, every option will take one bit of the underlying integral type, and the enumeration value is stored by bitwise OR combination of selected options.","title":"Enumeration type"},{"location":"manual/basics/type_system/#generic-structure-type-and-generic-structure-instanced-type","text":"Generic structure type represents one structure type with generic type parameters, such as Vector<T> . The number of generic type parameters can be uncertain, like Tuple<T1, T2, ...> . Generic structure types cannot be used directly, they must be instantiated to a generic structure instanced type by calling get_generic_instanced_type . The generic instantiation process is happened at run time, every generic instanced type with one particular set of generic structure type and generic type parameters will be instantiated only once, and the instantiated type will be reused. One generic structure instanced type can be used just as one normal structure type.","title":"Generic structure type and generic structure instanced type"},{"location":"manual/basics/type_system/#registering-structure-type","text":"#include <Luna/Runtime/Reflection.hpp> There are two methods to register one structure type. The first method is simpler and can be used for most cases, the second method is non-intrusive can be used if the structure is defined in another module or third-party library and cannot be changed directly.","title":"Registering structure type"},{"location":"manual/basics/type_system/#the-first-method","text":"The first method is to insert one lustruct macro in your structure definition, specifying the name and GUID of the structure. struct SpotLight { lustruct(\"SpotLight\", \"{2BB45396-E0E3-433E-8794-49BEE8BD1BB5}\"); Float3 intensity = { 0.5f, 0.5f, 0.5f }; f32 intensity_multiplier = 1.0f; f32 attenuation_power = 1.0f; f32 spot_power = 64.0f; }; Then you can call register_struct_type<T> to register the type. The properties of the type can be specified quickly using luproperty macro: register_struct_type<SpotLight>({ luproperty(SpotLight, Float3, intensity), luproperty(SpotLight, f32, intensity_multiplier), luproperty(SpotLight, f32, attenuation_power), luproperty(SpotLight, f32, spot_power) }); If the structure type has base type, the base type should be specified as the second argument, after the property list.","title":"The first method"},{"location":"manual/basics/type_system/#the-second-method","text":"In the second method, the user should fill one StructureTypeDesc structure, then call register_struct_type to register the type. For example, the following code registers Name type into the system. StructureTypeDesc desc; desc.guid = Guid(\"{E5EEA2C6-2D51-4658-9B3F-C141DDE983D8}\"); desc.name = \"Name\"; desc.alias = \"\"; desc.size = sizeof(Name); desc.alignment = alignof(Name); desc.base_type = nullptr; desc.ctor = nullptr; desc.dtor = default_dtor<Name>; desc.copy_ctor = default_copy_ctor<Name>; desc.move_ctor = default_move_ctor<Name>; desc.copy_assign = default_copy_assign<Name>; desc.move_assign = default_move_assign<Name>; desc.trivially_relocatable = true; typeinfo_t type = register_struct_type(desc); After the type is registered, the user should also implement typeof_t<T> structure for the type like so: // In .hpp file: LUNA_MYMODULE_API typeinfo_t get_my_type(); template <> struct typeof_t<MyType> { typeinfo_t operator()() const { return get_my_type(); } }; // In .cpp file: typeinfo_t g_my_type; LUNA_XXX_API typeinfo_t get_my_type() { return g_my_type; }","title":"The second method"},{"location":"manual/basics/type_system/#registering-enumeration-type","text":"#include <Luna/Runtime/Reflection.hpp> The user can use register_enum_type function and luoption macro to register one enumeration type. For example, if we have the following type: enum class CameraType : u32 { perspective = 0, orthographic = 1, }; The registration code will be: register_enum_type<CameraType>({ luoption(CameraType, perspective), luoption(CameraType, orthographic) }); Since enumeration types cannot include static variables, the GUID of the enumeration type must be declared separately using luenum like so: luenum(CameraType, \"CameraType\", \"{920C8F7F-7CEC-4776-BF01-1F63A4C51D9F}\"); luenum must be defined directly in Luna namespace, not the sub-namespace of Luna namespace.","title":"Registering enumeration type"},{"location":"manual/basics/type_system/#registering-generic-structure-type","text":"#include <Luna/Runtime/Reflection.hpp> Generic structure type is not actually a real type, but a type generator for generic structure instance types. To register one generic structure type, the user should fill one GenericStructureTypeDesc structure, and call register_generic_struct_type to register the generic structure type. The most important property of GenericStructureTypeDesc is instantiate , which is a callback function that generates one generic structure instance type based on type arguments provided: GenericStructureInstantiateInfo instantiate(typeinfo_t generic_type, const typeinfo_t* generic_arguments, usize num_generic_arguments) This function should returns one GenericStructureInstantiateInfo structure, which is similar to StructureTypeDesc and describes one generic structure instanced type. The generic structure instanced type is then registered to the system can will be returned by get_generic_instanced_type . The instantiation function never fails, if the instantiation function cannot handle the input type arguments, it should call lupanic_msg to crash the program. The base generic structure type and all its instanced types will have the same name and GUID, but each of them will have a unique typeinfo_t handle. You can get the type arguments of one generic structure instanced type by calling count_struct_generic_arguments and get_struct_generic_argument .","title":"Registering generic structure type"},{"location":"manual/basics/type_system/#implementing-typeof_tt-for-generic-structure-types","text":"The user can implement typeof_t<T> using C++ partial template specification like so: LUNA_RUNTIME_API typeinfo_t vector_type(); // Returns the generic structure type. template <typename _Ty> struct typeof_t<Vector<_Ty>> { typeinfo_t operator()() const { return get_generic_instanced_type(vector_type(), { typeof<_Ty>() }); } // Returns the generic structure instanced type. };","title":"Implementing typeof_t&lt;T&gt; for generic structure types"},{"location":"manual/basics/variants/","text":"Variants #include <Luna/Runtime/Variant.hpp> Variant is a dynamic typed object that stores data in a schema-less (self-described) manner. Variant is used as a general way of representing data for purposes like serialization and deserialization . Variant type The type of one Variant is represented by VariantType enumeration and can be fetched by calling type method. Luna SDK supports the following variant types: Null Number String Boolean BLOB Pointer Array of variants Associated array of variants Null variant Variant can be null , which represents the absence of value for the variant object. Calling type of one null variant returns VariantType::null , and calling valid of one null variant returns false . Number variant Number variant contains one number of integer or floating-point type. The number type of one number variant is represented by VariantNumberType enumeration and can be fetched by calling number_type method. If the variant object is not a number type, NumberType::not_number will be returned. The number value of the variant can be fetched by calling unum , inum and fnum methods, each of them returns the underlying number in specified format with implicit type conversion when needed. If the variant type is not VariantType::number , 0 or 0.0 will be returned. One variant can be set to number by assigning it with one integer or floating-point value or instance. String variant String variant contains one single string represented by a Name object. You can fetch the underlying string of one variant by calling str() method, which returns one empty string if the type of the variant is not VariantType::string . We also provide c_str method to fetch the string buffer quickly, which will return \"\" if the variant is not VariantType::string . One variant can be set to string by assigning it with one Name instance, one String instance, one string literal, or one zero-terminated c8* pointer instance. Boolean variant Boolean variant contains only two kinds of values: true and false . The Boolean value of one variant can be fetched by calling boolean method, which returns false if the variant is not VariantType::boolean . One variant can be set to Boolean by assigning it with one bool value or instance. BLOB Variant BLOB variant contains one single binary large object. The data, size and alignment of the data can be fetched by calling blob_data , blob_size and blob_alignment methods. Note that Variant does optimizations for small blob data, so the blob data is not necessary represented by Blob . You may detach the blob data from the variant by calling blob_detach , which returns the blob data as a Blob object, and the variant will contain one empty blob after this operation. One variant can be set to pointer by assigning it with one Blob value or instance. Pointer Variant Pointer variant contains one type-less user pointer. The pointer is stored as-is and can be fetched by calling pointer method, which returns nullptr if the variant is not VariantType::pointer . One variant can be set to pointer by assigning it with one pointer value or instance. Array of variants Array variant contains one array of Variant objects, which acts as sub-objects of the current object. Note that Variant does optimizations for small array, so the array data is not necessary represented by Vector<Variant> . Associated array of variants Associated array variant contains one set of Variant objects, which acts as sub-objects of the current object. Unlike array variants, objects in associated array variant are indexed by Name objects, and does not have a particular order. Note that Variant does optimizations for small array, so the array data is not necessary represented by HashMap<Name, Variant> . For both array variants and associated array variants, size method returns the number of sub-objects in the array, and empty method returns true if size() returns 0 . The user can use subscript syntaxes ( [] ) to fetch elements in array variants ( [N] ) and associated array variants ( [\"Name\"] ), if the specified element does not exist, one null variant will be returned. Using subscript syntaxes for variants with incorrect types always return null objects. Variant differential #include <Luna/Runtime/VariantDiff.hpp> Luna SDK comes with one variant differential library that computes and patches variant differences. diff_variant calculates the difference between before and after variant objects, and returns the difference as another variant object called diff object. patch_variant_diff applies diff object to before variant object to reproduce after object, and reverse_variant_diff removes the diff object from after object to reproduce before object. These functions are useful for implementing data versioning and undo/redo operations. JSON encoding #include <Luna/Runtime/VariantJSON.hpp> Luna SDK comes with one JSON encoding/decoding library for Variant objects. json_write encodes one Variant to one JSON text stream, while json_read decodes one JSON text stream to one Variant object. When performing JSON encoding, Variant of VariantType::pointer will be ignored, and Variant with VariantType::blob will be encoded using Base64 encoding format.","title":"Variants"},{"location":"manual/basics/variants/#variants","text":"#include <Luna/Runtime/Variant.hpp> Variant is a dynamic typed object that stores data in a schema-less (self-described) manner. Variant is used as a general way of representing data for purposes like serialization and deserialization .","title":"Variants"},{"location":"manual/basics/variants/#variant-type","text":"The type of one Variant is represented by VariantType enumeration and can be fetched by calling type method. Luna SDK supports the following variant types: Null Number String Boolean BLOB Pointer Array of variants Associated array of variants","title":"Variant type"},{"location":"manual/basics/variants/#null-variant","text":"Variant can be null , which represents the absence of value for the variant object. Calling type of one null variant returns VariantType::null , and calling valid of one null variant returns false .","title":"Null variant"},{"location":"manual/basics/variants/#number-variant","text":"Number variant contains one number of integer or floating-point type. The number type of one number variant is represented by VariantNumberType enumeration and can be fetched by calling number_type method. If the variant object is not a number type, NumberType::not_number will be returned. The number value of the variant can be fetched by calling unum , inum and fnum methods, each of them returns the underlying number in specified format with implicit type conversion when needed. If the variant type is not VariantType::number , 0 or 0.0 will be returned. One variant can be set to number by assigning it with one integer or floating-point value or instance.","title":"Number variant"},{"location":"manual/basics/variants/#string-variant","text":"String variant contains one single string represented by a Name object. You can fetch the underlying string of one variant by calling str() method, which returns one empty string if the type of the variant is not VariantType::string . We also provide c_str method to fetch the string buffer quickly, which will return \"\" if the variant is not VariantType::string . One variant can be set to string by assigning it with one Name instance, one String instance, one string literal, or one zero-terminated c8* pointer instance.","title":"String variant"},{"location":"manual/basics/variants/#boolean-variant","text":"Boolean variant contains only two kinds of values: true and false . The Boolean value of one variant can be fetched by calling boolean method, which returns false if the variant is not VariantType::boolean . One variant can be set to Boolean by assigning it with one bool value or instance.","title":"Boolean variant"},{"location":"manual/basics/variants/#blob-variant","text":"BLOB variant contains one single binary large object. The data, size and alignment of the data can be fetched by calling blob_data , blob_size and blob_alignment methods. Note that Variant does optimizations for small blob data, so the blob data is not necessary represented by Blob . You may detach the blob data from the variant by calling blob_detach , which returns the blob data as a Blob object, and the variant will contain one empty blob after this operation. One variant can be set to pointer by assigning it with one Blob value or instance.","title":"BLOB Variant"},{"location":"manual/basics/variants/#pointer-variant","text":"Pointer variant contains one type-less user pointer. The pointer is stored as-is and can be fetched by calling pointer method, which returns nullptr if the variant is not VariantType::pointer . One variant can be set to pointer by assigning it with one pointer value or instance.","title":"Pointer Variant"},{"location":"manual/basics/variants/#array-of-variants","text":"Array variant contains one array of Variant objects, which acts as sub-objects of the current object. Note that Variant does optimizations for small array, so the array data is not necessary represented by Vector<Variant> .","title":"Array of variants"},{"location":"manual/basics/variants/#associated-array-of-variants","text":"Associated array variant contains one set of Variant objects, which acts as sub-objects of the current object. Unlike array variants, objects in associated array variant are indexed by Name objects, and does not have a particular order. Note that Variant does optimizations for small array, so the array data is not necessary represented by HashMap<Name, Variant> . For both array variants and associated array variants, size method returns the number of sub-objects in the array, and empty method returns true if size() returns 0 . The user can use subscript syntaxes ( [] ) to fetch elements in array variants ( [N] ) and associated array variants ( [\"Name\"] ), if the specified element does not exist, one null variant will be returned. Using subscript syntaxes for variants with incorrect types always return null objects.","title":"Associated array of variants"},{"location":"manual/basics/variants/#variant-differential","text":"#include <Luna/Runtime/VariantDiff.hpp> Luna SDK comes with one variant differential library that computes and patches variant differences. diff_variant calculates the difference between before and after variant objects, and returns the difference as another variant object called diff object. patch_variant_diff applies diff object to before variant object to reproduce after object, and reverse_variant_diff removes the diff object from after object to reproduce before object. These functions are useful for implementing data versioning and undo/redo operations.","title":"Variant differential"},{"location":"manual/basics/variants/#json-encoding","text":"#include <Luna/Runtime/VariantJSON.hpp> Luna SDK comes with one JSON encoding/decoding library for Variant objects. json_write encodes one Variant to one JSON text stream, while json_read decodes one JSON text stream to one Variant object. When performing JSON encoding, Variant of VariantType::pointer will be ignored, and Variant with VariantType::blob will be encoded using Base64 encoding format.","title":"JSON encoding"},{"location":"manual/introduction/","text":"Introduction Thanks for using Luna SDK. This user manual provides a comprehensive explanation of every aspect of Luna SDK, and is served for your reference. If you are completely new to Luna SDK, we suggest you to follow the step-by-step Getting Started tutorial for a quick boot. Then you should read the Basics chapter for a deeper understanding of the basic usage of Luna SDK. Other chapters in this manual does not have a particular dependency, you can read these chapters in any order, and in any time you want.","title":"Introduction"},{"location":"manual/introduction/#introduction","text":"Thanks for using Luna SDK. This user manual provides a comprehensive explanation of every aspect of Luna SDK, and is served for your reference. If you are completely new to Luna SDK, we suggest you to follow the step-by-step Getting Started tutorial for a quick boot. Then you should read the Basics chapter for a deeper understanding of the basic usage of Luna SDK. Other chapters in this manual does not have a particular dependency, you can read these chapters in any order, and in any time you want.","title":"Introduction"},{"location":"manual/introduction/getting_started/","text":"Getting Started Welcome to Luna SDK. In this article, we will guide you to Luna SDK by creating a simple program that draws one textured 3D cube on the screen. At the end of this article, you will have a basic understanding of using Luna SDK to create a simple graphic program, and can start to explore more advanced features provided by Luna SDK. The source code of this article can be downloaded here: DemoApp.zip Prerequisites In this article, we assume that you have the basic knowledge of C++ programming and graphics programming (like using D3D11, D3D12 or OpenGL). You should also correctly setup Luna SDK and developing environments using the instructions provided in README.md of the project. Creating the program The first thing to do is to create an binary target for our demo program, so that XMake build system can correctly build our program. To create a new program, create a new folder in the {LUNA_ROOT_DIR}/Programs directory, and name it DemoApp . In this folder, create a new Lua script file called xmake.lua , and fill its content with the following text: target(\"DemoApp\") set_luna_sdk_program() add_files(\"**.cpp\") add_deps(\"Runtime\", \"Window\", \"RHI\", \"ShaderCompiler\", \"Image\") target_end() target and target_end enclose a target scope , where all target definitions are specified. set_luna_sdk_program tells XMake that we are defining one Luna SDK program, this will let XMake set the target kind to \"binary\" and import all SDK options for the program. add_files(\"**.cpp\") tells XMake to add all CPP files in the current directory and all subdirectories to the this target. add_deps lists all libraries that this program links to, in our example, we need to link to the SDK runtime ( Runtime ), the window module ( Window ) , the Graphics API module ( RHI ), the shader compiler module ( ShaderCompiler ) and the image file module ( Image ). If you got unresolved external symbol errors when compiling, make sure you already link correct libraries. Then we need to create source CPP files for our program. Since out demo program is simple, we only create one \"main.cpp\" file to host all source codes. After this, the DemoApp directory should looks like this: DemoApp |- xmake.lua |- main.cpp The last thing is to add one line in the end of {LUNA_ROOT_DIR}/Programs/xmake.lua to tell XMake to add our program in the solution: includes(\"DemoApp\") Well done, now every is set up and we can start to program our first Luna SDK program! Program structure Next, fills main.cpp with the following initial content. As we go further, we will add more properties and methods to our DemoApp structure, while remaining the rest part unchanged. #include <Luna/Runtime/Runtime.hpp> #include <Luna/Runtime/Module.hpp> #include <Luna/Runtime/Log.hpp> #include <Luna/Runtime/UniquePtr.hpp> using namespace Luna; struct DemoApp { RV init(); RV update(); bool is_exiting(); }; RV DemoApp::init() { return ok; } RV DemoApp::update() { return ok; } bool DemoApp::is_closed() { return false; } RV run_app() { auto result = init_modules(); if(failed(result)) return result; UniquePtr<DemoApp> app (memnew<DemoApp>()); result = app->init(); if(failed(result)) return result; while(!app->is_exiting()) { result = app->update(); if(failed(result)) return result; } return ok; } int main() { bool initialized = Luna::init(); if(!initialized) return -1; RV result = run_app(); if(failed(result)) log_error(\"DemoApp\", \"%s\", explain(result.errcode())); Luna::close(); return 0; } The first four lines includes the header files that we need to include to compile the program, which are: * for Luna::init() and Luna::shutdown() . * for Luna::init_modules() . * for Luna::log_error() . * for Luna::UniquePtr<T> . You can include any SDK interface header files using similar syntax: #include <Luna/Module/File> . We set {LUNA_ROOT_DIR}/Engine as the global include directory, the user may check it for available header files. In this example, all header files are from the Runtime module, which is the core module of Luna SDK that provides fundamental SDK features. The next statement is using namespace Luna . In Luna SDK, all types, functions and variables are defined in Luna namespace, and every module will define its elements in nested namespace, such as Luna::RHI . So, we use this statement to prevent spelling the Luna:: namespace prefix in our following code. The program starts with the main function, just like any normal C/C++ program. In the main function, we firstly call Luna::init to initialize Luna SDK. This function should be called before any other Luna SDK function. Luna::init returns one Boolean value to indicate whether the SDK initialization is succeeded, if the return value is false , we then return -1 and exit the program to indicate one runtime error. If Luna::init returns true , then one Luna::close call is need before the program exit to let the SDK clean up all internal resources. We then wrap the real program logic in one run_app function. The return type of run_app is RV , which is a shortcut for R<void> , this is part of the error handling mechanism of Luna SDK. R<T> is a structure that encapsulates one return value with type T and one error code with type ErrCode , which is simply an alias of usize (or std::size_t ). If the function succeeds, the returned value will be one T -typed value and one error code 0 ; if the function fails, the returned value will be one non-zero error code, and the T -typed value will be uninitialized and inaccessible, you may call errcode() to fetch the error code from R<T> , and may call explain to get a brief description of the error. In our main function, we check whether our run_app function is failed by using failed helper function (there is also one succeeded helper function available), then we print the error description and exits the program if any error occurs. In our run_app function, the first thing to do is calling init_modules , which will initialize all linked SDK modules for our program. We deliberately separate module initialization from Luna::init so that the user get a chance to set module initialization parameters before initializing modules, and modules can also indicate initialization failure by returning error codes (error handling system is available after Luna::init ). Then, we allocate and initialize one new object of DemoApp type by calling memnew function. The following table shows memory allocation functions used in Luna SDK: Luna SDK functions C++ functions/keywords memalloc(size, alignment) malloc(size) memfree(ptr, alignment) free(ptr) memrealloc(ptr, size, alignment) realloc(ptr, size) memsize(size, alignment) N/A memnew<T>(args...) new T (args...) memdelete(ptr) delete ptr The user should uses allocation functions provided by Luna SDK instead of those provided by C++ std. DemoApp will contain all states and logics for our demo program. The created DempApp instance will then be stored as a variable app with UniquePtr<DemoApp> type, which is a smart pointer that will delete the pointing object automatically when expired. DemoApp has three functions: init , update and is_closed . The init function initializes the program, and reports errors if the initialization is failed; the update function updates the program state and renders the image at every frame; the is_exiting function checks whether the program is exiting. We will implement these three methods in the following sections. The rest part of our run_app function simply checks whether the program is exiting by calling is_exiting , and updates the program when it is not exiting. After filling this content, execute xmake build DemoApp on terminal or click build button on your IDE, you should successfully build the DemoApp program. Window creation and event handling Now that we have one basic program structure, we need to create a system window so that we can render images to it. We also need to implement window event handling so that the program can exit when the user clicks the close button of the window. Window creation is fairly simple, we firstly need to introduce one new header: #include <Luna/Window/Window.hpp> then we add one new property to our DemoApp structure: struct DemoApp { Ref<Window::IWindow> window; RV init(); RV update(); bool is_exiting(); RV resize(u32 width, u32 height); }; The window object is provided by Window::IWindow* interface pointer in Luna SDK, which points to a boxed object which manages its lifetime using reference counting . IWindow interface may have different implementations on different platforms, by they all provide the same functionality required by this interface. Ref<T> is a smart pointer for boxed objects, it will manage the reference counter of the pointing object automatically when being constructed and destructed, so the user does not need to call object_retain and object_release manually. You may compare Ref<T> to ComPtr used in Microsoft's Component-Object Model (COM), or the automatic reference counting in Apple's Objective-C and Swift. The default constructor of Ref<T> initializes the pointer to nullptr , so we need to assign it with a valid object. Then we need to create our window in DemoApp::init : RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); } lucatch { return lures; } return ok; } Besides the new_window function that creates the window, there are four new keywords in our code: lutry , lucatch , luset and lures . These four keywords are macros that enables us to write error handling using a simpler try-catch style, rather than fetching and checking error codes once and once again for every function call that may fail. lutry and lucatch must be used in pairs, next to each other. In the lutry block, the user may define multiple lulet , luset or luexp statements, lulet statement creates a new local variable to hold the return value of the function, and jumps to lucatch if the function fails; luset assigns the return value to one existing variable, and jumps to lucatch if the function fails; luexp is used if the function does not return any value, it simply checks whether the function succeeds, and jumps to lucatch if not. The user may also call luthrow manually in lutry block to jump to lucatch directly. In the lucatch block, lures is provided as the error code that causes the failure. You may use one switch statement on the lures to handle specific errors, or you can propagate the error directly to parent function by return lures . Since error propagating is so commonly used, we create another macro lucatchret to replace lucatch { return lures; } , so the code above can be written as: RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); } lucatchret; return ok; } Since we use goto statement to implement lutry and lucatch , it you needs multiple lutry-lucatch pairs in one function, you should use a numbered version for every pair (like lutry2 , lucatch2 , luset 2, lures2 , etc.). In most cases, only one lutry-lucatch pair is sufficient. Now let's get back to Window::new_window function that does the actual work: R<Ref<IWindow>> new_window(const c8* title, const WindowDisplaySettings& display_settings, WindowCreationFlag flags) In this function, title Specifies the title of the window, which is usually displayed on the title bar of the window. flags are a combination of WindowCreationFlag enumeration class that lists flags for window creation process, like whether the window is resizable by dragging the border of the window, whether the window is a border-less window, etc. display_settings specifies the display settings for the window, which is described by WindowDisplaySettings structre: struct WindowDisplaySettings { monitor_t monitor; i32 x; i32 y; u32 width; u32 height; u32 refresh_rate; bool full_screen; }; Every window can be displayed in windowed mode or full screen mode, which can be specified by full_screen . monitor specifies the monitor to attach the window to in full screen mode. If monitor is nullptr and the window is set to full screen mode, the primary monitor of the system will be used. x and y are the position of the window on screen coordinates in windowed mode. The user may pass DEFAULT_POS constant to indicate a system-specific default position for the window. width and height are used to control the size of the window, the user can pass 0 to indicate a system-specific default size. refresh_rate controls the refresh rate of the window, the user may pass 0 to use the default refresh rate of the system. WindowDisplaySettings comes with two static functions as_windowed and as_full_screen for quickly specify all parameters in one row, with default values specified when they are skipped by the user, just as in our example. After the window is created, we need to register window event callbacks so that we can handle window events properly. In this example, the events we need to handle is the close event (triggered when the close button of the window is pressed) and the framebuffer resize event (triggered when the window framebuffer size is changed). This can be done by the following statements: window->get_close_event().add_handler([](Window::IWindow* window) { window->close(); }); window->get_framebuffer_resize_event().add_handler([this](Window::IWindow* window, u32 width, u32 height) { lupanic_if_failed(this->resize(width, height)); }); get_close_event and get_framebuffer_resize_event are methods of IWindow that gets the close event and the framebuffer resize event object of the window. The event object is a collection of callback functions that once triggered, calls all the callback functions. We then register one callback function to the close event that closes the window immediately, and one callback function to the framebuffer resize event that calls the resize method of our DempApp . The resize method is currently empty, we will fill the content of this method when we create render textures later: RV DemoApp::resize(u32 width, u32 height) { return ok; } Window events are not polled automatically, we need to tell the window system to poll events at every frame by calling Window::poll_events in update function: RV DemoApp::update() { Window::poll_events(); return ok; } This call polls events for all existing windows, so we don't need to provide specific window here. After we correctly handle the close event, we can complete the is_closed method of DemoApp : bool DemoApp::is_exiting() { return window->is_closed(); } So far, the complete code for main.cpp is: #include <Luna/Runtime/Runtime.hpp> #include <Luna/Runtime/Module.hpp> #include <Luna/Runtime/Log.hpp> #include <Luna/Runtime/UniquePtr.hpp> #include <Luna/Window/Window.hpp> using namespace Luna; struct DemoApp { Ref<Window::IWindow> window; RV init(); RV update(); bool is_exiting(); RV resize(u32 width, u32 height); }; RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); window->get_close_event().add_handler([](Window::IWindow* window) { window->close(); }); window->get_framebuffer_resize_event().add_handler([this](Window::IWindow* window, u32 width, u32 height) { lupanic_if_failed(this->resize(width, height)); }); } lucatchret; return ok; } RV DemoApp::update() { Window::poll_events(); return ok; } bool DemoApp::is_exiting() { return window->is_closed(); } RV DemoApp::resize(u32 width, u32 height) { return ok; } RV run_app() { auto result = init_modules(); if(failed(result)) return result; UniquePtr<DemoApp> app (memnew<DemoApp>()); result = app->init(); if(failed(result)) return result; while(!app->is_exiting()) { result = app->update(); if(failed(result)) return result; } return ok; } int main() { bool initialized = Luna::init(); if(!initialized) return -1; RV result = run_app(); if(failed(result)) log_error(\"DemoApp\", \"%s\", explain(result.errcode())); Luna::close(); return 0; } Build and run DemoApp , and you will see a blank window appears, and the program exits when you click the close button of the window. Fetching graphics device After the window is created, we can start drawing our box. Luna SDK provides all rendering features through RHI module, which is the abbreviation of Rendering Hardware Interface . To use RHI module, we need to include its header first: #include <Luna/RHI/RHI.hpp> In Luna SDK, all graphics resources are related to one specific graphics device represented by RHI::IDevice , which is the virtual representation of the physical graphics device on the platform, so we need to add one property to DemoApp to hold this device: Ref<RHI::IDevice> dev; When RHI module initializes, it automatically chooses the most suitable physical device and creates one IDevice instance for you, which can be fetched by RHI::get_main_device() . You may also create additional devices for special use, but in our DemoApp , we will stick to the default one by adding the following line in the lutry scope of DemoApp::init : dev = RHI::get_main_device(); We can also import all RHI types and functions by using namespace RHI; so that we don't need to spell them all over the init function: using namespace RHI; The code of DemoApp::init should look similar to: RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); window->get_close_event().add_handler([](Window::IWindow* window) { window->close(); }); window->get_framebuffer_resize_event().add_handler([this](Window::IWindow* window, u32 width, u32 height) { lupanic_if_failed(this->resize(width, height)); }); dev = RHI::get_main_device(); using namespace RHI; // New resource creation code goes here... } lucatchret; return ok; } Unless explicitly specified, all codes we need to add to DemoApp::init in the following sections are added to the end of lutry scope, not in the end of the function scope directly. Fetching command queue and creating command buffer Luna SDK employs deferred execution model , where render and compute invocations are recorded as commands in command buffers , then submitted to GPU explicitly by submitting command buffers to command queues . The command buffer object manages memory allocated to store commands, it also tracks the execution state for commands in the buffer when the buffer is submitted for execution. The command queue is a FIFO message queue between the host program and GPU. The host program submits command buffers to the command queue, and GPU consumes command buffers from the queue and execute commands in the buffer. Command buffers in the same queue are guaranteed to execute one after another, the next command buffer will not be executed until the last command buffer is finished. When IDevice initializes, it creates one or multiple command queues based on the physical device architecture and limitation. The user can use IDevice::get_num_command_queues to fetch the number of command queues present on the current device, and use IDevice::get_command_queue_desc to fetch the command queue description of each command queue. get_command_queue_desc returns one CommandQueueDesc structure, which is defined as follows: struct CommandQueueDesc { CommandQueueType type; CommandQueueFlag flags; }; CommandQueueType indicates the type of the command queue. There are three different queue types: graphics , compute and copy . The copy queue only accepts copy commands, and is used for transferring data between different resources; the compute queue accepts copy and compute tasks, while the graphics queue accepts graphics, compute and copy commands. CommandQueueFlag indicates additional properties for the queue, including CommandQueueFlag::presenting , which indicates one command queue that supports swap chain presenting. In our program, we need to choose one command queue of graphics type, and has CommandQueueFlag::presenting flag present. We firstly need to add one property to DemoApp to store the command queue index we choose: u32 queue; Then the command queue can be fetched by adding the following codes to DemoApp::init : queue = U32_MAX; u32 num_queues = dev->get_num_command_queues(); for (u32 i = 0; i < num_queues; ++i) { auto desc = dev->get_command_queue_desc(i); if (desc.type == CommandQueueType::graphics && test_flags(desc.flags, CommandQueueFlag::presenting)) { queue = i; break; } } if(queue == U32_MAX) return BasicError::not_supported(); After we fetched the command queue, we need to create one command buffer to record commands that will be submitted to that queue. We firstly need to add one new property to DemoApp to hold the command buffer: Ref<RHI::ICommandBuffer> cmdbuf; Then we can create the command buffer by adding the following codes to DemoApp::init : luset(cmdbuf, dev->new_command_buffer(queue)); When we create the command buffer, we should pass the index of the command queue that is attached to the command buffer. The created command buffer can only be submitted to the command queue specified when creating the command buffer. Creating swap chain The swap chain object contains resources that are used to present render results to our window. In order to create one swap chain, we firstly need to add one property to DemoApp to store the created swap chain: Ref<RHI::ISwapChain> swap_chain; In Luna SDK, the swap chain presentation is also a command that should be submitted using command queues, so we need to specify the command queue we need to use when creating swap chains like so: luset(swap_chain, dev->new_swap_chain(queue, window, SwapChainDesc(0, 0, 2, Format::bgra8_unorm, true))); The swap chain is described by one SwapChainDesc structure: struct SwapChainDesc { u32 width; u32 height; u32 buffer_count; Format pixel_format; bool vertically_synchronized; }; When used for creating swap chains, you may pass 0 for width and height property, which indicates the system to use the window framebuffer size as the size of the swap chain. The swap chain needs to be resized when the window framebuffer size is changed. This can be done by filling DemoApp::resize method with the following codes: RV DemoApp::resize(u32 width, u32 height) { lutry { using namespace RHI; if(width && height) { auto dev = get_main_device(); luexp(swap_chain->reset({width, height, 2, Format::unknown, true})); } } lucatchret; return ok; } ISwapChain::reset will reset the swap chain according to the new swap chain description, we can use Format::unknown to tell the system to use the current back buffer format for the new back buffer. Note that on some systems, the resize event will be emitted with both width and height being 0 if the window is minimized. We cannot create one swap chain with zero width or height, so we should handle this case and resize the back buffer with only non-zero size values. Creating descriptor set layout and descriptor set The descriptor set object stores descriptors that bind resources to graphics or compute pipeline. Descriptors have the following types: Uniform buffer view, which binds constant global data to shaders. Read buffer view, which binds buffers to shaders and enables load operations on the buffer data. Read texture view, which binds textures to shaders and enables sampling and load operations on the pixel data. Read write buffer view, which binds buffers to shaders and enables load, store and atomic operations on the buffer data. Read write texture view, which binds textures to shaders and enables load, store, and atomic operations on the pixel data. Sampler, which stores sampling settings and exposes those settings for shaders. Every pipeline may bind multiple descriptor sets, every descriptor set may contain all kinds of descriptors listed above. The descriptor set layout object stores the layout of one descriptor set object, including the number of descriptors in the descriptor set and the property of each descriptor. In order to create one descriptor set layout object, we need to fill one DescriptorSetLayoutDesc structure. Here is the definition of DescriptorSetLayoutDesc structure: struct DescriptorSetLayoutDesc { Span<const DescriptorSetLayoutBinding> bindings; DescriptorSetLayoutFlag flags = DescriptorSetLayoutFlag::none; }; The descriptor set layout consists of multiple bindings specified by DescriptorSetLayoutBinding , each binding describes one range of the descriptor set: struct DescriptorSetLayoutBinding { DescriptorType type; TextureViewType texture_view_type; u32 binding_slot; u32 num_descs; ShaderVisibilityFlag shader_visibility_flags; }; the type property describes the type of this binding. All descriptors in the same binding must be the same type: enum class DescriptorType : u32 { uniform_buffer_view, read_buffer_view, read_write_buffer_view, read_texture_view, read_write_texture_view, sampler }; the texture_view_type property describes the texture view type that can be set in this binding. This is required only when type of this binding is read_texture_view or read_write_texture_view . All texture views in the same binding must be the same type. binding_slot and num_descs describes the binding slot range of this binding, starting from 0 . All slots in [binding_slot, binding_slot + num_descs) will be occupied by this binding and cannot be used by other bindings. If num_descs is greater than 1 , then this binding will be interpreted as one descriptor array in the shader. shader_visibility_flags specifies which shaders may access descriptors in this binding, you may restrict the visibility of one binding to one set of specific shaders, which may improve performance on some platforms. We need to add two new properties to DemoApp to hold the descriptor set layout object and the descriptor set object: Ref<RHI::IDescriptorSetLayout> dlayout; Ref<RHI::IDescriptorSet> desc_set; We need 1 descriptor set with 1 constant buffer view, 1 shader resource view and 1 sampler. So we can create our descriptor set layout object in DemoApp::init like so: luset(dlayout, dev->new_descriptor_set_layout(DescriptorSetLayoutDesc({ DescriptorSetLayoutBinding::uniform_buffer_view(0, 1, ShaderVisibilityFlag::vertex), DescriptorSetLayoutBinding::read_texture_view(TextureViewType::tex2d, 1, 1, ShaderVisibilityFlag::pixel), DescriptorSetLayoutBinding::sampler(2, 1, ShaderVisibilityFlag::pixel) }))); Then we can create one descriptor set using the descriptor set layout object: luset(desc_set, dev->new_descriptor_set(DescriptorSetDesc(dlayout))); We will fill descriptors in the set by calling update_descriptors later. Compiling shaders The next thing to do is compiling shaders for the pipeline state object. Luna SDK uses HLSL as the source shader language, and uses ShaderCompiler module to compile HLSL to DXBC, DXIL, SPIR-V and other target shading languages. To compile shader, we need to include corresponding header files: #include <Luna/ShaderCompiler/ShaderCompiler.hpp> #include <Luna/RHI/ShaderCompileHelper.hpp> ShaderCompileHelper.hpp includes RHI::get_current_platform_shader_target_format() function, which tell the shader compiler the native target target shader format for the current graphics API. Since our shader is rather simple, we declare our shader source code directly in the C++ source file, in DemoApp::init function: const char vs_shader_code[] = R\"( cbuffer vertexBuffer : register(b0) { float4x4 world_to_proj; }; struct VS_INPUT { [[vk::location(0)]] float3 position : POSITION; [[vk::location(1)]] float2 texcoord : TEXCOORD; }; struct PS_INPUT { [[vk::location(0)]] float4 position : SV_POSITION; [[vk::location(1)]] float2 texcoord : TEXCOORD; }; PS_INPUT main(VS_INPUT input) { PS_INPUT output; output.position = mul(world_to_proj, float4(input.position, 1.0f)); output.texcoord = input.texcoord; return output; })\"; const char ps_shader_code[] = R\"( Texture2D tex : register(t1); SamplerState tex_sampler : register(s2); struct PS_INPUT { [[vk::location(0)]] float4 position : SV_POSITION; [[vk::location(1)]] float2 texcoord : TEXCOORD; }; [[vk::location(0)]] float4 main(PS_INPUT input) : SV_Target { return float4(tex.Sample(tex_sampler, input.texcoord)); })\"; here we use C++ raw string syntax R\"()\" to declare multiline string without appending \\ for every string line. Note the register number specified in shader must match the binding slot specified in descriptor set layout we just created. Since we use the same slot numbering system for all descriptor types, the register number for b , t , u and s should not overlap. Then we can compile shaders using ShaderCompiler::ICompiler object: auto compiler = ShaderCompiler::new_compiler(); compiler->set_source({ vs_shader_code, strlen(vs_shader_code) }); compiler->set_source_name(\"DemoAppVS\"); compiler->set_entry_point(\"main\"); compiler->set_target_format(RHI::get_current_platform_shader_target_format()); compiler->set_shader_type(ShaderCompiler::ShaderType::vertex); compiler->set_shader_model(6, 0); compiler->set_optimization_level(ShaderCompiler::OptimizationLevel::full); luexp(compiler->compile()); auto vs_data = compiler->get_output(); Blob vs(vs_data.data(), vs_data.size()); compiler->reset(); compiler->set_source({ ps_shader_code, strlen(ps_shader_code) }); compiler->set_source_name(\"DemoAppPS\"); compiler->set_entry_point(\"main\"); compiler->set_target_format(RHI::get_current_platform_shader_target_format()); compiler->set_shader_type(ShaderCompiler::ShaderType::pixel); compiler->set_shader_model(6, 0); compiler->set_optimization_level(ShaderCompiler::OptimizationLevel::full); luexp(compiler->compile()); auto ps_data = compiler->get_output(); Blob ps(ps_data.data(), ps_data.size()); The shader compilation process is fairly simple, we just set source code, compilation settings, then triggers the compilation. The compilation result will be given by get_output , we use one Blob object , a container for binary data, to hold the compilation result. The compiled shader data will be used when creating pipeline state object later. Creating pipeline layout and pipeline state The graphics and compute pipeline state is described by two objects: pipeline layout object and pipeline state object. Pipeline layout object stores the shader binding layout information for all shader stages, while pipeline state object stores pipeline settings for all graphics stages. Pipeline layout is described by the PipelineLayoutDesc structure, which is configured by specifying layouts of descriptor sets that will be bound to this pipeline and flags that specifies shaders that are allowed to access shader inputs. struct PipelineLayoutDesc { Span<IDescriptorSetLayout*> descriptor_set_layouts; PipelineLayoutFlag flags; }; We need to add one new property to DemoApp to hold the pipeline layout object: Ref<RHI::IPipelineLayout> playout; Then we can create pipeline layout object using the following code: luset(playout, dev->new_pipeline_layout(PipelineLayoutDesc({dlayout}, PipelineLayoutFlag::allow_input_assembler_input_layout))); The pipeline object is described by the GraphicsPipelineStateDesc structure or the ComputePipelineStateDesc structure. Since we are creating one graphics pipeline, we need to fill the GraphicsPipelineStateDesc structure, which is a complex structure that contains all pipeline settings for one graphics pipeline: struct GraphicsPipelineStateDesc { InputLayoutDesc input_layout; IPipelineLayout* pipeline_layout = nullptr; Span<const byte_t> vs; Span<const byte_t> ps; RasterizerDesc rasterizer_state; DepthStencilDesc depth_stencil_state; BlendDesc blend_state; IndexBufferStripCutValue ib_strip_cut_value = IndexBufferStripCutValue::disabled; PrimitiveTopology primitive_topology = PrimitiveTopology::triangle_list; u8 num_color_attachments = 0; Format color_formats[8] = { Format::unknown }; Format depth_stencil_format = Format::unknown; u32 sample_count = 1; u32 sample_mask = 0xFFFFFFFF; }; Most graphic settings are similar to those in D3D11, D3D12, OpenGL or Vulkan, we will not explain these settings, but only gives the code that correctly sets every setting of the pipeline. You can see docs for RHI module for detailed explanations of these settings. We need to add one new property to DemoApp to hold the pipeline state object: Ref<RHI::IPipelineState> pso; Then we can create pipeline state object using the following code: GraphicsPipelineStateDesc ps_desc; ps_desc.primitive_topology = PrimitiveTopology::triangle_list; ps_desc.sample_mask = U32_MAX; ps_desc.rasterizer_state = RasterizerDesc(); ps_desc.depth_stencil_state = DepthStencilDesc(true, true, CompareFunction::less_equal); ps_desc.ib_strip_cut_value = IndexBufferStripCutValue::disabled; InputAttributeDesc input_attributes[] = { InputAttributeDesc(\"POSITION\", 0, 0, 0, 0, Format::rgb32_float), InputAttributeDesc(\"TEXCOORD\", 0, 1, 0, 12, Format::rg32_float) }; InputBindingDesc input_bindings[] = { InputBindingDesc(0, 20, InputRate::per_vertex) }; ps_desc.input_layout.attributes = {input_attributes, 2}; ps_desc.input_layout.bindings = {input_bindings, 1}; ps_desc.vs = vs.cspan(); ps_desc.ps = ps.cspan(); ps_desc.pipeline_layout = playout; ps_desc.num_color_attachments = 1; ps_desc.color_formats[0] = Format::rgba8_unorm; ps_desc.depth_stencil_format = Format::d32_float; luset(pso, dev->new_graphics_pipeline_state(ps_desc)); Creating depth textures The next step is to create one depth texture that is used as the depth stencil attachment when drawing our box. Texture objects in Luna SDK are represented by ITexture interface, and are described by TextureDesc structure, which is defined as follows: struct TextureDesc { TextureType type; Format format; u32 width; u32 height; u32 depth; u32 array_size; u32 mip_levels; u32 sample_count; TextureUsageFlag usages; ResourceFlag flags; } type specifies the type of the texture, like tex1d , tex2d , etc. format specifies the pixel format of the texture. usages specifies all possible usages of the texture when being bound to a pipeline. width , height and depth specifies the size of the texture. array_size specifies the number of texture elements if this texture object represents a texture array, otherwise 1 shall be specified. mip_levels specifies the number of mips that should be allocated for the resource, if this is 0 , the system allocates full mipmap chain for the resource. sample_count specifies the sampling count for MSAA textures. flags specifies additional features for the texture, like whether this texture can share memory with other resources. To simplify the texture description, we can use static methods provided by TextureDesc to quickly construct TextureDesc structure: TextureDesc TextureDesc::tex1d(Format format, TextureUsageFlag usages, u64 width, u32 array_size = 1, u32 mip_levels = 0, ResourceFlag flags = ResourceFlag::none); TextureDesc TextureDesc::tex2d(Format format, TextureUsageFlag usages, u64 width, u32 height, u32 array_size = 1, u32 mip_levels = 0, u32 sample_count = 1, ResourceFlag flags = ResourceFlag::none); TextureDesc TextureDesc::tex3d(Format format, TextureUsageFlag usages, u64 width, u32 height, u32 depth, u32 mip_levels = 0, ResourceFlag flags = ResourceFlag::none); Back to our DemoApp , we need to add one new property to DemoApp to hold the depth texture: Ref<RHI::ITexture> depth_tex; Then we can create textures using the following code: auto window_size = window->get_framebuffer_size(); luset(depth_tex, dev->new_texture(MemoryType::local, TextureDesc::tex2d(Format::d32_float, TextureUsageFlag::depth_stencil_attachment, window_size.x, window_size.y, 1, 1))); The first parameter of new_texture is the memory type of texture memory. The memory type is defined by MemoryType enumeration, possible options include: local - The memory can only be accessed by GPU, CPU access is disabled. This memory type is suitable for resources that will be frequently accessed by GPU. upload - The memory can be written by CPU and read by GPU. This memory type is suitable for resources that should be updated by CPU frequently. Textures cannot be created in this heap. readback - The memory can be written by GPU and read by CPU. This memory type is suitable for transferring data from GPU to CPU. Textures cannot be created in this heap. Note that when retrieving window size for rendering, we need to call IWindow::get_framebuffer_size instead of IWindow::get_size , on some platforms the window size is not necessary measured in pixels, causing these two methods return different values. Since we are using the window size as the depth texture size, the depth texture should also be recreated when the window size is changed. This can be done by adding the following code to the DemoApp::resize method: luset(depth_tex, dev->new_texture(MemoryType::local, TextureDesc::tex2d(Format::d32_float, TextureUsageFlag::depth_stencil_attachment, width, height, 1, 1))); Creating buffers and uploading buffer data The next step is to create buffers used in our DemoApp , including: The vertex buffer and index buffer for our box mesh. The uniform buffer for camera properties. Firstly we need to define the vertex structure of our box. Adding the following code after the declaration of DemoApp structure: struct Vertex { Float3U position; Float2U texcoord; }; Float2U and Float3U are vector types used in Luna SDK, which represent 2D and 3D vectors. In Luna SDK, we have 16-bytes aligned vector types Float2 , Float3 , Float4 , and unaligned vector types Float2U , Float3U and Float4U . The aligned vector types are used for calculations, SIMD functions like min , max , lerp , clamp only accepts aligned types, while unaligned vector types are used for storing and transferring data, just like this case. The size of aligned vector types are all 16 bytes, while the size of unaligned types are 8, 12 and 16 for Float2U , Float3U and Float4U . We need to add three new properties to DemoApp to hold the these three buffers: Ref<RHI::IBuffer> vb; Ref<RHI::IBuffer> ib; Ref<RHI::IBuffer> ub; As you can see, buffer objects are represented by IBuffer interface. Both IBuffer and ITexture interface inherits from IResource interface, which provides one method to fetch the underlying memory of the resource. Fetching the underlying memory enables the user to create aliasing resources that share the same memory, which is an advanced feature that will not be covered in this article. One buffer resource is described by BufferDesc structure, which is defined as follows: struct BufferDesc { u64 size; BufferUsageFlag usages; ResourceFlag flags; } BufferDesc is rather simple compared to TextureDesc . size specifies the size of the buffer, usages specifies all possible usages of the buffer when being bound to the pipeline, and flags specifies additional features of the buffer, like whether this buffer can share memory with other resources. Then, we need to create the vertex buffer and index buffer for our box using the following code: Vertex vertices[] = { {{+0.5, -0.5, -0.5}, {0.0, 1.0}}, {{+0.5, +0.5, -0.5}, {0.0, 0.0}}, {{+0.5, +0.5, +0.5}, {1.0, 0.0}}, {{+0.5, -0.5, +0.5}, {1.0, 1.0}}, {{+0.5, -0.5, +0.5}, {0.0, 1.0}}, {{+0.5, +0.5, +0.5}, {0.0, 0.0}}, {{-0.5, +0.5, +0.5}, {1.0, 0.0}}, {{-0.5, -0.5, +0.5}, {1.0, 1.0}}, {{-0.5, -0.5, +0.5}, {0.0, 1.0}}, {{-0.5, +0.5, +0.5}, {0.0, 0.0}}, {{-0.5, +0.5, -0.5}, {1.0, 0.0}}, {{-0.5, -0.5, -0.5}, {1.0, 1.0}}, {{-0.5, -0.5, -0.5}, {0.0, 1.0}}, {{-0.5, +0.5, -0.5}, {0.0, 0.0}}, {{+0.5, +0.5, -0.5}, {1.0, 0.0}}, {{+0.5, -0.5, -0.5}, {1.0, 1.0}}, {{-0.5, +0.5, -0.5}, {0.0, 1.0}}, {{-0.5, +0.5, +0.5}, {0.0, 0.0}}, {{+0.5, +0.5, +0.5}, {1.0, 0.0}}, {{+0.5, +0.5, -0.5}, {1.0, 1.0}}, {{+0.5, -0.5, -0.5}, {0.0, 1.0}}, {{+0.5, -0.5, +0.5}, {0.0, 0.0}}, {{-0.5, -0.5, +0.5}, {1.0, 0.0}}, {{-0.5, -0.5, -0.5}, {1.0, 1.0}} }; u32 indices[] = { 0, 1, 2, 0, 2, 3, 4, 5, 6, 4, 6, 7, 8, 9, 10, 8, 10, 11, 12, 13, 14, 12, 14, 15, 16, 17, 18, 16, 18, 19, 20, 21, 22, 20, 22, 23 }; luset(vb, dev->new_buffer(MemoryType::local, BufferDesc(BufferUsageFlag::vertex_buffer | BufferUsageFlag::copy_dest, sizeof(vertices)))); luset(ib, dev->new_buffer(MemoryType::local, BufferDesc(BufferUsageFlag::index_buffer | BufferUsageFlag::copy_dest, sizeof(indices)))); We firstly define vertex and index data for our box, then we create two buffer resources to hold the vertex and index data. One buffer is created by calling IDevice::new_buffer , which is similar to IDevice::new_texture , but takes BufferDesc as the resource descriptor object. Since we only need to upload vertex and index buffer data once, these two buffers are created in local memory to achieve maximum GPU bandwidth. We can use similar code to create the constant buffer for uploading camera properties, but there are two differences. First, the graphic device has alignment requirements for constant buffers, which can be fetched from IDevice::get_uniform_buffer_data_alignment() , so we use align_upper helper function to adjust the size of our uniform buffer resource to meet the alignment requirement. Second, since we need to update uniform buffer data once every frame, we should choose upload memory type instead of local to give host program direct access to that resource. In our DemoApp , the data of the uniform buffer is the 4x4 world-to-project matrix of the camera. We need to add a new include file to use matrix types: #include <Luna/Runtime/Math/Matrix.hpp> then we can use the following code to create constant buffer: auto ub_align = dev->get_uniform_buffer_data_alignment(); luset(ub, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::uniform_buffer, align_upper(sizeof(Float4x4), ub_align)))); as you can see, Float4x4 is the matrix type used in Luna SDK. We also have Float3x3 for 2D affine transformations. Uploading vertex and index data Now that we have created one vertex buffer and one index buffer, we need to upload vertex and index data to these buffers, so that they can be used by GPU correctly. As we have mentioned before, resources with local memory type can not be accessed by the host directly. To copy data between local memory and host memory, we can either use staging buffers to transfer the data manually, or we can use RHI::copy_resource_data to perform data copy automatically. We will show how to perform data copy in both approaches. Uploading data manually In order to upload data to resources with local memory type, we need to create intermediate buffers with upload memory type, copy data to such buffers form the host, and use GPU to copy data from such buffers to resources with local memory type. Such intermediate buffers are usually called staging buffers , and are used frequently to copy data from host memory to device local memory. The following code shows how to upload data for our vertex and index buffer: lulet(vb_staging, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::copy_source, sizeof(vertices)))); lulet(ib_staging, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::copy_source, sizeof(indices)))); void* vb_mapped = nullptr; luexp(vb_staging->map(0, 0, &vb_mapped)); memcpy(vb_mapped, vertices, sizeof(vertices)); vb_staging->unmap(0, sizeof(vertices)); void* ib_mapped = nullptr; luexp(ib_staging->map(0, 0, &ib_mapped)); memcpy(ib_mapped, indices, sizeof(indices)); ib_staging->unmap(0, sizeof(indices)); cmdbuf->begin_copy_pass(); cmdbuf->resource_barrier({ BufferBarrier(vb, BufferStateFlag::automatic, BufferStateFlag::copy_dest), BufferBarrier(vb_staging, BufferStateFlag::automatic, BufferStateFlag::copy_source), BufferBarrier(ib, BufferStateFlag::automatic, BufferStateFlag::copy_dest), BufferBarrier(ib_staging, BufferStateFlag::automatic, BufferStateFlag::copy_source), }, {}); cmdbuf->copy_buffer(vb, 0, vb_staging, 0, sizeof(vertices)); cmdbuf->copy_buffer(ib, 0, ib_staging, 0, sizeof(indices)); cmdbuf->end_copy_pass(); cmdbuf->submit({}, {}, true); cmdbuf->wait(); cmdbuf->reset(); Firstly, we create two staging buffers vb_staging and ib_staging . These two buffers have the same size as vb and ib and use upload memory type, so they can be written by the host directly. Then, we use IBuffer::map to take pointers to the buffer memory, use memcpy to copy data to the memory, then use IBuffer::unmap to release the host access to the memory. map takes two integer parameters indicating the host reading range of the mapped memory, this should always be 0 if the memory type of the buffer is not readback , just like this case. unmap takes another two integer parameters indicating the host writing range of the mapped memory. in our case, we have written memory in [0, sizeof(data)) range, so we should specify the range correctly. There is a special range [0, USIZE_MAX) that indicates the whole buffer memory is read or written, so we don't need to specify the size explicitly. After we copy data to staging buffers, we need to tell GPU to copy data from staging buffers to GPU local resources. As we have mentioned before, to send commands to GPU, we need to record commands into command buffers, submit them to command queues, then waits for command buffers to be finished by GPU. The first command we need to record is ICommandBuffer::begin_copy_pass , which tells GPU to start a copy pass. This is required because all copy commands like copy_buffer , copy_texture etc. can only be recorded in a copy pass scope. Similarly, we have render passes for render commands, and compute passes for compute commands. After beginning the copy pass, we need to emit resource barriers to transfer resources used by GPU to compatible states. Resource barrier commands are recorded by ICommandBuffer::resource_barrier , and will be described later. After resources have been transferred into suitable states, we call ICommandBuffer::copy_buffer to record one buffer-to-buffer copy command. Finally, we call ICommandBuffer::end_copy_pass to end the copy pass we opened before. When we finish recording commands into the command buffer, we call ICommandBuffer::submit to submit the command buffer to the command queue, call ICommandBuffer::wait to wait for the command buffer to be finished, then call ICommandBuffer::reset to clear commands in the command buffer, and reset the command buffer state so that it can be used for a recording new commands. Uploading data using RHI::copy_resource_data In order to use RHI::copy_resource_data , we need to include one new header file: #include <Luna/RHI/Utility.hpp> RHI/Utility.hpp is an auxiliary library that defines high-level functionalities implemented using APIs provided by RHI , including RHI::copy_resource_data we use here. The following code shows how to upload data using RHI::copy_resource_data : luexp(copy_resource_data(cmdbuf, { CopyResourceData::write_buffer(vb, 0, vertices, sizeof(vertices)), CopyResourceData::write_buffer(ib, 0, indices, sizeof(indices)) })); You can see how RHI::copy_resource_data greatly simplifies the code we need to write in order to upload resource data. Loading image from file The next step is to load our Luna LOGO image that will be drawn on the box surface: Save the image file in the same directory as main.cpp , and naming it luna.png . You should have one file structure similar to this: DemoApp |- xmake.lua |- main.cpp |- luna.png Then fills xmake.lua with the following code: target(\"DemoApp\") set_luna_sdk_program() add_files(\"**.cpp\") add_deps(\"Runtime\", \"Window\", \"RHI\", \"ShaderCompiler\", \"Image\") before_build(function(target) os.cp(\"$(scriptdir)/luna.png\", target:targetdir() .. \"/luna.png\") end) after_install(function (target) os.cp(target:targetdir() .. \"/luna.png\", target:installdir() .. \"/bin/luna.png\") end) target_end() This script triggers registers custom functions before building the program and after installing the program, the custom function copies the image file to same the directory of our program binary file, so that our program can correctly find the image file. Then, go back to main.cpp , and add one new property to DemoApp to represent the loaded image: Ref<RHI::ITexture> file_tex; To load the image in our program, we need to use one new module called Image , which parses image file data and gives row-majored image data in our desired format. We also need to use the file API provided by Runtime module, so we includes two new headers: #include <Luna/Runtime/File.hpp> #include <Luna/Image/Image.hpp> The first thing to do is to load image file data from our luna.png file. In order to load file data, we need to use the open_file function provided by the Runtime module. This function returns one file handle represented by IFile if the file is correctly opened. Then, we loads the file data into one Blob object by calling load_file_data , this function creates one properly-sized blob object, and calls IFile::read to read all data of the file to the blob, then returns the blob: lulet(image_file, open_file(\"Luna.png\", FileOpenFlag::read, FileCreationMode::open_existing)); lulet(image_file_data, load_file_data(image_file)); Now that the file data has been stored in image_file_data , we need to call Image::read_image_file function to parse the file data and gives the real image data: Image::ImageDesc image_desc; lulet(image_data, Image::read_image_file(image_file_data.data(), image_file_data.size(), Image::ImagePixelFormat::rgba8_unorm, image_desc)); Image::read_image_file function outputs one Image::ImageDesc structure that describes the returned image data, including the width, height and pixel format of the image. The image data is arranged in a row-major manner and without and alignment padding. We can now creates the texture resource based on the image size: luset(file_tex, dev->new_texture(MemoryType::local, TextureDesc::tex2d(Format::rgba8_unorm, TextureUsageFlag::copy_dest | TextureUsageFlag::read_texture, image_desc.width, image_desc.height, 1, 1))); The following code shows how to upload data for our texture: u64 tex_size, tex_row_pitch, tex_slice_pitch; dev->get_texture_data_placement_info(image_desc.width, image_desc.height, 1, Format::rgba8_unorm, &tex_size, nullptr, &tex_row_pitch, &tex_slice_pitch); lulet(file_tex_staging, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::copy_source, tex_size))); void* file_tex_mapped = nullptr; luexp(file_tex_staging->map(0, 0, &file_tex_mapped)); memcpy_bitmap(file_tex_mapped, image_data.data(), image_desc.width * 4, image_desc.height, tex_row_pitch, image_desc.width * 4); file_tex_staging->unmap(0, USIZE_MAX); cmdbuf->begin_copy_pass(); cmdbuf->resource_barrier({ BufferBarrier(file_tex_staging, BufferStateFlag::automatic, BufferStateFlag::copy_source) }, { TextureBarrier(file_tex, TEXTURE_BARRIER_ALL_SUBRESOURCES, TextureStateFlag::automatic, TextureStateFlag::copy_dest) }); cmdbuf->copy_buffer_to_texture(file_tex, SubresourceIndex(0, 0), 0, 0, 0, file_tex_staging, 0, tex_row_pitch, tex_slice_pitch, image_desc.width, image_desc.height, 1); cmdbuf->end_copy_pass(); cmdbuf->submit({}, {}, true); cmdbuf->wait(); cmdbuf->reset(); Uploading texture data is similar to uploading buffer data, we need to create one staging buffer to hold the texture data, then use ICommandBuffer::copy_buffer_to_texture to copy data from buffer to texture. Note that most systems have special alignment requirements for texture data in buffers when copying data between buffers and textures, the user should call IDevice::get_texture_data_placement_info to fetch the texture data placement information for one specific texture, and use that information to manipulate texture data in the buffer. Instead of memcpy , the user should call memcpy_bitmap to copy row-major bitmap data, which takes src_row_pitch and dst_row_pitch to correctly offsets every texture data row. We can also use RHI::copy_resource_data to upload data for textures like so: luexp(copy_resource_data(cmdbuf, { CopyResourceData::write_texture(file_tex, SubresourceIndex(0, 0), 0, 0, 0, image_data.data(), image_desc.width * 4, image_desc.width * image_desc.height * 4, image_desc.width, image_desc.height, 1) })); Set up descriptor set Once the uniform buffer and file texture is set up, we can bind these two resources to the descriptor set by calling IDescriptorSet::update_descriptors . We also need to set the sampler in the descriptor set to be used by the pixel shader. luexp(desc_set->update_descriptors({ WriteDescriptorSet::uniform_buffer_view(0, BufferViewDesc::uniform_buffer(ub)), WriteDescriptorSet::read_texture_view(1, TextureViewDesc::tex2d(file_tex)), WriteDescriptorSet::sampler(2, SamplerDesc(Filter::linear, Filter::linear, Filter::linear, TextureAddressMode::clamp, TextureAddressMode::clamp, TextureAddressMode::clamp)) })); This concludes the DemoApp::init function. Camera control Now that we have created all resources required to draw the box, we need to fill the actual drawing code in DemoApp::update . To make our program more interesting, we can apply one simple animation that rotates the camera around the box. We firstly adds one new property to DemoApp that stores the rotation angle of the camera: f32 camera_rotation = 0.0f; We can increase the rotation angle of the camera by one at every frame by adding the following line to the end of DemoApp:update : camera_rotation += 1.0f; Since we are going to use many functions that may throw errors, it is better to declare one lutry - lucatch scope that wraps all succeeding codes in DemoApp:update . Also, we don't want to render the image if the window is closed or minimized, so we add two early-out conditions after Window::poll_events() . Now DemoApp::update should look like this: RV DemoApp::update() { Window::poll_events(); if(window->is_closed()) return ok; if(window->is_minimized()) return ok; lutry { camera_rotation += 1.0f; // More codes goes here... } lucatchret; return ok; } After we updates the camera rotation, we need to calculate the view-projection matrix for the camera. Fortunately, the math library of the Runtime module already includes implementations for many commonly used vector and matrix calculations, and here we are going to use two of them: AffineMatrix::make_look_at and ProjectionMatrix::make_perspective_fov . To use these two functions, we firstly need to add one new header file: #include <Luna/Runtime/Math/Transform.hpp> Then the matrix can be computed using the following code: Float3 camera_pos(cosf(camera_rotation / 180.0f * PI) * 3.0f, 1.0f, sinf(camera_rotation / 180.0f * PI) * 3.0f); Float4x4 camera_mat = AffineMatrix::make_look_at(camera_pos, Float3(0, 0, 0), Float3(0, 1, 0)); auto window_sz = window->get_framebuffer_size(); camera_mat = mul(camera_mat, ProjectionMatrix::make_perspective_fov(PI / 3.0f, (f32)window_sz.x / (f32)window_sz.y, 0.001f, 100.0f)); AffineMatrix::make_look_at generates one camera view matrix from the position of the camera and the position of the point to look at. ProjectionMatrix::make_perspective_fov is another helper function that generates one projection matrix from the specified field-of-view and aspect ratio values. Those two matrices are multiplied by mul function to get the final view-projection matrix. Note that when performing matrix multiplications, use mul instead of operator * , the later one is used to multiply each element in the matrix separately. After we get the matrix, we need to copy the matrix data to the uniform buffer resource like so: void* camera_mapped; luexp(ub->map(0, 0, &camera_mapped)); memcpy(camera_mapped, &camera_mat, sizeof(Float4x4)); ub->unmap(0, sizeof(Float4x4)); Fetching the back buffer In order to render contents to one window, we need to fetch back buffers managed by the window swap chain. The number of back buffers that are contained by a swap chain is determined by SwapChainDesc::buffer_count , which can be set when the swap chain is created or reset. At every frame, only one back buffer can be used for rendering, which can be fetched by calling ISwapChain::get_current_back_buffer : lulet(back_buffer, swap_chain->get_current_back_buffer()); ISwapChain::get_current_back_buffer can be called multiple times during the same frame, and will return the same back buffer. The current back buffer will be switched when ISwapChain::present is called, the user should not use the back buffer in the previous frame after ISwapChain::present is called. Resource barriers In Luna SDK, every graphic resource has one state that describes the current memory layout and pipeline access polity of the resource. Before we can issue draw calls, we need to transfer every resource we use to their correct states. Luna SDK requires the user to transfer the state explicitly by calling ICommandBuffer::resource_barrier with transition-typed resource barriers. In our example, we need to perform the following transitions: cmdbuf->resource_barrier({ BufferBarrier(ub, BufferStateFlag::automatic, BufferStateFlag::uniform_buffer_vs), BufferBarrier(vb, BufferStateFlag::automatic, BufferStateFlag::vertex_buffer), BufferBarrier(ib, BufferStateFlag::automatic, BufferStateFlag::index_buffer) }, { TextureBarrier(file_tex, TEXTURE_BARRIER_ALL_SUBRESOURCES, TextureStateFlag::automatic, TextureStateFlag::shader_read_ps), TextureBarrier(back_buffer, SubresourceIndex(0, 0), TextureStateFlag::automatic, TextureStateFlag::color_attachment_write), TextureBarrier(depth_tex, SubresourceIndex(0, 0), TextureStateFlag::automatic, TextureStateFlag::depth_stencil_attachment_write) }); One resource can have multiple states, so long as such states are compatible to each other. For example, one texture can have TextureStateFlag::shader_read_vs and TextureStateFlag::shader_read_ps at the same time if it will be accessed by both vertex and pixel shader, or can have TextureStateFlag::shader_read_cs and TextureStateFlag::shader_write_cs at the same time if it will be read and write by compute shader. Luna SDK internally tracks the current states for all resources, so we can set before states of resources to automatic in most cases, which tells the system to load the previous states automatically. Luna SDK also omits unnecessary barriers automatically. Drawing the box Finally, we can issue the draw call that draws our box: RenderPassDesc desc; desc.color_attachments[0] = ColorAttachment(back_buffer, LoadOp::clear, StoreOp::store, Float4U(0.0f)); desc.depth_stencil_attachment = DepthStencilAttachment(depth_tex, false, LoadOp::clear, StoreOp::store, 1.0f); cmdbuf->begin_render_pass(desc); cmdbuf->set_graphics_pipeline_layout(playout); cmdbuf->set_graphics_pipeline_state(pso); cmdbuf->set_graphics_descriptor_set(0, desc_set); auto sz = vb->get_desc().size; cmdbuf->set_vertex_buffers(0, {VertexBufferView(vb, 0, sz, sizeof(Vertex))}); sz = ib->get_desc().size; cmdbuf->set_index_buffer(IndexBufferView(ib, 0, sz, Format::r32_uint)); cmdbuf->set_scissor_rect(RectI(0, 0, (i32)window_sz.x, (i32)window_sz.y)); cmdbuf->set_viewport(Viewport(0.0f, 0.0f, (f32)window_sz.x, (f32)window_sz.y, 0.0f, 1.0f)); cmdbuf->draw_indexed(36, 0, 0); cmdbuf->end_render_pass(); The first thing to do is to begin a render pass that attaches one set of color attachments and/or the depth stencil attachment to the graphic pipeline, these textures are bound to the pipeline during the current render pass and cannot be changed, while all other settings (like shader input layout object, pipeline state object, descriptor sets, etc) can be changed within the same render pass. The render pass begins with ICommandBuffer::begin_render_pass . In the render pass, we set up all pipeline settings, and bind all resources required for the current draw call, then calls ICommandBuffer::draw_indexed to issue the draw call based on the current settings. Then we should close the render pass by calling ICommandBuffer::end_render_pass . We won't go detail about the pipeline setup for this draw call, they should be familiar to you if you have been using other graphics API before. For further explanations, please consult the documentations for the RHI module. Before we can submit our command buffer, we need to insert another resource barrier to transfer our back buffer into TextureStateFlag::present state. This is required for one back buffer to be successfully presented. cmdbuf->resource_barrier({}, { TextureBarrier(back_buffer, SubresourceIndex(0, 0), TextureStateFlag::automatic, TextureStateFlag::present) }); Finally, we submit our command buffer, waiting for its completion, and resets the command buffer for next frame: luexp(cmdbuf->submit({}, {}, true)); cmdbuf->wait(); luexp(cmdbuf->reset()); Presenting the render result The last thing we need to do is to present our rendering result to the window. This is done by calling ISwapChain::present : luexp(swap_chain->present()); This concludes the DemoApp::update function. Build and run DemoApp , if everything goes correctly, you will see a textured rotating box in the screen: Congratulations! If you have followed every step of this article correctly, you should have a first impression of graphic programming using Luna SDK. If anything goes wrong, you can download the source code archive from the beginning of this article and compare it with your code.","title":"Getting Started"},{"location":"manual/introduction/getting_started/#getting-started","text":"Welcome to Luna SDK. In this article, we will guide you to Luna SDK by creating a simple program that draws one textured 3D cube on the screen. At the end of this article, you will have a basic understanding of using Luna SDK to create a simple graphic program, and can start to explore more advanced features provided by Luna SDK. The source code of this article can be downloaded here: DemoApp.zip","title":"Getting Started"},{"location":"manual/introduction/getting_started/#prerequisites","text":"In this article, we assume that you have the basic knowledge of C++ programming and graphics programming (like using D3D11, D3D12 or OpenGL). You should also correctly setup Luna SDK and developing environments using the instructions provided in README.md of the project.","title":"Prerequisites"},{"location":"manual/introduction/getting_started/#creating-the-program","text":"The first thing to do is to create an binary target for our demo program, so that XMake build system can correctly build our program. To create a new program, create a new folder in the {LUNA_ROOT_DIR}/Programs directory, and name it DemoApp . In this folder, create a new Lua script file called xmake.lua , and fill its content with the following text: target(\"DemoApp\") set_luna_sdk_program() add_files(\"**.cpp\") add_deps(\"Runtime\", \"Window\", \"RHI\", \"ShaderCompiler\", \"Image\") target_end() target and target_end enclose a target scope , where all target definitions are specified. set_luna_sdk_program tells XMake that we are defining one Luna SDK program, this will let XMake set the target kind to \"binary\" and import all SDK options for the program. add_files(\"**.cpp\") tells XMake to add all CPP files in the current directory and all subdirectories to the this target. add_deps lists all libraries that this program links to, in our example, we need to link to the SDK runtime ( Runtime ), the window module ( Window ) , the Graphics API module ( RHI ), the shader compiler module ( ShaderCompiler ) and the image file module ( Image ). If you got unresolved external symbol errors when compiling, make sure you already link correct libraries. Then we need to create source CPP files for our program. Since out demo program is simple, we only create one \"main.cpp\" file to host all source codes. After this, the DemoApp directory should looks like this: DemoApp |- xmake.lua |- main.cpp The last thing is to add one line in the end of {LUNA_ROOT_DIR}/Programs/xmake.lua to tell XMake to add our program in the solution: includes(\"DemoApp\") Well done, now every is set up and we can start to program our first Luna SDK program!","title":"Creating the program"},{"location":"manual/introduction/getting_started/#program-structure","text":"Next, fills main.cpp with the following initial content. As we go further, we will add more properties and methods to our DemoApp structure, while remaining the rest part unchanged. #include <Luna/Runtime/Runtime.hpp> #include <Luna/Runtime/Module.hpp> #include <Luna/Runtime/Log.hpp> #include <Luna/Runtime/UniquePtr.hpp> using namespace Luna; struct DemoApp { RV init(); RV update(); bool is_exiting(); }; RV DemoApp::init() { return ok; } RV DemoApp::update() { return ok; } bool DemoApp::is_closed() { return false; } RV run_app() { auto result = init_modules(); if(failed(result)) return result; UniquePtr<DemoApp> app (memnew<DemoApp>()); result = app->init(); if(failed(result)) return result; while(!app->is_exiting()) { result = app->update(); if(failed(result)) return result; } return ok; } int main() { bool initialized = Luna::init(); if(!initialized) return -1; RV result = run_app(); if(failed(result)) log_error(\"DemoApp\", \"%s\", explain(result.errcode())); Luna::close(); return 0; } The first four lines includes the header files that we need to include to compile the program, which are: * for Luna::init() and Luna::shutdown() . * for Luna::init_modules() . * for Luna::log_error() . * for Luna::UniquePtr<T> . You can include any SDK interface header files using similar syntax: #include <Luna/Module/File> . We set {LUNA_ROOT_DIR}/Engine as the global include directory, the user may check it for available header files. In this example, all header files are from the Runtime module, which is the core module of Luna SDK that provides fundamental SDK features. The next statement is using namespace Luna . In Luna SDK, all types, functions and variables are defined in Luna namespace, and every module will define its elements in nested namespace, such as Luna::RHI . So, we use this statement to prevent spelling the Luna:: namespace prefix in our following code. The program starts with the main function, just like any normal C/C++ program. In the main function, we firstly call Luna::init to initialize Luna SDK. This function should be called before any other Luna SDK function. Luna::init returns one Boolean value to indicate whether the SDK initialization is succeeded, if the return value is false , we then return -1 and exit the program to indicate one runtime error. If Luna::init returns true , then one Luna::close call is need before the program exit to let the SDK clean up all internal resources. We then wrap the real program logic in one run_app function. The return type of run_app is RV , which is a shortcut for R<void> , this is part of the error handling mechanism of Luna SDK. R<T> is a structure that encapsulates one return value with type T and one error code with type ErrCode , which is simply an alias of usize (or std::size_t ). If the function succeeds, the returned value will be one T -typed value and one error code 0 ; if the function fails, the returned value will be one non-zero error code, and the T -typed value will be uninitialized and inaccessible, you may call errcode() to fetch the error code from R<T> , and may call explain to get a brief description of the error. In our main function, we check whether our run_app function is failed by using failed helper function (there is also one succeeded helper function available), then we print the error description and exits the program if any error occurs. In our run_app function, the first thing to do is calling init_modules , which will initialize all linked SDK modules for our program. We deliberately separate module initialization from Luna::init so that the user get a chance to set module initialization parameters before initializing modules, and modules can also indicate initialization failure by returning error codes (error handling system is available after Luna::init ). Then, we allocate and initialize one new object of DemoApp type by calling memnew function. The following table shows memory allocation functions used in Luna SDK: Luna SDK functions C++ functions/keywords memalloc(size, alignment) malloc(size) memfree(ptr, alignment) free(ptr) memrealloc(ptr, size, alignment) realloc(ptr, size) memsize(size, alignment) N/A memnew<T>(args...) new T (args...) memdelete(ptr) delete ptr The user should uses allocation functions provided by Luna SDK instead of those provided by C++ std. DemoApp will contain all states and logics for our demo program. The created DempApp instance will then be stored as a variable app with UniquePtr<DemoApp> type, which is a smart pointer that will delete the pointing object automatically when expired. DemoApp has three functions: init , update and is_closed . The init function initializes the program, and reports errors if the initialization is failed; the update function updates the program state and renders the image at every frame; the is_exiting function checks whether the program is exiting. We will implement these three methods in the following sections. The rest part of our run_app function simply checks whether the program is exiting by calling is_exiting , and updates the program when it is not exiting. After filling this content, execute xmake build DemoApp on terminal or click build button on your IDE, you should successfully build the DemoApp program.","title":"Program structure"},{"location":"manual/introduction/getting_started/#window-creation-and-event-handling","text":"Now that we have one basic program structure, we need to create a system window so that we can render images to it. We also need to implement window event handling so that the program can exit when the user clicks the close button of the window. Window creation is fairly simple, we firstly need to introduce one new header: #include <Luna/Window/Window.hpp> then we add one new property to our DemoApp structure: struct DemoApp { Ref<Window::IWindow> window; RV init(); RV update(); bool is_exiting(); RV resize(u32 width, u32 height); }; The window object is provided by Window::IWindow* interface pointer in Luna SDK, which points to a boxed object which manages its lifetime using reference counting . IWindow interface may have different implementations on different platforms, by they all provide the same functionality required by this interface. Ref<T> is a smart pointer for boxed objects, it will manage the reference counter of the pointing object automatically when being constructed and destructed, so the user does not need to call object_retain and object_release manually. You may compare Ref<T> to ComPtr used in Microsoft's Component-Object Model (COM), or the automatic reference counting in Apple's Objective-C and Swift. The default constructor of Ref<T> initializes the pointer to nullptr , so we need to assign it with a valid object. Then we need to create our window in DemoApp::init : RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); } lucatch { return lures; } return ok; } Besides the new_window function that creates the window, there are four new keywords in our code: lutry , lucatch , luset and lures . These four keywords are macros that enables us to write error handling using a simpler try-catch style, rather than fetching and checking error codes once and once again for every function call that may fail. lutry and lucatch must be used in pairs, next to each other. In the lutry block, the user may define multiple lulet , luset or luexp statements, lulet statement creates a new local variable to hold the return value of the function, and jumps to lucatch if the function fails; luset assigns the return value to one existing variable, and jumps to lucatch if the function fails; luexp is used if the function does not return any value, it simply checks whether the function succeeds, and jumps to lucatch if not. The user may also call luthrow manually in lutry block to jump to lucatch directly. In the lucatch block, lures is provided as the error code that causes the failure. You may use one switch statement on the lures to handle specific errors, or you can propagate the error directly to parent function by return lures . Since error propagating is so commonly used, we create another macro lucatchret to replace lucatch { return lures; } , so the code above can be written as: RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); } lucatchret; return ok; } Since we use goto statement to implement lutry and lucatch , it you needs multiple lutry-lucatch pairs in one function, you should use a numbered version for every pair (like lutry2 , lucatch2 , luset 2, lures2 , etc.). In most cases, only one lutry-lucatch pair is sufficient. Now let's get back to Window::new_window function that does the actual work: R<Ref<IWindow>> new_window(const c8* title, const WindowDisplaySettings& display_settings, WindowCreationFlag flags) In this function, title Specifies the title of the window, which is usually displayed on the title bar of the window. flags are a combination of WindowCreationFlag enumeration class that lists flags for window creation process, like whether the window is resizable by dragging the border of the window, whether the window is a border-less window, etc. display_settings specifies the display settings for the window, which is described by WindowDisplaySettings structre: struct WindowDisplaySettings { monitor_t monitor; i32 x; i32 y; u32 width; u32 height; u32 refresh_rate; bool full_screen; }; Every window can be displayed in windowed mode or full screen mode, which can be specified by full_screen . monitor specifies the monitor to attach the window to in full screen mode. If monitor is nullptr and the window is set to full screen mode, the primary monitor of the system will be used. x and y are the position of the window on screen coordinates in windowed mode. The user may pass DEFAULT_POS constant to indicate a system-specific default position for the window. width and height are used to control the size of the window, the user can pass 0 to indicate a system-specific default size. refresh_rate controls the refresh rate of the window, the user may pass 0 to use the default refresh rate of the system. WindowDisplaySettings comes with two static functions as_windowed and as_full_screen for quickly specify all parameters in one row, with default values specified when they are skipped by the user, just as in our example. After the window is created, we need to register window event callbacks so that we can handle window events properly. In this example, the events we need to handle is the close event (triggered when the close button of the window is pressed) and the framebuffer resize event (triggered when the window framebuffer size is changed). This can be done by the following statements: window->get_close_event().add_handler([](Window::IWindow* window) { window->close(); }); window->get_framebuffer_resize_event().add_handler([this](Window::IWindow* window, u32 width, u32 height) { lupanic_if_failed(this->resize(width, height)); }); get_close_event and get_framebuffer_resize_event are methods of IWindow that gets the close event and the framebuffer resize event object of the window. The event object is a collection of callback functions that once triggered, calls all the callback functions. We then register one callback function to the close event that closes the window immediately, and one callback function to the framebuffer resize event that calls the resize method of our DempApp . The resize method is currently empty, we will fill the content of this method when we create render textures later: RV DemoApp::resize(u32 width, u32 height) { return ok; } Window events are not polled automatically, we need to tell the window system to poll events at every frame by calling Window::poll_events in update function: RV DemoApp::update() { Window::poll_events(); return ok; } This call polls events for all existing windows, so we don't need to provide specific window here. After we correctly handle the close event, we can complete the is_closed method of DemoApp : bool DemoApp::is_exiting() { return window->is_closed(); } So far, the complete code for main.cpp is: #include <Luna/Runtime/Runtime.hpp> #include <Luna/Runtime/Module.hpp> #include <Luna/Runtime/Log.hpp> #include <Luna/Runtime/UniquePtr.hpp> #include <Luna/Window/Window.hpp> using namespace Luna; struct DemoApp { Ref<Window::IWindow> window; RV init(); RV update(); bool is_exiting(); RV resize(u32 width, u32 height); }; RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); window->get_close_event().add_handler([](Window::IWindow* window) { window->close(); }); window->get_framebuffer_resize_event().add_handler([this](Window::IWindow* window, u32 width, u32 height) { lupanic_if_failed(this->resize(width, height)); }); } lucatchret; return ok; } RV DemoApp::update() { Window::poll_events(); return ok; } bool DemoApp::is_exiting() { return window->is_closed(); } RV DemoApp::resize(u32 width, u32 height) { return ok; } RV run_app() { auto result = init_modules(); if(failed(result)) return result; UniquePtr<DemoApp> app (memnew<DemoApp>()); result = app->init(); if(failed(result)) return result; while(!app->is_exiting()) { result = app->update(); if(failed(result)) return result; } return ok; } int main() { bool initialized = Luna::init(); if(!initialized) return -1; RV result = run_app(); if(failed(result)) log_error(\"DemoApp\", \"%s\", explain(result.errcode())); Luna::close(); return 0; } Build and run DemoApp , and you will see a blank window appears, and the program exits when you click the close button of the window.","title":"Window creation and event handling"},{"location":"manual/introduction/getting_started/#fetching-graphics-device","text":"After the window is created, we can start drawing our box. Luna SDK provides all rendering features through RHI module, which is the abbreviation of Rendering Hardware Interface . To use RHI module, we need to include its header first: #include <Luna/RHI/RHI.hpp> In Luna SDK, all graphics resources are related to one specific graphics device represented by RHI::IDevice , which is the virtual representation of the physical graphics device on the platform, so we need to add one property to DemoApp to hold this device: Ref<RHI::IDevice> dev; When RHI module initializes, it automatically chooses the most suitable physical device and creates one IDevice instance for you, which can be fetched by RHI::get_main_device() . You may also create additional devices for special use, but in our DemoApp , we will stick to the default one by adding the following line in the lutry scope of DemoApp::init : dev = RHI::get_main_device(); We can also import all RHI types and functions by using namespace RHI; so that we don't need to spell them all over the init function: using namespace RHI; The code of DemoApp::init should look similar to: RV DemoApp::init() { lutry { luset(window, Window::new_window(\"DemoApp\", Window::WindowDisplaySettings::as_windowed(), Window::WindowCreationFlag::resizable)); window->get_close_event().add_handler([](Window::IWindow* window) { window->close(); }); window->get_framebuffer_resize_event().add_handler([this](Window::IWindow* window, u32 width, u32 height) { lupanic_if_failed(this->resize(width, height)); }); dev = RHI::get_main_device(); using namespace RHI; // New resource creation code goes here... } lucatchret; return ok; } Unless explicitly specified, all codes we need to add to DemoApp::init in the following sections are added to the end of lutry scope, not in the end of the function scope directly.","title":"Fetching graphics device"},{"location":"manual/introduction/getting_started/#fetching-command-queue-and-creating-command-buffer","text":"Luna SDK employs deferred execution model , where render and compute invocations are recorded as commands in command buffers , then submitted to GPU explicitly by submitting command buffers to command queues . The command buffer object manages memory allocated to store commands, it also tracks the execution state for commands in the buffer when the buffer is submitted for execution. The command queue is a FIFO message queue between the host program and GPU. The host program submits command buffers to the command queue, and GPU consumes command buffers from the queue and execute commands in the buffer. Command buffers in the same queue are guaranteed to execute one after another, the next command buffer will not be executed until the last command buffer is finished. When IDevice initializes, it creates one or multiple command queues based on the physical device architecture and limitation. The user can use IDevice::get_num_command_queues to fetch the number of command queues present on the current device, and use IDevice::get_command_queue_desc to fetch the command queue description of each command queue. get_command_queue_desc returns one CommandQueueDesc structure, which is defined as follows: struct CommandQueueDesc { CommandQueueType type; CommandQueueFlag flags; }; CommandQueueType indicates the type of the command queue. There are three different queue types: graphics , compute and copy . The copy queue only accepts copy commands, and is used for transferring data between different resources; the compute queue accepts copy and compute tasks, while the graphics queue accepts graphics, compute and copy commands. CommandQueueFlag indicates additional properties for the queue, including CommandQueueFlag::presenting , which indicates one command queue that supports swap chain presenting. In our program, we need to choose one command queue of graphics type, and has CommandQueueFlag::presenting flag present. We firstly need to add one property to DemoApp to store the command queue index we choose: u32 queue; Then the command queue can be fetched by adding the following codes to DemoApp::init : queue = U32_MAX; u32 num_queues = dev->get_num_command_queues(); for (u32 i = 0; i < num_queues; ++i) { auto desc = dev->get_command_queue_desc(i); if (desc.type == CommandQueueType::graphics && test_flags(desc.flags, CommandQueueFlag::presenting)) { queue = i; break; } } if(queue == U32_MAX) return BasicError::not_supported(); After we fetched the command queue, we need to create one command buffer to record commands that will be submitted to that queue. We firstly need to add one new property to DemoApp to hold the command buffer: Ref<RHI::ICommandBuffer> cmdbuf; Then we can create the command buffer by adding the following codes to DemoApp::init : luset(cmdbuf, dev->new_command_buffer(queue)); When we create the command buffer, we should pass the index of the command queue that is attached to the command buffer. The created command buffer can only be submitted to the command queue specified when creating the command buffer.","title":"Fetching command queue and creating command buffer"},{"location":"manual/introduction/getting_started/#creating-swap-chain","text":"The swap chain object contains resources that are used to present render results to our window. In order to create one swap chain, we firstly need to add one property to DemoApp to store the created swap chain: Ref<RHI::ISwapChain> swap_chain; In Luna SDK, the swap chain presentation is also a command that should be submitted using command queues, so we need to specify the command queue we need to use when creating swap chains like so: luset(swap_chain, dev->new_swap_chain(queue, window, SwapChainDesc(0, 0, 2, Format::bgra8_unorm, true))); The swap chain is described by one SwapChainDesc structure: struct SwapChainDesc { u32 width; u32 height; u32 buffer_count; Format pixel_format; bool vertically_synchronized; }; When used for creating swap chains, you may pass 0 for width and height property, which indicates the system to use the window framebuffer size as the size of the swap chain. The swap chain needs to be resized when the window framebuffer size is changed. This can be done by filling DemoApp::resize method with the following codes: RV DemoApp::resize(u32 width, u32 height) { lutry { using namespace RHI; if(width && height) { auto dev = get_main_device(); luexp(swap_chain->reset({width, height, 2, Format::unknown, true})); } } lucatchret; return ok; } ISwapChain::reset will reset the swap chain according to the new swap chain description, we can use Format::unknown to tell the system to use the current back buffer format for the new back buffer. Note that on some systems, the resize event will be emitted with both width and height being 0 if the window is minimized. We cannot create one swap chain with zero width or height, so we should handle this case and resize the back buffer with only non-zero size values.","title":"Creating swap chain"},{"location":"manual/introduction/getting_started/#creating-descriptor-set-layout-and-descriptor-set","text":"The descriptor set object stores descriptors that bind resources to graphics or compute pipeline. Descriptors have the following types: Uniform buffer view, which binds constant global data to shaders. Read buffer view, which binds buffers to shaders and enables load operations on the buffer data. Read texture view, which binds textures to shaders and enables sampling and load operations on the pixel data. Read write buffer view, which binds buffers to shaders and enables load, store and atomic operations on the buffer data. Read write texture view, which binds textures to shaders and enables load, store, and atomic operations on the pixel data. Sampler, which stores sampling settings and exposes those settings for shaders. Every pipeline may bind multiple descriptor sets, every descriptor set may contain all kinds of descriptors listed above. The descriptor set layout object stores the layout of one descriptor set object, including the number of descriptors in the descriptor set and the property of each descriptor. In order to create one descriptor set layout object, we need to fill one DescriptorSetLayoutDesc structure. Here is the definition of DescriptorSetLayoutDesc structure: struct DescriptorSetLayoutDesc { Span<const DescriptorSetLayoutBinding> bindings; DescriptorSetLayoutFlag flags = DescriptorSetLayoutFlag::none; }; The descriptor set layout consists of multiple bindings specified by DescriptorSetLayoutBinding , each binding describes one range of the descriptor set: struct DescriptorSetLayoutBinding { DescriptorType type; TextureViewType texture_view_type; u32 binding_slot; u32 num_descs; ShaderVisibilityFlag shader_visibility_flags; }; the type property describes the type of this binding. All descriptors in the same binding must be the same type: enum class DescriptorType : u32 { uniform_buffer_view, read_buffer_view, read_write_buffer_view, read_texture_view, read_write_texture_view, sampler }; the texture_view_type property describes the texture view type that can be set in this binding. This is required only when type of this binding is read_texture_view or read_write_texture_view . All texture views in the same binding must be the same type. binding_slot and num_descs describes the binding slot range of this binding, starting from 0 . All slots in [binding_slot, binding_slot + num_descs) will be occupied by this binding and cannot be used by other bindings. If num_descs is greater than 1 , then this binding will be interpreted as one descriptor array in the shader. shader_visibility_flags specifies which shaders may access descriptors in this binding, you may restrict the visibility of one binding to one set of specific shaders, which may improve performance on some platforms. We need to add two new properties to DemoApp to hold the descriptor set layout object and the descriptor set object: Ref<RHI::IDescriptorSetLayout> dlayout; Ref<RHI::IDescriptorSet> desc_set; We need 1 descriptor set with 1 constant buffer view, 1 shader resource view and 1 sampler. So we can create our descriptor set layout object in DemoApp::init like so: luset(dlayout, dev->new_descriptor_set_layout(DescriptorSetLayoutDesc({ DescriptorSetLayoutBinding::uniform_buffer_view(0, 1, ShaderVisibilityFlag::vertex), DescriptorSetLayoutBinding::read_texture_view(TextureViewType::tex2d, 1, 1, ShaderVisibilityFlag::pixel), DescriptorSetLayoutBinding::sampler(2, 1, ShaderVisibilityFlag::pixel) }))); Then we can create one descriptor set using the descriptor set layout object: luset(desc_set, dev->new_descriptor_set(DescriptorSetDesc(dlayout))); We will fill descriptors in the set by calling update_descriptors later.","title":"Creating descriptor set layout and descriptor set"},{"location":"manual/introduction/getting_started/#compiling-shaders","text":"The next thing to do is compiling shaders for the pipeline state object. Luna SDK uses HLSL as the source shader language, and uses ShaderCompiler module to compile HLSL to DXBC, DXIL, SPIR-V and other target shading languages. To compile shader, we need to include corresponding header files: #include <Luna/ShaderCompiler/ShaderCompiler.hpp> #include <Luna/RHI/ShaderCompileHelper.hpp> ShaderCompileHelper.hpp includes RHI::get_current_platform_shader_target_format() function, which tell the shader compiler the native target target shader format for the current graphics API. Since our shader is rather simple, we declare our shader source code directly in the C++ source file, in DemoApp::init function: const char vs_shader_code[] = R\"( cbuffer vertexBuffer : register(b0) { float4x4 world_to_proj; }; struct VS_INPUT { [[vk::location(0)]] float3 position : POSITION; [[vk::location(1)]] float2 texcoord : TEXCOORD; }; struct PS_INPUT { [[vk::location(0)]] float4 position : SV_POSITION; [[vk::location(1)]] float2 texcoord : TEXCOORD; }; PS_INPUT main(VS_INPUT input) { PS_INPUT output; output.position = mul(world_to_proj, float4(input.position, 1.0f)); output.texcoord = input.texcoord; return output; })\"; const char ps_shader_code[] = R\"( Texture2D tex : register(t1); SamplerState tex_sampler : register(s2); struct PS_INPUT { [[vk::location(0)]] float4 position : SV_POSITION; [[vk::location(1)]] float2 texcoord : TEXCOORD; }; [[vk::location(0)]] float4 main(PS_INPUT input) : SV_Target { return float4(tex.Sample(tex_sampler, input.texcoord)); })\"; here we use C++ raw string syntax R\"()\" to declare multiline string without appending \\ for every string line. Note the register number specified in shader must match the binding slot specified in descriptor set layout we just created. Since we use the same slot numbering system for all descriptor types, the register number for b , t , u and s should not overlap. Then we can compile shaders using ShaderCompiler::ICompiler object: auto compiler = ShaderCompiler::new_compiler(); compiler->set_source({ vs_shader_code, strlen(vs_shader_code) }); compiler->set_source_name(\"DemoAppVS\"); compiler->set_entry_point(\"main\"); compiler->set_target_format(RHI::get_current_platform_shader_target_format()); compiler->set_shader_type(ShaderCompiler::ShaderType::vertex); compiler->set_shader_model(6, 0); compiler->set_optimization_level(ShaderCompiler::OptimizationLevel::full); luexp(compiler->compile()); auto vs_data = compiler->get_output(); Blob vs(vs_data.data(), vs_data.size()); compiler->reset(); compiler->set_source({ ps_shader_code, strlen(ps_shader_code) }); compiler->set_source_name(\"DemoAppPS\"); compiler->set_entry_point(\"main\"); compiler->set_target_format(RHI::get_current_platform_shader_target_format()); compiler->set_shader_type(ShaderCompiler::ShaderType::pixel); compiler->set_shader_model(6, 0); compiler->set_optimization_level(ShaderCompiler::OptimizationLevel::full); luexp(compiler->compile()); auto ps_data = compiler->get_output(); Blob ps(ps_data.data(), ps_data.size()); The shader compilation process is fairly simple, we just set source code, compilation settings, then triggers the compilation. The compilation result will be given by get_output , we use one Blob object , a container for binary data, to hold the compilation result. The compiled shader data will be used when creating pipeline state object later.","title":"Compiling shaders"},{"location":"manual/introduction/getting_started/#creating-pipeline-layout-and-pipeline-state","text":"The graphics and compute pipeline state is described by two objects: pipeline layout object and pipeline state object. Pipeline layout object stores the shader binding layout information for all shader stages, while pipeline state object stores pipeline settings for all graphics stages. Pipeline layout is described by the PipelineLayoutDesc structure, which is configured by specifying layouts of descriptor sets that will be bound to this pipeline and flags that specifies shaders that are allowed to access shader inputs. struct PipelineLayoutDesc { Span<IDescriptorSetLayout*> descriptor_set_layouts; PipelineLayoutFlag flags; }; We need to add one new property to DemoApp to hold the pipeline layout object: Ref<RHI::IPipelineLayout> playout; Then we can create pipeline layout object using the following code: luset(playout, dev->new_pipeline_layout(PipelineLayoutDesc({dlayout}, PipelineLayoutFlag::allow_input_assembler_input_layout))); The pipeline object is described by the GraphicsPipelineStateDesc structure or the ComputePipelineStateDesc structure. Since we are creating one graphics pipeline, we need to fill the GraphicsPipelineStateDesc structure, which is a complex structure that contains all pipeline settings for one graphics pipeline: struct GraphicsPipelineStateDesc { InputLayoutDesc input_layout; IPipelineLayout* pipeline_layout = nullptr; Span<const byte_t> vs; Span<const byte_t> ps; RasterizerDesc rasterizer_state; DepthStencilDesc depth_stencil_state; BlendDesc blend_state; IndexBufferStripCutValue ib_strip_cut_value = IndexBufferStripCutValue::disabled; PrimitiveTopology primitive_topology = PrimitiveTopology::triangle_list; u8 num_color_attachments = 0; Format color_formats[8] = { Format::unknown }; Format depth_stencil_format = Format::unknown; u32 sample_count = 1; u32 sample_mask = 0xFFFFFFFF; }; Most graphic settings are similar to those in D3D11, D3D12, OpenGL or Vulkan, we will not explain these settings, but only gives the code that correctly sets every setting of the pipeline. You can see docs for RHI module for detailed explanations of these settings. We need to add one new property to DemoApp to hold the pipeline state object: Ref<RHI::IPipelineState> pso; Then we can create pipeline state object using the following code: GraphicsPipelineStateDesc ps_desc; ps_desc.primitive_topology = PrimitiveTopology::triangle_list; ps_desc.sample_mask = U32_MAX; ps_desc.rasterizer_state = RasterizerDesc(); ps_desc.depth_stencil_state = DepthStencilDesc(true, true, CompareFunction::less_equal); ps_desc.ib_strip_cut_value = IndexBufferStripCutValue::disabled; InputAttributeDesc input_attributes[] = { InputAttributeDesc(\"POSITION\", 0, 0, 0, 0, Format::rgb32_float), InputAttributeDesc(\"TEXCOORD\", 0, 1, 0, 12, Format::rg32_float) }; InputBindingDesc input_bindings[] = { InputBindingDesc(0, 20, InputRate::per_vertex) }; ps_desc.input_layout.attributes = {input_attributes, 2}; ps_desc.input_layout.bindings = {input_bindings, 1}; ps_desc.vs = vs.cspan(); ps_desc.ps = ps.cspan(); ps_desc.pipeline_layout = playout; ps_desc.num_color_attachments = 1; ps_desc.color_formats[0] = Format::rgba8_unorm; ps_desc.depth_stencil_format = Format::d32_float; luset(pso, dev->new_graphics_pipeline_state(ps_desc));","title":"Creating pipeline layout and pipeline state"},{"location":"manual/introduction/getting_started/#creating-depth-textures","text":"The next step is to create one depth texture that is used as the depth stencil attachment when drawing our box. Texture objects in Luna SDK are represented by ITexture interface, and are described by TextureDesc structure, which is defined as follows: struct TextureDesc { TextureType type; Format format; u32 width; u32 height; u32 depth; u32 array_size; u32 mip_levels; u32 sample_count; TextureUsageFlag usages; ResourceFlag flags; } type specifies the type of the texture, like tex1d , tex2d , etc. format specifies the pixel format of the texture. usages specifies all possible usages of the texture when being bound to a pipeline. width , height and depth specifies the size of the texture. array_size specifies the number of texture elements if this texture object represents a texture array, otherwise 1 shall be specified. mip_levels specifies the number of mips that should be allocated for the resource, if this is 0 , the system allocates full mipmap chain for the resource. sample_count specifies the sampling count for MSAA textures. flags specifies additional features for the texture, like whether this texture can share memory with other resources. To simplify the texture description, we can use static methods provided by TextureDesc to quickly construct TextureDesc structure: TextureDesc TextureDesc::tex1d(Format format, TextureUsageFlag usages, u64 width, u32 array_size = 1, u32 mip_levels = 0, ResourceFlag flags = ResourceFlag::none); TextureDesc TextureDesc::tex2d(Format format, TextureUsageFlag usages, u64 width, u32 height, u32 array_size = 1, u32 mip_levels = 0, u32 sample_count = 1, ResourceFlag flags = ResourceFlag::none); TextureDesc TextureDesc::tex3d(Format format, TextureUsageFlag usages, u64 width, u32 height, u32 depth, u32 mip_levels = 0, ResourceFlag flags = ResourceFlag::none); Back to our DemoApp , we need to add one new property to DemoApp to hold the depth texture: Ref<RHI::ITexture> depth_tex; Then we can create textures using the following code: auto window_size = window->get_framebuffer_size(); luset(depth_tex, dev->new_texture(MemoryType::local, TextureDesc::tex2d(Format::d32_float, TextureUsageFlag::depth_stencil_attachment, window_size.x, window_size.y, 1, 1))); The first parameter of new_texture is the memory type of texture memory. The memory type is defined by MemoryType enumeration, possible options include: local - The memory can only be accessed by GPU, CPU access is disabled. This memory type is suitable for resources that will be frequently accessed by GPU. upload - The memory can be written by CPU and read by GPU. This memory type is suitable for resources that should be updated by CPU frequently. Textures cannot be created in this heap. readback - The memory can be written by GPU and read by CPU. This memory type is suitable for transferring data from GPU to CPU. Textures cannot be created in this heap. Note that when retrieving window size for rendering, we need to call IWindow::get_framebuffer_size instead of IWindow::get_size , on some platforms the window size is not necessary measured in pixels, causing these two methods return different values. Since we are using the window size as the depth texture size, the depth texture should also be recreated when the window size is changed. This can be done by adding the following code to the DemoApp::resize method: luset(depth_tex, dev->new_texture(MemoryType::local, TextureDesc::tex2d(Format::d32_float, TextureUsageFlag::depth_stencil_attachment, width, height, 1, 1)));","title":"Creating depth textures"},{"location":"manual/introduction/getting_started/#creating-buffers-and-uploading-buffer-data","text":"The next step is to create buffers used in our DemoApp , including: The vertex buffer and index buffer for our box mesh. The uniform buffer for camera properties. Firstly we need to define the vertex structure of our box. Adding the following code after the declaration of DemoApp structure: struct Vertex { Float3U position; Float2U texcoord; }; Float2U and Float3U are vector types used in Luna SDK, which represent 2D and 3D vectors. In Luna SDK, we have 16-bytes aligned vector types Float2 , Float3 , Float4 , and unaligned vector types Float2U , Float3U and Float4U . The aligned vector types are used for calculations, SIMD functions like min , max , lerp , clamp only accepts aligned types, while unaligned vector types are used for storing and transferring data, just like this case. The size of aligned vector types are all 16 bytes, while the size of unaligned types are 8, 12 and 16 for Float2U , Float3U and Float4U . We need to add three new properties to DemoApp to hold the these three buffers: Ref<RHI::IBuffer> vb; Ref<RHI::IBuffer> ib; Ref<RHI::IBuffer> ub; As you can see, buffer objects are represented by IBuffer interface. Both IBuffer and ITexture interface inherits from IResource interface, which provides one method to fetch the underlying memory of the resource. Fetching the underlying memory enables the user to create aliasing resources that share the same memory, which is an advanced feature that will not be covered in this article. One buffer resource is described by BufferDesc structure, which is defined as follows: struct BufferDesc { u64 size; BufferUsageFlag usages; ResourceFlag flags; } BufferDesc is rather simple compared to TextureDesc . size specifies the size of the buffer, usages specifies all possible usages of the buffer when being bound to the pipeline, and flags specifies additional features of the buffer, like whether this buffer can share memory with other resources. Then, we need to create the vertex buffer and index buffer for our box using the following code: Vertex vertices[] = { {{+0.5, -0.5, -0.5}, {0.0, 1.0}}, {{+0.5, +0.5, -0.5}, {0.0, 0.0}}, {{+0.5, +0.5, +0.5}, {1.0, 0.0}}, {{+0.5, -0.5, +0.5}, {1.0, 1.0}}, {{+0.5, -0.5, +0.5}, {0.0, 1.0}}, {{+0.5, +0.5, +0.5}, {0.0, 0.0}}, {{-0.5, +0.5, +0.5}, {1.0, 0.0}}, {{-0.5, -0.5, +0.5}, {1.0, 1.0}}, {{-0.5, -0.5, +0.5}, {0.0, 1.0}}, {{-0.5, +0.5, +0.5}, {0.0, 0.0}}, {{-0.5, +0.5, -0.5}, {1.0, 0.0}}, {{-0.5, -0.5, -0.5}, {1.0, 1.0}}, {{-0.5, -0.5, -0.5}, {0.0, 1.0}}, {{-0.5, +0.5, -0.5}, {0.0, 0.0}}, {{+0.5, +0.5, -0.5}, {1.0, 0.0}}, {{+0.5, -0.5, -0.5}, {1.0, 1.0}}, {{-0.5, +0.5, -0.5}, {0.0, 1.0}}, {{-0.5, +0.5, +0.5}, {0.0, 0.0}}, {{+0.5, +0.5, +0.5}, {1.0, 0.0}}, {{+0.5, +0.5, -0.5}, {1.0, 1.0}}, {{+0.5, -0.5, -0.5}, {0.0, 1.0}}, {{+0.5, -0.5, +0.5}, {0.0, 0.0}}, {{-0.5, -0.5, +0.5}, {1.0, 0.0}}, {{-0.5, -0.5, -0.5}, {1.0, 1.0}} }; u32 indices[] = { 0, 1, 2, 0, 2, 3, 4, 5, 6, 4, 6, 7, 8, 9, 10, 8, 10, 11, 12, 13, 14, 12, 14, 15, 16, 17, 18, 16, 18, 19, 20, 21, 22, 20, 22, 23 }; luset(vb, dev->new_buffer(MemoryType::local, BufferDesc(BufferUsageFlag::vertex_buffer | BufferUsageFlag::copy_dest, sizeof(vertices)))); luset(ib, dev->new_buffer(MemoryType::local, BufferDesc(BufferUsageFlag::index_buffer | BufferUsageFlag::copy_dest, sizeof(indices)))); We firstly define vertex and index data for our box, then we create two buffer resources to hold the vertex and index data. One buffer is created by calling IDevice::new_buffer , which is similar to IDevice::new_texture , but takes BufferDesc as the resource descriptor object. Since we only need to upload vertex and index buffer data once, these two buffers are created in local memory to achieve maximum GPU bandwidth. We can use similar code to create the constant buffer for uploading camera properties, but there are two differences. First, the graphic device has alignment requirements for constant buffers, which can be fetched from IDevice::get_uniform_buffer_data_alignment() , so we use align_upper helper function to adjust the size of our uniform buffer resource to meet the alignment requirement. Second, since we need to update uniform buffer data once every frame, we should choose upload memory type instead of local to give host program direct access to that resource. In our DemoApp , the data of the uniform buffer is the 4x4 world-to-project matrix of the camera. We need to add a new include file to use matrix types: #include <Luna/Runtime/Math/Matrix.hpp> then we can use the following code to create constant buffer: auto ub_align = dev->get_uniform_buffer_data_alignment(); luset(ub, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::uniform_buffer, align_upper(sizeof(Float4x4), ub_align)))); as you can see, Float4x4 is the matrix type used in Luna SDK. We also have Float3x3 for 2D affine transformations.","title":"Creating buffers and uploading buffer data"},{"location":"manual/introduction/getting_started/#uploading-vertex-and-index-data","text":"Now that we have created one vertex buffer and one index buffer, we need to upload vertex and index data to these buffers, so that they can be used by GPU correctly. As we have mentioned before, resources with local memory type can not be accessed by the host directly. To copy data between local memory and host memory, we can either use staging buffers to transfer the data manually, or we can use RHI::copy_resource_data to perform data copy automatically. We will show how to perform data copy in both approaches.","title":"Uploading vertex and index data"},{"location":"manual/introduction/getting_started/#uploading-data-manually","text":"In order to upload data to resources with local memory type, we need to create intermediate buffers with upload memory type, copy data to such buffers form the host, and use GPU to copy data from such buffers to resources with local memory type. Such intermediate buffers are usually called staging buffers , and are used frequently to copy data from host memory to device local memory. The following code shows how to upload data for our vertex and index buffer: lulet(vb_staging, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::copy_source, sizeof(vertices)))); lulet(ib_staging, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::copy_source, sizeof(indices)))); void* vb_mapped = nullptr; luexp(vb_staging->map(0, 0, &vb_mapped)); memcpy(vb_mapped, vertices, sizeof(vertices)); vb_staging->unmap(0, sizeof(vertices)); void* ib_mapped = nullptr; luexp(ib_staging->map(0, 0, &ib_mapped)); memcpy(ib_mapped, indices, sizeof(indices)); ib_staging->unmap(0, sizeof(indices)); cmdbuf->begin_copy_pass(); cmdbuf->resource_barrier({ BufferBarrier(vb, BufferStateFlag::automatic, BufferStateFlag::copy_dest), BufferBarrier(vb_staging, BufferStateFlag::automatic, BufferStateFlag::copy_source), BufferBarrier(ib, BufferStateFlag::automatic, BufferStateFlag::copy_dest), BufferBarrier(ib_staging, BufferStateFlag::automatic, BufferStateFlag::copy_source), }, {}); cmdbuf->copy_buffer(vb, 0, vb_staging, 0, sizeof(vertices)); cmdbuf->copy_buffer(ib, 0, ib_staging, 0, sizeof(indices)); cmdbuf->end_copy_pass(); cmdbuf->submit({}, {}, true); cmdbuf->wait(); cmdbuf->reset(); Firstly, we create two staging buffers vb_staging and ib_staging . These two buffers have the same size as vb and ib and use upload memory type, so they can be written by the host directly. Then, we use IBuffer::map to take pointers to the buffer memory, use memcpy to copy data to the memory, then use IBuffer::unmap to release the host access to the memory. map takes two integer parameters indicating the host reading range of the mapped memory, this should always be 0 if the memory type of the buffer is not readback , just like this case. unmap takes another two integer parameters indicating the host writing range of the mapped memory. in our case, we have written memory in [0, sizeof(data)) range, so we should specify the range correctly. There is a special range [0, USIZE_MAX) that indicates the whole buffer memory is read or written, so we don't need to specify the size explicitly. After we copy data to staging buffers, we need to tell GPU to copy data from staging buffers to GPU local resources. As we have mentioned before, to send commands to GPU, we need to record commands into command buffers, submit them to command queues, then waits for command buffers to be finished by GPU. The first command we need to record is ICommandBuffer::begin_copy_pass , which tells GPU to start a copy pass. This is required because all copy commands like copy_buffer , copy_texture etc. can only be recorded in a copy pass scope. Similarly, we have render passes for render commands, and compute passes for compute commands. After beginning the copy pass, we need to emit resource barriers to transfer resources used by GPU to compatible states. Resource barrier commands are recorded by ICommandBuffer::resource_barrier , and will be described later. After resources have been transferred into suitable states, we call ICommandBuffer::copy_buffer to record one buffer-to-buffer copy command. Finally, we call ICommandBuffer::end_copy_pass to end the copy pass we opened before. When we finish recording commands into the command buffer, we call ICommandBuffer::submit to submit the command buffer to the command queue, call ICommandBuffer::wait to wait for the command buffer to be finished, then call ICommandBuffer::reset to clear commands in the command buffer, and reset the command buffer state so that it can be used for a recording new commands.","title":"Uploading data manually"},{"location":"manual/introduction/getting_started/#uploading-data-using-rhicopy_resource_data","text":"In order to use RHI::copy_resource_data , we need to include one new header file: #include <Luna/RHI/Utility.hpp> RHI/Utility.hpp is an auxiliary library that defines high-level functionalities implemented using APIs provided by RHI , including RHI::copy_resource_data we use here. The following code shows how to upload data using RHI::copy_resource_data : luexp(copy_resource_data(cmdbuf, { CopyResourceData::write_buffer(vb, 0, vertices, sizeof(vertices)), CopyResourceData::write_buffer(ib, 0, indices, sizeof(indices)) })); You can see how RHI::copy_resource_data greatly simplifies the code we need to write in order to upload resource data.","title":"Uploading data using RHI::copy_resource_data"},{"location":"manual/introduction/getting_started/#loading-image-from-file","text":"The next step is to load our Luna LOGO image that will be drawn on the box surface: Save the image file in the same directory as main.cpp , and naming it luna.png . You should have one file structure similar to this: DemoApp |- xmake.lua |- main.cpp |- luna.png Then fills xmake.lua with the following code: target(\"DemoApp\") set_luna_sdk_program() add_files(\"**.cpp\") add_deps(\"Runtime\", \"Window\", \"RHI\", \"ShaderCompiler\", \"Image\") before_build(function(target) os.cp(\"$(scriptdir)/luna.png\", target:targetdir() .. \"/luna.png\") end) after_install(function (target) os.cp(target:targetdir() .. \"/luna.png\", target:installdir() .. \"/bin/luna.png\") end) target_end() This script triggers registers custom functions before building the program and after installing the program, the custom function copies the image file to same the directory of our program binary file, so that our program can correctly find the image file. Then, go back to main.cpp , and add one new property to DemoApp to represent the loaded image: Ref<RHI::ITexture> file_tex; To load the image in our program, we need to use one new module called Image , which parses image file data and gives row-majored image data in our desired format. We also need to use the file API provided by Runtime module, so we includes two new headers: #include <Luna/Runtime/File.hpp> #include <Luna/Image/Image.hpp> The first thing to do is to load image file data from our luna.png file. In order to load file data, we need to use the open_file function provided by the Runtime module. This function returns one file handle represented by IFile if the file is correctly opened. Then, we loads the file data into one Blob object by calling load_file_data , this function creates one properly-sized blob object, and calls IFile::read to read all data of the file to the blob, then returns the blob: lulet(image_file, open_file(\"Luna.png\", FileOpenFlag::read, FileCreationMode::open_existing)); lulet(image_file_data, load_file_data(image_file)); Now that the file data has been stored in image_file_data , we need to call Image::read_image_file function to parse the file data and gives the real image data: Image::ImageDesc image_desc; lulet(image_data, Image::read_image_file(image_file_data.data(), image_file_data.size(), Image::ImagePixelFormat::rgba8_unorm, image_desc)); Image::read_image_file function outputs one Image::ImageDesc structure that describes the returned image data, including the width, height and pixel format of the image. The image data is arranged in a row-major manner and without and alignment padding. We can now creates the texture resource based on the image size: luset(file_tex, dev->new_texture(MemoryType::local, TextureDesc::tex2d(Format::rgba8_unorm, TextureUsageFlag::copy_dest | TextureUsageFlag::read_texture, image_desc.width, image_desc.height, 1, 1))); The following code shows how to upload data for our texture: u64 tex_size, tex_row_pitch, tex_slice_pitch; dev->get_texture_data_placement_info(image_desc.width, image_desc.height, 1, Format::rgba8_unorm, &tex_size, nullptr, &tex_row_pitch, &tex_slice_pitch); lulet(file_tex_staging, dev->new_buffer(MemoryType::upload, BufferDesc(BufferUsageFlag::copy_source, tex_size))); void* file_tex_mapped = nullptr; luexp(file_tex_staging->map(0, 0, &file_tex_mapped)); memcpy_bitmap(file_tex_mapped, image_data.data(), image_desc.width * 4, image_desc.height, tex_row_pitch, image_desc.width * 4); file_tex_staging->unmap(0, USIZE_MAX); cmdbuf->begin_copy_pass(); cmdbuf->resource_barrier({ BufferBarrier(file_tex_staging, BufferStateFlag::automatic, BufferStateFlag::copy_source) }, { TextureBarrier(file_tex, TEXTURE_BARRIER_ALL_SUBRESOURCES, TextureStateFlag::automatic, TextureStateFlag::copy_dest) }); cmdbuf->copy_buffer_to_texture(file_tex, SubresourceIndex(0, 0), 0, 0, 0, file_tex_staging, 0, tex_row_pitch, tex_slice_pitch, image_desc.width, image_desc.height, 1); cmdbuf->end_copy_pass(); cmdbuf->submit({}, {}, true); cmdbuf->wait(); cmdbuf->reset(); Uploading texture data is similar to uploading buffer data, we need to create one staging buffer to hold the texture data, then use ICommandBuffer::copy_buffer_to_texture to copy data from buffer to texture. Note that most systems have special alignment requirements for texture data in buffers when copying data between buffers and textures, the user should call IDevice::get_texture_data_placement_info to fetch the texture data placement information for one specific texture, and use that information to manipulate texture data in the buffer. Instead of memcpy , the user should call memcpy_bitmap to copy row-major bitmap data, which takes src_row_pitch and dst_row_pitch to correctly offsets every texture data row. We can also use RHI::copy_resource_data to upload data for textures like so: luexp(copy_resource_data(cmdbuf, { CopyResourceData::write_texture(file_tex, SubresourceIndex(0, 0), 0, 0, 0, image_data.data(), image_desc.width * 4, image_desc.width * image_desc.height * 4, image_desc.width, image_desc.height, 1) }));","title":"Loading image from file"},{"location":"manual/introduction/getting_started/#set-up-descriptor-set","text":"Once the uniform buffer and file texture is set up, we can bind these two resources to the descriptor set by calling IDescriptorSet::update_descriptors . We also need to set the sampler in the descriptor set to be used by the pixel shader. luexp(desc_set->update_descriptors({ WriteDescriptorSet::uniform_buffer_view(0, BufferViewDesc::uniform_buffer(ub)), WriteDescriptorSet::read_texture_view(1, TextureViewDesc::tex2d(file_tex)), WriteDescriptorSet::sampler(2, SamplerDesc(Filter::linear, Filter::linear, Filter::linear, TextureAddressMode::clamp, TextureAddressMode::clamp, TextureAddressMode::clamp)) })); This concludes the DemoApp::init function.","title":"Set up descriptor set"},{"location":"manual/introduction/getting_started/#camera-control","text":"Now that we have created all resources required to draw the box, we need to fill the actual drawing code in DemoApp::update . To make our program more interesting, we can apply one simple animation that rotates the camera around the box. We firstly adds one new property to DemoApp that stores the rotation angle of the camera: f32 camera_rotation = 0.0f; We can increase the rotation angle of the camera by one at every frame by adding the following line to the end of DemoApp:update : camera_rotation += 1.0f; Since we are going to use many functions that may throw errors, it is better to declare one lutry - lucatch scope that wraps all succeeding codes in DemoApp:update . Also, we don't want to render the image if the window is closed or minimized, so we add two early-out conditions after Window::poll_events() . Now DemoApp::update should look like this: RV DemoApp::update() { Window::poll_events(); if(window->is_closed()) return ok; if(window->is_minimized()) return ok; lutry { camera_rotation += 1.0f; // More codes goes here... } lucatchret; return ok; } After we updates the camera rotation, we need to calculate the view-projection matrix for the camera. Fortunately, the math library of the Runtime module already includes implementations for many commonly used vector and matrix calculations, and here we are going to use two of them: AffineMatrix::make_look_at and ProjectionMatrix::make_perspective_fov . To use these two functions, we firstly need to add one new header file: #include <Luna/Runtime/Math/Transform.hpp> Then the matrix can be computed using the following code: Float3 camera_pos(cosf(camera_rotation / 180.0f * PI) * 3.0f, 1.0f, sinf(camera_rotation / 180.0f * PI) * 3.0f); Float4x4 camera_mat = AffineMatrix::make_look_at(camera_pos, Float3(0, 0, 0), Float3(0, 1, 0)); auto window_sz = window->get_framebuffer_size(); camera_mat = mul(camera_mat, ProjectionMatrix::make_perspective_fov(PI / 3.0f, (f32)window_sz.x / (f32)window_sz.y, 0.001f, 100.0f)); AffineMatrix::make_look_at generates one camera view matrix from the position of the camera and the position of the point to look at. ProjectionMatrix::make_perspective_fov is another helper function that generates one projection matrix from the specified field-of-view and aspect ratio values. Those two matrices are multiplied by mul function to get the final view-projection matrix. Note that when performing matrix multiplications, use mul instead of operator * , the later one is used to multiply each element in the matrix separately. After we get the matrix, we need to copy the matrix data to the uniform buffer resource like so: void* camera_mapped; luexp(ub->map(0, 0, &camera_mapped)); memcpy(camera_mapped, &camera_mat, sizeof(Float4x4)); ub->unmap(0, sizeof(Float4x4));","title":"Camera control"},{"location":"manual/introduction/getting_started/#fetching-the-back-buffer","text":"In order to render contents to one window, we need to fetch back buffers managed by the window swap chain. The number of back buffers that are contained by a swap chain is determined by SwapChainDesc::buffer_count , which can be set when the swap chain is created or reset. At every frame, only one back buffer can be used for rendering, which can be fetched by calling ISwapChain::get_current_back_buffer : lulet(back_buffer, swap_chain->get_current_back_buffer()); ISwapChain::get_current_back_buffer can be called multiple times during the same frame, and will return the same back buffer. The current back buffer will be switched when ISwapChain::present is called, the user should not use the back buffer in the previous frame after ISwapChain::present is called.","title":"Fetching the back buffer"},{"location":"manual/introduction/getting_started/#resource-barriers","text":"In Luna SDK, every graphic resource has one state that describes the current memory layout and pipeline access polity of the resource. Before we can issue draw calls, we need to transfer every resource we use to their correct states. Luna SDK requires the user to transfer the state explicitly by calling ICommandBuffer::resource_barrier with transition-typed resource barriers. In our example, we need to perform the following transitions: cmdbuf->resource_barrier({ BufferBarrier(ub, BufferStateFlag::automatic, BufferStateFlag::uniform_buffer_vs), BufferBarrier(vb, BufferStateFlag::automatic, BufferStateFlag::vertex_buffer), BufferBarrier(ib, BufferStateFlag::automatic, BufferStateFlag::index_buffer) }, { TextureBarrier(file_tex, TEXTURE_BARRIER_ALL_SUBRESOURCES, TextureStateFlag::automatic, TextureStateFlag::shader_read_ps), TextureBarrier(back_buffer, SubresourceIndex(0, 0), TextureStateFlag::automatic, TextureStateFlag::color_attachment_write), TextureBarrier(depth_tex, SubresourceIndex(0, 0), TextureStateFlag::automatic, TextureStateFlag::depth_stencil_attachment_write) }); One resource can have multiple states, so long as such states are compatible to each other. For example, one texture can have TextureStateFlag::shader_read_vs and TextureStateFlag::shader_read_ps at the same time if it will be accessed by both vertex and pixel shader, or can have TextureStateFlag::shader_read_cs and TextureStateFlag::shader_write_cs at the same time if it will be read and write by compute shader. Luna SDK internally tracks the current states for all resources, so we can set before states of resources to automatic in most cases, which tells the system to load the previous states automatically. Luna SDK also omits unnecessary barriers automatically.","title":"Resource barriers"},{"location":"manual/introduction/getting_started/#drawing-the-box","text":"Finally, we can issue the draw call that draws our box: RenderPassDesc desc; desc.color_attachments[0] = ColorAttachment(back_buffer, LoadOp::clear, StoreOp::store, Float4U(0.0f)); desc.depth_stencil_attachment = DepthStencilAttachment(depth_tex, false, LoadOp::clear, StoreOp::store, 1.0f); cmdbuf->begin_render_pass(desc); cmdbuf->set_graphics_pipeline_layout(playout); cmdbuf->set_graphics_pipeline_state(pso); cmdbuf->set_graphics_descriptor_set(0, desc_set); auto sz = vb->get_desc().size; cmdbuf->set_vertex_buffers(0, {VertexBufferView(vb, 0, sz, sizeof(Vertex))}); sz = ib->get_desc().size; cmdbuf->set_index_buffer(IndexBufferView(ib, 0, sz, Format::r32_uint)); cmdbuf->set_scissor_rect(RectI(0, 0, (i32)window_sz.x, (i32)window_sz.y)); cmdbuf->set_viewport(Viewport(0.0f, 0.0f, (f32)window_sz.x, (f32)window_sz.y, 0.0f, 1.0f)); cmdbuf->draw_indexed(36, 0, 0); cmdbuf->end_render_pass(); The first thing to do is to begin a render pass that attaches one set of color attachments and/or the depth stencil attachment to the graphic pipeline, these textures are bound to the pipeline during the current render pass and cannot be changed, while all other settings (like shader input layout object, pipeline state object, descriptor sets, etc) can be changed within the same render pass. The render pass begins with ICommandBuffer::begin_render_pass . In the render pass, we set up all pipeline settings, and bind all resources required for the current draw call, then calls ICommandBuffer::draw_indexed to issue the draw call based on the current settings. Then we should close the render pass by calling ICommandBuffer::end_render_pass . We won't go detail about the pipeline setup for this draw call, they should be familiar to you if you have been using other graphics API before. For further explanations, please consult the documentations for the RHI module. Before we can submit our command buffer, we need to insert another resource barrier to transfer our back buffer into TextureStateFlag::present state. This is required for one back buffer to be successfully presented. cmdbuf->resource_barrier({}, { TextureBarrier(back_buffer, SubresourceIndex(0, 0), TextureStateFlag::automatic, TextureStateFlag::present) }); Finally, we submit our command buffer, waiting for its completion, and resets the command buffer for next frame: luexp(cmdbuf->submit({}, {}, true)); cmdbuf->wait(); luexp(cmdbuf->reset());","title":"Drawing the box"},{"location":"manual/introduction/getting_started/#presenting-the-render-result","text":"The last thing we need to do is to present our rendering result to the window. This is done by calling ISwapChain::present : luexp(swap_chain->present()); This concludes the DemoApp::update function. Build and run DemoApp , if everything goes correctly, you will see a textured rotating box in the screen: Congratulations! If you have followed every step of this article correctly, you should have a first impression of graphic programming using Luna SDK. If anything goes wrong, you can download the source code archive from the beginning of this article and compare it with your code.","title":"Presenting the render result"},{"location":"manual/rhi/","text":"RHI Overview RHI (rendering hardware interface) is a abstraction layer of the underlying graphics devices and graphics API. By using RHI, the user can write render codes in a platform-agnostic way. Interfaces of RHI are designed targeting modern graphics APIs, so the application can unleash the full perfomance of modern graphics hardwares by using asynchronous computing, manual synchronization, overlapped memory allocation and other features.","title":"RHI"},{"location":"manual/rhi/#rhi-overview","text":"RHI (rendering hardware interface) is a abstraction layer of the underlying graphics devices and graphics API. By using RHI, the user can write render codes in a platform-agnostic way. Interfaces of RHI are designed targeting modern graphics APIs, so the application can unleash the full perfomance of modern graphics hardwares by using asynchronous computing, manual synchronization, overlapped memory allocation and other features.","title":"RHI Overview"},{"location":"manual/rhi/command_queues_and_command_buffers/","text":"Command Queues and Command Buffers RHI employs a concurrent command recording and submission model, such model reduces CPU and GPU overhead by allowing multiple CPU threads and GPU engines work concurrently as much as possible, but such model also requires the user to pay more attention on how to record, submit and synchronize GPU commands. In paticular, by using the concurrent command recording and submission model, the user should pay attention to the following things: How to distribute command recording work to multiple CPU threads. How to submit commands recorded by multiple threads to GPU. How to determine whether commands submitted to GPU have been finished. How to synchronize commands submitted to different GPU queues, so they are executed in correct order. Command Queues Commands queues are FIFO (first-in-first-out) queues used by the application to submit commands to GPU. The appliaction can submit commands to one specific queue, which pushes such commands to the back of the queue; GPU engine will pop commands from the front of the queue, and executes such commands in the order they are submitted to the queue. One device may have one or multiple command queues. Command queues are initialized when creating the device, and can be used for submitting commands right after the device is created. Command queues have three types: graphics , compute and copy : * Graphics command queues can accept graphics, compute and copy commands. * Compute command queues can accept compute and copy commands. * Copy command queues accepts only copy commands. Every device has at least one graphics command queue that accepts all kinds of commands, some GPUs may have additional compute and copy engine that can run compute and copy commands concurrently with graphics commands. On such devices, the user can submit compute and copy commands to dedicated compute and copy queues to reduce graphics command queue workload and improve perfomance. The user can call IDevice::get_num_command_queues to fetch the number of command queues present on the device, then call IDevice::get_command_queue_desc(command_queue_index) to fetch a description of each command queue. On other APIs of RHI, the user can use the same index passed to IDevice::get_command_queue_desc(command_queue_index) to identify the specific command queue. Command Buffers Command buffers are device-allocated memory that are used to store commands recorded by the application. The application does not push commands to the queue directly, instead, it records commands into command buffers, then submits command buffers to the command queue. By using command buffers, the application can use multiple threads to record multiple command buffers synchronously, then submits them in the main thread to improve performance. To create a command buffer, call IDevice::new_command_buffer(command_queue_index) . One command buffer is bound to one specific command queue, which shall be passed when the command buffer is created. This binding cannot be changed after the command buffer is created. One command queue can create multiple command buffers, each command buffer can only be accessed by one thread at one time, but different command buffers can be accessed by different threads concurrently. One command buffer have two states: recording state and execution state . When one command buffer is created, it is in recording state. When one command buffer is in recording state, it is accessible by the application, and the application can record commands to the command buffer. After the application finishes recording commands, it can call ICommandBuffer::submit(wait_fences, signal_fences, allow_host_waiting) to submit the command buffer to the command queue, and transfers the command buffer to execution state. When one command buffer is in execution state, it is accessible by GPU, but inaccessible by the application. The application can call ICommandBuffer::reset() to reset the command buffer back to recording state, this call will clear all commands and states recorded in the command buffer, so the application must ensure that GPU is not accessing the command buffer when ICommandBuffer::reset() is called. After the application submits the command buffer, GPU will pop the command buffer from the command queue and execute commands in the command buffer. As we said before, the user must wait for GPU to finish accessing commands in the command buffer before she can reset the command buffer. To wait for command buffers being completed by GPU, the user can set allow_host_waiting to true when submitting the command buffer, then call ICommandBuffer::wait() to block the current thread until the command buffer exectuion is completed, or call ICommandBuffer::try_wait() to check whether the command buffer exectuion is completed in a non-blocking way. Command buffers pushed to the same queue are guaranteed to be executed in their submission order, so if the user needs to submit multiple command buffers to the same queue, she only needs to wait for the last command buffer to be finished, and can then safely reset all command buffers submitted. The following diagram shows the state transition of one command buffer. Multi-queues Synchronization Command buffers pushed to the same queue are guaranteed to be executed in their submission order. However, command buffers pushed to different queues are executed out of order, since they can run concurrently on multiple GPU engines. If such command buffers have execution dependencies, the user must synchronize these command buffers' execution explicitly. The command buffer execution synchronization is achieved using fence objects, represented by IFence . Fence objects are created using IDevice::new_fence() . One fence have two states: signaled and unsignaled. One fence is unsignaled when it is created. When the user submits one command buffer by calling ICommandBuffer::submit(wait_fences, signal_fences, allow_host_waiting) , she can specify one set of wait fences and another set of signal fences. Before one command buffer gets executed, the device will wait for all fences in wait_fences to be in signaled state, then the device will reset all fences in wait_fences to unsignaled state and starts executing the command buffer. After one command buffer is finished, the device will set all fences in signal_fences to signaled state, so that other command buffers waiting for the fences can start executing. One signal operation can happen before or after one wait operation, but waits and signals to one fence object must occur in one-by-one pair, that is to say, every two wait operations must have one signal operation in between, and every two signal operations must have one wait operation in between.","title":"Command Queues and Command Buffers"},{"location":"manual/rhi/command_queues_and_command_buffers/#command-queues-and-command-buffers","text":"RHI employs a concurrent command recording and submission model, such model reduces CPU and GPU overhead by allowing multiple CPU threads and GPU engines work concurrently as much as possible, but such model also requires the user to pay more attention on how to record, submit and synchronize GPU commands. In paticular, by using the concurrent command recording and submission model, the user should pay attention to the following things: How to distribute command recording work to multiple CPU threads. How to submit commands recorded by multiple threads to GPU. How to determine whether commands submitted to GPU have been finished. How to synchronize commands submitted to different GPU queues, so they are executed in correct order.","title":"Command Queues and Command Buffers"},{"location":"manual/rhi/command_queues_and_command_buffers/#command-queues","text":"Commands queues are FIFO (first-in-first-out) queues used by the application to submit commands to GPU. The appliaction can submit commands to one specific queue, which pushes such commands to the back of the queue; GPU engine will pop commands from the front of the queue, and executes such commands in the order they are submitted to the queue. One device may have one or multiple command queues. Command queues are initialized when creating the device, and can be used for submitting commands right after the device is created. Command queues have three types: graphics , compute and copy : * Graphics command queues can accept graphics, compute and copy commands. * Compute command queues can accept compute and copy commands. * Copy command queues accepts only copy commands. Every device has at least one graphics command queue that accepts all kinds of commands, some GPUs may have additional compute and copy engine that can run compute and copy commands concurrently with graphics commands. On such devices, the user can submit compute and copy commands to dedicated compute and copy queues to reduce graphics command queue workload and improve perfomance. The user can call IDevice::get_num_command_queues to fetch the number of command queues present on the device, then call IDevice::get_command_queue_desc(command_queue_index) to fetch a description of each command queue. On other APIs of RHI, the user can use the same index passed to IDevice::get_command_queue_desc(command_queue_index) to identify the specific command queue.","title":"Command Queues"},{"location":"manual/rhi/command_queues_and_command_buffers/#command-buffers","text":"Command buffers are device-allocated memory that are used to store commands recorded by the application. The application does not push commands to the queue directly, instead, it records commands into command buffers, then submits command buffers to the command queue. By using command buffers, the application can use multiple threads to record multiple command buffers synchronously, then submits them in the main thread to improve performance. To create a command buffer, call IDevice::new_command_buffer(command_queue_index) . One command buffer is bound to one specific command queue, which shall be passed when the command buffer is created. This binding cannot be changed after the command buffer is created. One command queue can create multiple command buffers, each command buffer can only be accessed by one thread at one time, but different command buffers can be accessed by different threads concurrently. One command buffer have two states: recording state and execution state . When one command buffer is created, it is in recording state. When one command buffer is in recording state, it is accessible by the application, and the application can record commands to the command buffer. After the application finishes recording commands, it can call ICommandBuffer::submit(wait_fences, signal_fences, allow_host_waiting) to submit the command buffer to the command queue, and transfers the command buffer to execution state. When one command buffer is in execution state, it is accessible by GPU, but inaccessible by the application. The application can call ICommandBuffer::reset() to reset the command buffer back to recording state, this call will clear all commands and states recorded in the command buffer, so the application must ensure that GPU is not accessing the command buffer when ICommandBuffer::reset() is called. After the application submits the command buffer, GPU will pop the command buffer from the command queue and execute commands in the command buffer. As we said before, the user must wait for GPU to finish accessing commands in the command buffer before she can reset the command buffer. To wait for command buffers being completed by GPU, the user can set allow_host_waiting to true when submitting the command buffer, then call ICommandBuffer::wait() to block the current thread until the command buffer exectuion is completed, or call ICommandBuffer::try_wait() to check whether the command buffer exectuion is completed in a non-blocking way. Command buffers pushed to the same queue are guaranteed to be executed in their submission order, so if the user needs to submit multiple command buffers to the same queue, she only needs to wait for the last command buffer to be finished, and can then safely reset all command buffers submitted. The following diagram shows the state transition of one command buffer.","title":"Command Buffers"},{"location":"manual/rhi/command_queues_and_command_buffers/#multi-queues-synchronization","text":"Command buffers pushed to the same queue are guaranteed to be executed in their submission order. However, command buffers pushed to different queues are executed out of order, since they can run concurrently on multiple GPU engines. If such command buffers have execution dependencies, the user must synchronize these command buffers' execution explicitly. The command buffer execution synchronization is achieved using fence objects, represented by IFence . Fence objects are created using IDevice::new_fence() . One fence have two states: signaled and unsignaled. One fence is unsignaled when it is created. When the user submits one command buffer by calling ICommandBuffer::submit(wait_fences, signal_fences, allow_host_waiting) , she can specify one set of wait fences and another set of signal fences. Before one command buffer gets executed, the device will wait for all fences in wait_fences to be in signaled state, then the device will reset all fences in wait_fences to unsignaled state and starts executing the command buffer. After one command buffer is finished, the device will set all fences in signal_fences to signaled state, so that other command buffers waiting for the fences can start executing. One signal operation can happen before or after one wait operation, but waits and signals to one fence object must occur in one-by-one pair, that is to say, every two wait operations must have one signal operation in between, and every two signal operations must have one wait operation in between.","title":"Multi-queues Synchronization"},{"location":"manual/rhi/devices/","text":"Devices A graphics device ( IDevice ) is an virtual representation of one graphics subsystem on the platform. Some platforms have only one graphics subsystem, while others have more. For example: Desktop and laptop PCs usually have both integrated GPUs and dedicated graphics cards, so they will have two graphics subsystem listed. But this is not always the case, for example, Apple computers with Apple Silicon processors can only have one graphics subsystem. Mobile devices (iOS, Andorid) has only one graphics subsystem that represents the GPU integrated in their processor. We use the term adapter to refer one graphics subsystem on the platform. The user can choose which adapter to use for the application, and creates one IDevice for that adapter. To determine which adapter to use for creating devices, the user can firstly call get_num_adapters to get the number of adapters available on the platform, and then call get_adapter_desc to get a detailed description of one specific adapter. After the user have decided which adapter to use, she can call new_device to create a new device from that adapter. Fetching the main device The main device is the system-preferred device that is created during module initialization, and can be fetched by calling get_main_device . The module stores the reference to the main device so that every time get_main_device is called, the same device reference will be returned. If the user needs only one device (which is true for most applications), she can call get_main_device to fetch the main device directly rather than creating devices manually. Calls to get_main_device are efficient and can be used wherever you want to fetch the main device. Device objects Most objects of RHI is device objects , such objects are attached to one specific device and cannot be used by other devices. Device objects inherit from IDeviceChild , which provides get_device function that can fetch the owner device of the object.","title":"Devices"},{"location":"manual/rhi/devices/#devices","text":"A graphics device ( IDevice ) is an virtual representation of one graphics subsystem on the platform. Some platforms have only one graphics subsystem, while others have more. For example: Desktop and laptop PCs usually have both integrated GPUs and dedicated graphics cards, so they will have two graphics subsystem listed. But this is not always the case, for example, Apple computers with Apple Silicon processors can only have one graphics subsystem. Mobile devices (iOS, Andorid) has only one graphics subsystem that represents the GPU integrated in their processor. We use the term adapter to refer one graphics subsystem on the platform. The user can choose which adapter to use for the application, and creates one IDevice for that adapter. To determine which adapter to use for creating devices, the user can firstly call get_num_adapters to get the number of adapters available on the platform, and then call get_adapter_desc to get a detailed description of one specific adapter. After the user have decided which adapter to use, she can call new_device to create a new device from that adapter.","title":"Devices"},{"location":"manual/rhi/devices/#fetching-the-main-device","text":"The main device is the system-preferred device that is created during module initialization, and can be fetched by calling get_main_device . The module stores the reference to the main device so that every time get_main_device is called, the same device reference will be returned. If the user needs only one device (which is true for most applications), she can call get_main_device to fetch the main device directly rather than creating devices manually. Calls to get_main_device are efficient and can be used wherever you want to fetch the main device.","title":"Fetching the main device"},{"location":"manual/rhi/devices/#device-objects","text":"Most objects of RHI is device objects , such objects are attached to one specific device and cannot be used by other devices. Device objects inherit from IDeviceChild , which provides get_device function that can fetch the owner device of the object.","title":"Device objects"},{"location":"manual/rhi/pipeline_configuration/","text":"Pipeline Configuration Pipelines are sequences of stages that are performed on graphics hardware to perform a certain task, like rendering or computing. In RHI, we have two kinds of pipeline: graphics pipeline and compute pipeline . The following diagram shows these two kinds of pipelines: Most pipeline configurations are stored in pipeline state objects (PSO) , represented by IPipelineState . The graphics and compute pipeline state objects share the same interface type, but are created using different functions: IDevice::new_graphics_pipeline_state(desc) and IDevice::new_compute_pipeline_state(desc) . Besides pipeline state objects, some pipeline configurations are encoded in command buffers directly (like viewport sizes, scissor rect sizes, blend factors, etc.) and can be set by corresponding command buffer functions. Graphics pipeline Graphics pipeline are used to perform render tasks, with draws primitives (points, lines, triangles) to texture attachments. One graphics pipeline has the following stages: Input Assmbler , which reads data form vertex buffers and optionally index buffer to build a list of vertices to be processed. Vertex Shader , which is a programmable function that will be called on every vertex to process the vertex data. Rasterizer , which performs primitive rasterizing to generate pixels from geometries. The vertex shader outputs will be rasterized to every pixel as pixel shader inputs using linear interpolation. Pixel Shader , which is a programmable function that will be called on every generated pixel to compute the final color that will be drawn to destination attachments. Depth Stencil Testing , which performs depth tests and stencil tests to discard pixels if they do not pass such tests. This stage also updates the depth stencil attachment value if depth and/or stencil write is enabled. Color Blending , which performs blending between the existing data on color attachments and the new color outputted by pixel shader, then writes the blend result to color attachments. Most configurations are done by filling GraphicsPipelineStateDesc descriptor, then call IDevice::new_graphics_pipeline_state(desc) with the descriptor to create a graphics pipeline state object. When recording render commands, call ICommandBuffer::set_graphics_pipeline_state(pso) to bind the pipeline state object to the pipeline, then all configurations in the pipeline state object will apply to succeeding draw commands until another PSO is bind, or until the render pass is ended. Input assembler Input assembler reads the vertex buffers and index buffer to generate vertices that will be processed on succeeding stages. Input assembers are configured by the input_layout property of GraphicsPipelineStateDesc , which includes input bindings configuration ( InputBindingDesc ) and input attributes configuration ( InputAttributeDesc ). Input bindings describe vertex buffers that are attached to the pipeline, including the binding slot of the vertex buffer, the size of elements in the vertex buffer, and the input rate of the vertex buffer (per vertex or per instance). The user should specify one input binding for every vertex buffer bound to the pipeline. Input attributes describe vertex attributes, including the format of the attribute, the semantic name and semantic index of the attribute, the location of the attribute, the binding slot of the vertex buffer that provides the attribute, and the byte offset of the attribute from the beginning of the element. The following diagram shows one comprehensive input assembler setup, where we provide vertices data using one vertex buffer, and provide instance data using two vertex buffers to draw the geometry multiple times using different color and transform information: Vertex shader Vertex shaders are user-defined functions that are called on every vertex outputted from input assembler. One vertex shader must have a four-component vector output attribute with SV_POSITION semantics that will be used as the vertex position for succeeding stages. The outputted vertex position is interpreted in normalized device coordinates (NDC), as shown below. If the fourth component ( w ) of the outputted vertex position is not 1.0 , the system divides each component of the vertex position with w to normalize it internally. Note that the depth value starts from 0.0 , not -1.0. Rasterizer Rasterizer generates pixels that will be used by pixel shaders from vertices outputted from vertex shaders. A traditional implementation of rasterizer performs the following tasks in order: Primitive generation: Generates primitives (points, lines or triangles that will be drawn) from vertices stream based on the primitive topology settings of the pipeline state (configured by GraphicsPipelineStateDesc::primitive_topology ). Covering test: Performs covering test for every pixel position against every primitive to see if the pixel is covered by the primitive. If MSAA is enabled, the covering test will be performed on every sub-pixel instead of every pixel. Pixel list generation: For every primitive, generate a list of pixels that are covered by the primitive. If MSAA is enabled, one pixel will be included in the list if any of its sub-pixels is covered by the primitive. Depth bias: If depth bias is used, offsetting depth values for primitives. Attribute interpolation: For every primitive, fill pixel shader input data for every pixel in the list by linear interpolating attributes outputted from the vertex shader. Rasterizers are configured by the rasterizer_state property of GraphicsPipelineStateDesc , which has the following properties: fill_mode : if the primitive type is triangle, controls the full mode of the rasterizer. Possible options include: wireframe : only pixels close to the border of the triangle will pass covering test. solid : all pixels in the triangle will pass covering test. cull_mode : if the primitive type is triangle, controls the cull mode of the rasterizer. Possible options include: front : cull out pixels in the front face of the triangle. back : cull out pixels in the back face of the triangle. none : do nothing. The front face and back face of one triangle is determined by the winding order of three triangle vertices in NDC (looking from -Z to +Z) and front_counter_clockwise property of RasterizerDesc . 1. front_counter_clockwise : If this is true , the rasterizer will regard one triangle as front-facing if its three vertices are wound in counter clockwise order; if this is false , the rasterizer will regard one triangle as front-facing if its three vertices are wound in clockwise order. 1. depth_clip_enable : If this is true , the rasterizer will discard pixels whose depth value ( z component of position after divided by w ) goes beyond ; if this is false , the rasterizer will clamp the depth value of pixel to 1.0 if it is greater than 1.0 , and retain the coverage value, which may cause depth test produce incorrect results. 1. depth_bias , slope_scaled_depth_bias and depth_bias_clamp are used to compute one depth bias value that will be added to the original depth value in depth bias step. The depth bias value is computed as: bias(depth) = clamp(C_{b} * E + C_{s} * slope(depth), -C_{clamp}, C_{clamp}) where: depth is the original depth of the pixel. C_{b} is depth_bias converted to f32 . E is a small number that represents the minimum representable value > 0 in the depth stencil attachment format converted to f32 : If the depth stencil attachment is in a normalized format ( unorm ), E = 2^{-n} , where n is the number of precision bits of the attachment format, for example, 16 for d16_unorm . If the depth stencil attachment is in a floating-point format ( float ), E = 2^{e-n} , where e=log_2(max(depth)) is the exponent of the maximum original depth value of the input primitive, and n is the number of bits in the floating-point mantissa, for example, 23 for d32_float . C_{s} is slope_scaled_depth_bias . slope(depth) is the slope of the depth value at pixel position, usually computed as max(ddx(depth), ddy(depth)) . ddx(depth) and ddy(depth) is the horizontal and vertical slopes of the depth value at the pixel position. C_{clamp} is depth_bias_clamp . Note that different platforms may implement depth bias using slightly different formula and precision, so the user should not expect a exact bias number between different platforms and graphics API. Viewports and scissor rects Viewports defines viewport transformation , which transforms positions in NDC to screen coordinates. Every viewport defines six properties: top_left_x , top_left_y , width , height , min_depth and max_depth . 1. top_left_x and top_left_y defines the position, in pixels, of the top-left point of the viewport relative to the top-left corner of the frame buffer. 1. width and height defines the size, in pixels, of the viewport. 1. min_depth and max_depth defines the valid depth value of outputted vertex position in NDC. Both value must in range [ 0.0 , 1.0 ], but min_depth can be equal to or greater than max_depth . Any pixel whose depth value go beyond this range will be clamped to the range. The viewport transformation is performed using the following formulas: X_{screen} = X_{top\\_left} + (P_x + 1.0) / 2.0 * width Y_{screen} = Y_{top\\_left} + (-P_y + 1.0) / 2.0 * height Z_{screen} = min_depth + P_z * (max_depth - min_depth) where: 1. P is the vertex position in NDC. 1. X_{screen} and Y_{screen}& are the screen-space position of the vertex in pixels, relative to the top-left corder of the frame buffer. 1. Z_{screen}$ is the depth value written to the depth buffer. After viewport transformation, scissor culling will be performed to discard pixels that go outside of the scissor rect. The scissor rect is defined by one RectI structure, while has the following components: 1. offset_x : The X offset, in pixels, of the scissor rect relative to the top-left corner of the frame buffer. 1. offset_y : The Y offset, in pixels, of the scissor rect relative to the top-left corner of the frame buffer. 1. width : The width, in pixels, of the scissor rect. 1. height : The height, in pixels, of the scissor rect. Viewports and scissor rects are set dynamically in command recording by ICommandBuffer::set_viewport(viewport) and ICommandBuffer::set_scissor_rect(rect) . The user may also set multiple viewports and scissor rects for one draw call by calling ICommandBuffer::set_viewports(viewports) and ICommandBuffer::set_scissor_rects(rects) , in such case, the viewport array and scissor rect array must have the same size so that every viewport will have one corresponding scissor rect. Every primitive generated by the rasterizer can only be sent to one viewport, the user can use SV_ViewportArrayIndex ( uint ) vertex shader output semantics to select which viewport to use. All vertices in the same primitive should choose the same viewport, or the behavior is not defined. If SV_ViewportArrayIndex is not specified, the first viewport and scissor rect will be used. Pixel shader Pixel shaders (or fragment shaders in some graphic APIs) are user-defined functions that are called on every pixel outputted from rasterizer whose coverage value is greater than zero. One pixel shader must have one output attribute with SV_COLOR{N} semantic for every color attachment of the render pass with correct type regarding to the format of the corresponding color attachment. Attribute values outputted from the vertex shader will be interpolated into every pixel and used as input attribute value of pixel shaders. Depth stencil testing Depth stencil testing stage performs depth and stencil tests on pixels outputted from the pixel shader and discards pixels that do not pass such tests, one pixel will be written to the attachment only if it passes both depth and stencil test. The depth test is usually used to ensure that pixels near the camera will not be covered by pixels far from the camera if they are rastered to the same screen position, even if the closer pixel is drawn first. Depth stencil testing stage is configured by depth_stencil_state property of GraphicsPipelineStateDesc , which has the following properties: depth_test_enable : Whether to enable the depth test. If depth test is disabled, all pixels will pass the depth test. This must be set to false if depth stencil attachment is not specified. depth_write_enable : Whether to write pixel depth value to the depth buffer if the pixel passes both depth and stencil test. This must be set to false if depth stencil attachment is not specified. depth_func : The depth test function. stencil_enable : Whether to enable the stencil test. If stencil test is disabled, all pixels will pass the stencil test. stencil_read_mask : The read mask that will be bitwise-AND combined with the value read from stencil buffer and the value of the pixel before they are used for stencil test. stencil_write_mask : The write mask specifying which bits of the value in the stencil buffer will be overwritten by the new pixel's stencil value. front_face and back_face are two stencil operation descriptors that allows the user to specify the stencil operation for front face and back face independently. The stencil operation descriptor has the following properties: stencil_func : The stencil test function. stencil_fail_op : The operation to perform on stencil buffer if the pixel fails to pass the stencil test. stencil_pass_op : The operation to perform on stencil buffer if the pixel passes the stencil test. stencil_depth_fail_op : The operation to perform on stencil buffer if the pixel passes the stencil test, but fails to pass the depth test. The depth stencil test can be represented by the following presudo C++ code: bool depth_test_pass = true; auto pixel = read_pixel_shader_pixel_data(); // depth test if (depth_test_enable) { f32 exist_depth = read_depth_from_depth_buffer(); depth_test_pass = depth_func(pixel.depth, exist_depth); } // stencil test bool stencil_test_pass = true; u8 stencil_value; u8 stencil_write_value; if (stencil_enable) { stencil_value = read_stencil_from_stencil_buffer(); u8 stencil_ref = get_stencil_ref(); // Set by ICommandBuffer::set_stencil_ref. bool is_front_face = is_pixel_front_face(pixel); if(is_front_face) { stencil_test_pass = front_face.stencil_func(stencil_ref & stencil_read_mask, stencil_value & stencil_read_mask); if(stencil_test_pass == true) { if(depth_test_pass == true) { stencil_write_value = front_face.stencil_pass_op(stencil_value, stencil_ref); } else { stencil_write_value = front_face.stencil_depth_fail_op(stencil_value, stencil_ref); } } else { stencil_write_value = front_face.stencil_fail_op(stencil_value, stencil_ref); } } else { stencil_test_pass = back_face.stencil_func(stencil_ref & stencil_read_mask, stencil_value & stencil_read_mask); if(stencil_test_pass == true) { if(depth_test_pass == true) { stencil_write_value = back_face.stencil_pass_op(stencil_value, stencil_ref); } else { stencil_write_value = back_face.stencil_depth_fail_op(stencil_value, stencil_ref); } } else { stencil_write_value = back_face.stencil_fail_op(stencil_value, stencil_ref); } } } // discard pixel if failed to pass the depth stencil test. if(depth_test_pass == false || stencil_test_pass == false) { discard(pixel); } else { if(depth_write_enable) { write_depth_to_depth_buffer(pixel.depth); } } // update stencil buffer. This will be performed even if the pixel is discarded. if(stencil_enable) { // only modify bits specified by the write mask. write_stencil_to_stencil_buffer((stencil_write_value & stencil_write_mask) | (stencil_value & ~stencil_write_mask)); } Color blending Color blending stage performs color blending between pixel colors outputted from pixel shader and pixel colors on the color attachment, and writes the blending result to the color attachment. Color blending stage is configured by blend_state for GraphicsPipelineStateDesc , which has the following properties: 1. attachments : Specify the color blending settings for every color attachment. Every attachment blend setting is described by AttachmentBlendDesc , which has the following properties: 1. blend_enable : Whether to enable blending for this attachment. Disabling blending behaves the same as setting blend_op_color to add and setting the source and destination blending factor for both color and alpha components to 1.0 and 0.0. 1. src_blend_color : The blend factor for source color components (RGB). 1. dst_blend_color : The blend factor for destination color components (RGB). 1. blend_op_color : The blend operation for color components (RGB). 1. src_blend_alpha : The blend factor for the source alpha component (A). 1. dst_blend_alpha : The blend factor for the destination alpha component (A). 1. blend_op_alpha : The blend operation for the alpha component (A). 1. render_target_write_mask : Specify which color channels (RGBA) are written to the color attachment texture. 1. independent_blend_enable : If this is false , then all color attachments should use the same color blending settings specified by the first element of attachments array. If this is true , then each color attachment uses dedicated color blending setting specified by the corresponding elements of attachments array. Set this to false may improve performance on some platforms. 1. alpha_to_coverage_enable : On MSAA pipelines, if this is true , alpha to coverage feature is enabled. See \"Multisample anti-aliasing\" section for details about coverage mask. This must be false on non-MSAA pipelines. The final written color for every color attachment is computed using the following equation: C_{final} = (C_{src})\\Delta_{color}(C_{dst}) A_{final} = (A_{src})\\Delta_{alpha}(A_{dst}) where: 1. C_{src} is the blend factor specified by src_blend_color . 1. C_{dst} is the blend factor specified by dst_blend_color . 1. \\Delta_{color} is the blend operation specified by blend_op_color . 1. A_{src} is the blend factor specified by src_blend_alpha . 1. A_{dst} is the blend factor specified by dst_blend_alpha . 1. \\Delta_{alpha} is the blend operation specified by blend_op_alpha . Multisample anti-aliasing Multisample anti-aliasing (MSAA) is a hardware-accelerated anti-aliasing technique that relieve geometry aliasing artifacts. When MSAA is enabled, the render pipeline generates sample_count sub-pixels for every pixel, and performs rasterization, depth stencil test and color blending on every sub-pixel instead of every pixel. The pixel shader, however, is invoked only once for every pixel, and all sub-pixels in that pixel get the same output value from pixel shader. To enable MSAA for one render pipeline, performs the following steps: 1. Use color and depth attachments with sample_count of TextureDesc greater than 1 . 1. Set sample_count of GraphicsPipelineStateDesc to a value greater than 1 . 1. Set sample_count of RenderPassDesc to a value greater than 1 . The sample count number must be equal for TextureDesc , GraphicsPipelineStateDesc and RenderPassDesc used in one MSAA draw. Coverage mask For every pixel in every primitive pixel list, the render pipeline generates a coverage mask that records the coverage result of every sub-pixel of that pixel. Every sub-pixel in one pixel takes one bit of the coverage mask, and that bit will be set to 1 if the sub-pixel passes coverage test and depth stencil test, and 0 otherwise. If alpha to coverage is enabled, the render pipeline will generate another coverage mask based on the alpha value of the first shader output color. The coverage mask generation algorithm is platform-specific, but should unset all bit if alpha is 0.0, set all bits if alpha is 1.0, and set a number of bits proportionally to the value of the floating-point input. That coverage mask will be bitwise-AND combined with the original coverage mask to compute the final coverage mask. The final coverage mask is used in color blending to determine which sub-pixels should be written back to the color and depth stencil buffer. ## Compute pipeline Compute pipelines are used to perform arbitrary compute tasks, which is somethings referred as general-purpose GPU (GPGPU) programming. The compute pipeline only includes one stage: the compute shader stage, which runs user-defined compute tasks. Compute pipelines configurations are done by filling ComputePipelineStateDesc descriptor, then call IDevice::new_compute_pipeline_state(desc) with the descriptor to create a compute pipeline state object. When recording compute commands, call ICommandBuffer::set_compute_pipeline_state(pso) to bind the pipeline state object to the pipeline, then all configurations in the pipeline state object will apply to succeeding dispatch commands until another PSO is bind, or until the render pass is ended. ## Shaders Shaders are user-defined functions that can be invoked by GPU to perform certain tasks. In LunaSDK, we have the following shaders: Vertex shader, set by GraphicsPipelineStateDesc::vs . Pixel shader, set by GraphicsPipelineStateDesc::ps . Compute shader, set by ComputePipelineStateDesc::cs . All shaders are specified by providing shader binary data to the pipeline state descriptor when creating the pipeline state. The shader binary data has different formats in different backends: Direct3D 12 accepts DXBC (produced by D3DCompile or fxc ) or DXIL (produced by dxc ) shader binary code. Vulkan accepts SPIR-V shader binary code produced by glslc or dxc . Metal is a little bit complicated. Since some settings (like the entry point of the shader) are not recorded in the shader code, but in application side, we need to append additional parameters to the shader data. Metal accepts a JSON string that indicates one object with the following properties: source (String): The MSL shader source code. entry_point (String): The name of the entry point function of the shader. numthreads (Array of integer): For compute shaders, specify the number of threads per thread group. Currently, Metal shaders are compiled during the pipeline object creation process.","title":"Pipeline Configuration"},{"location":"manual/rhi/pipeline_configuration/#pipeline-configuration","text":"Pipelines are sequences of stages that are performed on graphics hardware to perform a certain task, like rendering or computing. In RHI, we have two kinds of pipeline: graphics pipeline and compute pipeline . The following diagram shows these two kinds of pipelines: Most pipeline configurations are stored in pipeline state objects (PSO) , represented by IPipelineState . The graphics and compute pipeline state objects share the same interface type, but are created using different functions: IDevice::new_graphics_pipeline_state(desc) and IDevice::new_compute_pipeline_state(desc) . Besides pipeline state objects, some pipeline configurations are encoded in command buffers directly (like viewport sizes, scissor rect sizes, blend factors, etc.) and can be set by corresponding command buffer functions.","title":"Pipeline Configuration"},{"location":"manual/rhi/pipeline_configuration/#graphics-pipeline","text":"Graphics pipeline are used to perform render tasks, with draws primitives (points, lines, triangles) to texture attachments. One graphics pipeline has the following stages: Input Assmbler , which reads data form vertex buffers and optionally index buffer to build a list of vertices to be processed. Vertex Shader , which is a programmable function that will be called on every vertex to process the vertex data. Rasterizer , which performs primitive rasterizing to generate pixels from geometries. The vertex shader outputs will be rasterized to every pixel as pixel shader inputs using linear interpolation. Pixel Shader , which is a programmable function that will be called on every generated pixel to compute the final color that will be drawn to destination attachments. Depth Stencil Testing , which performs depth tests and stencil tests to discard pixels if they do not pass such tests. This stage also updates the depth stencil attachment value if depth and/or stencil write is enabled. Color Blending , which performs blending between the existing data on color attachments and the new color outputted by pixel shader, then writes the blend result to color attachments. Most configurations are done by filling GraphicsPipelineStateDesc descriptor, then call IDevice::new_graphics_pipeline_state(desc) with the descriptor to create a graphics pipeline state object. When recording render commands, call ICommandBuffer::set_graphics_pipeline_state(pso) to bind the pipeline state object to the pipeline, then all configurations in the pipeline state object will apply to succeeding draw commands until another PSO is bind, or until the render pass is ended.","title":"Graphics pipeline"},{"location":"manual/rhi/pipeline_configuration/#input-assembler","text":"Input assembler reads the vertex buffers and index buffer to generate vertices that will be processed on succeeding stages. Input assembers are configured by the input_layout property of GraphicsPipelineStateDesc , which includes input bindings configuration ( InputBindingDesc ) and input attributes configuration ( InputAttributeDesc ). Input bindings describe vertex buffers that are attached to the pipeline, including the binding slot of the vertex buffer, the size of elements in the vertex buffer, and the input rate of the vertex buffer (per vertex or per instance). The user should specify one input binding for every vertex buffer bound to the pipeline. Input attributes describe vertex attributes, including the format of the attribute, the semantic name and semantic index of the attribute, the location of the attribute, the binding slot of the vertex buffer that provides the attribute, and the byte offset of the attribute from the beginning of the element. The following diagram shows one comprehensive input assembler setup, where we provide vertices data using one vertex buffer, and provide instance data using two vertex buffers to draw the geometry multiple times using different color and transform information:","title":"Input assembler"},{"location":"manual/rhi/pipeline_configuration/#vertex-shader","text":"Vertex shaders are user-defined functions that are called on every vertex outputted from input assembler. One vertex shader must have a four-component vector output attribute with SV_POSITION semantics that will be used as the vertex position for succeeding stages. The outputted vertex position is interpreted in normalized device coordinates (NDC), as shown below. If the fourth component ( w ) of the outputted vertex position is not 1.0 , the system divides each component of the vertex position with w to normalize it internally. Note that the depth value starts from 0.0 , not -1.0.","title":"Vertex shader"},{"location":"manual/rhi/pipeline_configuration/#rasterizer","text":"Rasterizer generates pixels that will be used by pixel shaders from vertices outputted from vertex shaders. A traditional implementation of rasterizer performs the following tasks in order: Primitive generation: Generates primitives (points, lines or triangles that will be drawn) from vertices stream based on the primitive topology settings of the pipeline state (configured by GraphicsPipelineStateDesc::primitive_topology ). Covering test: Performs covering test for every pixel position against every primitive to see if the pixel is covered by the primitive. If MSAA is enabled, the covering test will be performed on every sub-pixel instead of every pixel. Pixel list generation: For every primitive, generate a list of pixels that are covered by the primitive. If MSAA is enabled, one pixel will be included in the list if any of its sub-pixels is covered by the primitive. Depth bias: If depth bias is used, offsetting depth values for primitives. Attribute interpolation: For every primitive, fill pixel shader input data for every pixel in the list by linear interpolating attributes outputted from the vertex shader. Rasterizers are configured by the rasterizer_state property of GraphicsPipelineStateDesc , which has the following properties: fill_mode : if the primitive type is triangle, controls the full mode of the rasterizer. Possible options include: wireframe : only pixels close to the border of the triangle will pass covering test. solid : all pixels in the triangle will pass covering test. cull_mode : if the primitive type is triangle, controls the cull mode of the rasterizer. Possible options include: front : cull out pixels in the front face of the triangle. back : cull out pixels in the back face of the triangle. none : do nothing. The front face and back face of one triangle is determined by the winding order of three triangle vertices in NDC (looking from -Z to +Z) and front_counter_clockwise property of RasterizerDesc . 1. front_counter_clockwise : If this is true , the rasterizer will regard one triangle as front-facing if its three vertices are wound in counter clockwise order; if this is false , the rasterizer will regard one triangle as front-facing if its three vertices are wound in clockwise order. 1. depth_clip_enable : If this is true , the rasterizer will discard pixels whose depth value ( z component of position after divided by w ) goes beyond ; if this is false , the rasterizer will clamp the depth value of pixel to 1.0 if it is greater than 1.0 , and retain the coverage value, which may cause depth test produce incorrect results. 1. depth_bias , slope_scaled_depth_bias and depth_bias_clamp are used to compute one depth bias value that will be added to the original depth value in depth bias step. The depth bias value is computed as: bias(depth) = clamp(C_{b} * E + C_{s} * slope(depth), -C_{clamp}, C_{clamp}) where: depth is the original depth of the pixel. C_{b} is depth_bias converted to f32 . E is a small number that represents the minimum representable value > 0 in the depth stencil attachment format converted to f32 : If the depth stencil attachment is in a normalized format ( unorm ), E = 2^{-n} , where n is the number of precision bits of the attachment format, for example, 16 for d16_unorm . If the depth stencil attachment is in a floating-point format ( float ), E = 2^{e-n} , where e=log_2(max(depth)) is the exponent of the maximum original depth value of the input primitive, and n is the number of bits in the floating-point mantissa, for example, 23 for d32_float . C_{s} is slope_scaled_depth_bias . slope(depth) is the slope of the depth value at pixel position, usually computed as max(ddx(depth), ddy(depth)) . ddx(depth) and ddy(depth) is the horizontal and vertical slopes of the depth value at the pixel position. C_{clamp} is depth_bias_clamp . Note that different platforms may implement depth bias using slightly different formula and precision, so the user should not expect a exact bias number between different platforms and graphics API.","title":"Rasterizer"},{"location":"manual/rhi/pipeline_configuration/#viewports-and-scissor-rects","text":"Viewports defines viewport transformation , which transforms positions in NDC to screen coordinates. Every viewport defines six properties: top_left_x , top_left_y , width , height , min_depth and max_depth . 1. top_left_x and top_left_y defines the position, in pixels, of the top-left point of the viewport relative to the top-left corner of the frame buffer. 1. width and height defines the size, in pixels, of the viewport. 1. min_depth and max_depth defines the valid depth value of outputted vertex position in NDC. Both value must in range [ 0.0 , 1.0 ], but min_depth can be equal to or greater than max_depth . Any pixel whose depth value go beyond this range will be clamped to the range. The viewport transformation is performed using the following formulas: X_{screen} = X_{top\\_left} + (P_x + 1.0) / 2.0 * width Y_{screen} = Y_{top\\_left} + (-P_y + 1.0) / 2.0 * height Z_{screen} = min_depth + P_z * (max_depth - min_depth) where: 1. P is the vertex position in NDC. 1. X_{screen} and Y_{screen}& are the screen-space position of the vertex in pixels, relative to the top-left corder of the frame buffer. 1. Z_{screen}$ is the depth value written to the depth buffer. After viewport transformation, scissor culling will be performed to discard pixels that go outside of the scissor rect. The scissor rect is defined by one RectI structure, while has the following components: 1. offset_x : The X offset, in pixels, of the scissor rect relative to the top-left corner of the frame buffer. 1. offset_y : The Y offset, in pixels, of the scissor rect relative to the top-left corner of the frame buffer. 1. width : The width, in pixels, of the scissor rect. 1. height : The height, in pixels, of the scissor rect. Viewports and scissor rects are set dynamically in command recording by ICommandBuffer::set_viewport(viewport) and ICommandBuffer::set_scissor_rect(rect) . The user may also set multiple viewports and scissor rects for one draw call by calling ICommandBuffer::set_viewports(viewports) and ICommandBuffer::set_scissor_rects(rects) , in such case, the viewport array and scissor rect array must have the same size so that every viewport will have one corresponding scissor rect. Every primitive generated by the rasterizer can only be sent to one viewport, the user can use SV_ViewportArrayIndex ( uint ) vertex shader output semantics to select which viewport to use. All vertices in the same primitive should choose the same viewport, or the behavior is not defined. If SV_ViewportArrayIndex is not specified, the first viewport and scissor rect will be used.","title":"Viewports and scissor rects"},{"location":"manual/rhi/pipeline_configuration/#pixel-shader","text":"Pixel shaders (or fragment shaders in some graphic APIs) are user-defined functions that are called on every pixel outputted from rasterizer whose coverage value is greater than zero. One pixel shader must have one output attribute with SV_COLOR{N} semantic for every color attachment of the render pass with correct type regarding to the format of the corresponding color attachment. Attribute values outputted from the vertex shader will be interpolated into every pixel and used as input attribute value of pixel shaders.","title":"Pixel shader"},{"location":"manual/rhi/pipeline_configuration/#depth-stencil-testing","text":"Depth stencil testing stage performs depth and stencil tests on pixels outputted from the pixel shader and discards pixels that do not pass such tests, one pixel will be written to the attachment only if it passes both depth and stencil test. The depth test is usually used to ensure that pixels near the camera will not be covered by pixels far from the camera if they are rastered to the same screen position, even if the closer pixel is drawn first. Depth stencil testing stage is configured by depth_stencil_state property of GraphicsPipelineStateDesc , which has the following properties: depth_test_enable : Whether to enable the depth test. If depth test is disabled, all pixels will pass the depth test. This must be set to false if depth stencil attachment is not specified. depth_write_enable : Whether to write pixel depth value to the depth buffer if the pixel passes both depth and stencil test. This must be set to false if depth stencil attachment is not specified. depth_func : The depth test function. stencil_enable : Whether to enable the stencil test. If stencil test is disabled, all pixels will pass the stencil test. stencil_read_mask : The read mask that will be bitwise-AND combined with the value read from stencil buffer and the value of the pixel before they are used for stencil test. stencil_write_mask : The write mask specifying which bits of the value in the stencil buffer will be overwritten by the new pixel's stencil value. front_face and back_face are two stencil operation descriptors that allows the user to specify the stencil operation for front face and back face independently. The stencil operation descriptor has the following properties: stencil_func : The stencil test function. stencil_fail_op : The operation to perform on stencil buffer if the pixel fails to pass the stencil test. stencil_pass_op : The operation to perform on stencil buffer if the pixel passes the stencil test. stencil_depth_fail_op : The operation to perform on stencil buffer if the pixel passes the stencil test, but fails to pass the depth test. The depth stencil test can be represented by the following presudo C++ code: bool depth_test_pass = true; auto pixel = read_pixel_shader_pixel_data(); // depth test if (depth_test_enable) { f32 exist_depth = read_depth_from_depth_buffer(); depth_test_pass = depth_func(pixel.depth, exist_depth); } // stencil test bool stencil_test_pass = true; u8 stencil_value; u8 stencil_write_value; if (stencil_enable) { stencil_value = read_stencil_from_stencil_buffer(); u8 stencil_ref = get_stencil_ref(); // Set by ICommandBuffer::set_stencil_ref. bool is_front_face = is_pixel_front_face(pixel); if(is_front_face) { stencil_test_pass = front_face.stencil_func(stencil_ref & stencil_read_mask, stencil_value & stencil_read_mask); if(stencil_test_pass == true) { if(depth_test_pass == true) { stencil_write_value = front_face.stencil_pass_op(stencil_value, stencil_ref); } else { stencil_write_value = front_face.stencil_depth_fail_op(stencil_value, stencil_ref); } } else { stencil_write_value = front_face.stencil_fail_op(stencil_value, stencil_ref); } } else { stencil_test_pass = back_face.stencil_func(stencil_ref & stencil_read_mask, stencil_value & stencil_read_mask); if(stencil_test_pass == true) { if(depth_test_pass == true) { stencil_write_value = back_face.stencil_pass_op(stencil_value, stencil_ref); } else { stencil_write_value = back_face.stencil_depth_fail_op(stencil_value, stencil_ref); } } else { stencil_write_value = back_face.stencil_fail_op(stencil_value, stencil_ref); } } } // discard pixel if failed to pass the depth stencil test. if(depth_test_pass == false || stencil_test_pass == false) { discard(pixel); } else { if(depth_write_enable) { write_depth_to_depth_buffer(pixel.depth); } } // update stencil buffer. This will be performed even if the pixel is discarded. if(stencil_enable) { // only modify bits specified by the write mask. write_stencil_to_stencil_buffer((stencil_write_value & stencil_write_mask) | (stencil_value & ~stencil_write_mask)); }","title":"Depth stencil testing"},{"location":"manual/rhi/pipeline_configuration/#color-blending","text":"Color blending stage performs color blending between pixel colors outputted from pixel shader and pixel colors on the color attachment, and writes the blending result to the color attachment. Color blending stage is configured by blend_state for GraphicsPipelineStateDesc , which has the following properties: 1. attachments : Specify the color blending settings for every color attachment. Every attachment blend setting is described by AttachmentBlendDesc , which has the following properties: 1. blend_enable : Whether to enable blending for this attachment. Disabling blending behaves the same as setting blend_op_color to add and setting the source and destination blending factor for both color and alpha components to 1.0 and 0.0. 1. src_blend_color : The blend factor for source color components (RGB). 1. dst_blend_color : The blend factor for destination color components (RGB). 1. blend_op_color : The blend operation for color components (RGB). 1. src_blend_alpha : The blend factor for the source alpha component (A). 1. dst_blend_alpha : The blend factor for the destination alpha component (A). 1. blend_op_alpha : The blend operation for the alpha component (A). 1. render_target_write_mask : Specify which color channels (RGBA) are written to the color attachment texture. 1. independent_blend_enable : If this is false , then all color attachments should use the same color blending settings specified by the first element of attachments array. If this is true , then each color attachment uses dedicated color blending setting specified by the corresponding elements of attachments array. Set this to false may improve performance on some platforms. 1. alpha_to_coverage_enable : On MSAA pipelines, if this is true , alpha to coverage feature is enabled. See \"Multisample anti-aliasing\" section for details about coverage mask. This must be false on non-MSAA pipelines. The final written color for every color attachment is computed using the following equation: C_{final} = (C_{src})\\Delta_{color}(C_{dst}) A_{final} = (A_{src})\\Delta_{alpha}(A_{dst}) where: 1. C_{src} is the blend factor specified by src_blend_color . 1. C_{dst} is the blend factor specified by dst_blend_color . 1. \\Delta_{color} is the blend operation specified by blend_op_color . 1. A_{src} is the blend factor specified by src_blend_alpha . 1. A_{dst} is the blend factor specified by dst_blend_alpha . 1. \\Delta_{alpha} is the blend operation specified by blend_op_alpha .","title":"Color blending"},{"location":"manual/rhi/pipeline_configuration/#multisample-anti-aliasing","text":"Multisample anti-aliasing (MSAA) is a hardware-accelerated anti-aliasing technique that relieve geometry aliasing artifacts. When MSAA is enabled, the render pipeline generates sample_count sub-pixels for every pixel, and performs rasterization, depth stencil test and color blending on every sub-pixel instead of every pixel. The pixel shader, however, is invoked only once for every pixel, and all sub-pixels in that pixel get the same output value from pixel shader. To enable MSAA for one render pipeline, performs the following steps: 1. Use color and depth attachments with sample_count of TextureDesc greater than 1 . 1. Set sample_count of GraphicsPipelineStateDesc to a value greater than 1 . 1. Set sample_count of RenderPassDesc to a value greater than 1 . The sample count number must be equal for TextureDesc , GraphicsPipelineStateDesc and RenderPassDesc used in one MSAA draw.","title":"Multisample anti-aliasing"},{"location":"manual/rhi/pipeline_configuration/#coverage-mask","text":"For every pixel in every primitive pixel list, the render pipeline generates a coverage mask that records the coverage result of every sub-pixel of that pixel. Every sub-pixel in one pixel takes one bit of the coverage mask, and that bit will be set to 1 if the sub-pixel passes coverage test and depth stencil test, and 0 otherwise. If alpha to coverage is enabled, the render pipeline will generate another coverage mask based on the alpha value of the first shader output color. The coverage mask generation algorithm is platform-specific, but should unset all bit if alpha is 0.0, set all bits if alpha is 1.0, and set a number of bits proportionally to the value of the floating-point input. That coverage mask will be bitwise-AND combined with the original coverage mask to compute the final coverage mask. The final coverage mask is used in color blending to determine which sub-pixels should be written back to the color and depth stencil buffer. ## Compute pipeline Compute pipelines are used to perform arbitrary compute tasks, which is somethings referred as general-purpose GPU (GPGPU) programming. The compute pipeline only includes one stage: the compute shader stage, which runs user-defined compute tasks. Compute pipelines configurations are done by filling ComputePipelineStateDesc descriptor, then call IDevice::new_compute_pipeline_state(desc) with the descriptor to create a compute pipeline state object. When recording compute commands, call ICommandBuffer::set_compute_pipeline_state(pso) to bind the pipeline state object to the pipeline, then all configurations in the pipeline state object will apply to succeeding dispatch commands until another PSO is bind, or until the render pass is ended. ## Shaders Shaders are user-defined functions that can be invoked by GPU to perform certain tasks. In LunaSDK, we have the following shaders: Vertex shader, set by GraphicsPipelineStateDesc::vs . Pixel shader, set by GraphicsPipelineStateDesc::ps . Compute shader, set by ComputePipelineStateDesc::cs . All shaders are specified by providing shader binary data to the pipeline state descriptor when creating the pipeline state. The shader binary data has different formats in different backends: Direct3D 12 accepts DXBC (produced by D3DCompile or fxc ) or DXIL (produced by dxc ) shader binary code. Vulkan accepts SPIR-V shader binary code produced by glslc or dxc . Metal is a little bit complicated. Since some settings (like the entry point of the shader) are not recorded in the shader code, but in application side, we need to append additional parameters to the shader data. Metal accepts a JSON string that indicates one object with the following properties: source (String): The MSL shader source code. entry_point (String): The name of the entry point function of the shader. numthreads (Array of integer): For compute shaders, specify the number of threads per thread group. Currently, Metal shaders are compiled during the pipeline object creation process.","title":"Coverage mask"},{"location":"manual/rhi/recording_commands/","text":"Recording Commands This section describes commands that can be added to one command buffer. In RHI, we have four kinds of commands: Pass begin/end commands. Render commands, which can only be added in render passes. Compute commands, which can only be added in compute passes. Copy command, which can only be added in copy passes. The barrier command. Profile commands. Pass begin/end commands Passes are device-specific states (contexts) that is set up in order to perform a certain kind of tasks. For example, in order to draw primitives, the device need a render pass setup, so that it can prepare framebuffers, pipeline states and other states for the draw call. In RHI, we have three kinds of passes: render pass , compute pass and copy pass . All passes are opened by begin_xxx_pass , and are closed by end_xxx_pass , one command buffer can only have one open pass at one time, the user should close the last pass begin opening a new pass. Render passes are opened by ICommandBuffer::begin_render_pass(desc) , and are closed by ICommandBuffer::end_render_pass() . When beginning a new render pass, the user should provide a render pass descriptor ( RenderPassDesc ) which specifies a set of attachments and query heaps used for the render pass. Attachments are textures that are used to store the render result of the render pass, including: Color attachments: One render pass can specify up to 8 color attachments used for storing render results. Depth stencil attachments: Stores the depth stencil information of the render result and used for depth stencil testing during the draw process. Resolve attachments: If MSAA is enabled, the user can specify resolve attachments that stores the resolve result of color attachments automatically when the render pass ends. Currently, this is the only way to resolve MSAA textures. Query heaps can be used to query statistics during a render pass, including: Timestamp: Queries the GPU timestamp at the beginning and end of the render pass to measure the GPU time cost for the pass. Pipeline statistics: Queries the pipeline statistics information during the render pass, like how many time vertex shaders and pixel shaders are invoked, how many primitives are drawn, etc. Occlusion: Queries the number of pixels that pass depth/stencil test. All attachments and query heaps are bound to the render pass until ICommandBuffer::end_render_pass() is called. The user cannot change such bindings during a render pass. Compute passes are opened by ICommandBuffer::begin_compute_pass(desc) , and are closed by ICommandBuffer::end_compute_pass() . When beginning a new compute pass, the user can provide a compute pass descriptor ( ComputePassDesc ) which specifies query heaps used for the compute pass, including: Timestamp: Queries the GPU timestamp at the beginning and end of the compute pass to measure the GPU time cost for the pass. Pipeline statistics: Queries the number of compute shader invocations during the compute pass. Copy passes are opened by ICommandBuffer::begin_copy_pass(desc) , and and are closed by ICommandBuffer::end_copy_pass() . When beginning a new copy pass, the user can provide a copy pass descriptor ( CopyPassDesc ) which specifies query heaps used for the copy pass, which can query for GPU timestamps and beginning and end of the copy pass. All pipeline states must be valid only in a pass scope, when one pass is closed, all pipeline states will be invalidated and must be set again in the next pass. Such state includes: Pipeline layout objectss. Pipeline state objects. Descriptor sets. Vertex buffers and index buffers. Viewports and scissor rects. Blend factors. Stencil reference values. Render commands Render commands are commands used for rendering tasks, they can only be recorded between ICommandBuffer::begin_render_pass(desc) and ICommandBuffer::end_render_pass() . Render commands have three types: graphics pipeline setup commands, draw commands and occlusion query commands. The following commands are graphics pipeline setup commands: 1. ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) 1. ICommandBuffer::set_graphics_pipeline_state(pso) 1. ICommandBuffer::set_vertex_buffers(start_slot, views) 1. ICommandBuffer::set_index_buffer(view) 1. ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) 1. ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) 1. ICommandBuffer::set_viewport(viewport) 1. ICommandBuffer::set_viewports(viewports) 1. ICommandBuffer::set_scissor_rect(rect) 1. ICommandBuffer::set_scissor_rects(rects) 1. ICommandBuffer::set_blend_factor(blend_factor) 1. ICommandBuffer::set_stencil_ref(stencil_ref) The following commands are draw commands: 1. ICommandBuffer::draw(vertex_count, start_vertex_location) 1. ICommandBuffer::draw_indexed(index_count, start_index_location, base_vertex_location) 1. ICommandBuffer::draw_instanced(vertex_count_per_instance, instance_count, start_vertex_location, start_instance_location) 1. ICommandBuffer::draw_indexed_instanced(index_count_per_instance, instance_count, start_index_location, base_vertex_location, start_instance_location) The following commands are occlusion query commands: 1. ICommandBuffer::begin_occlusion_query(mode, index) 1. ICommandBuffer::end_occlusion_query(index) The graphics pipeline behaves like a state machine: states set by ICommandBuffer::set_xxx stays in the state until changed by another set state call. All graphics pipeline states are undefined at the beginning of one render pass, the user should set all necessary states explicitly before she issues the draw call. All states will be lost at the end of the render pass, the user should set such states again for one new render pass. When setting pipeline states, the user should following the following rules: ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) and ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) must be called after a valid graphics pipeline layout is set by ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) . The following graphics pipeline setup order is suggested: ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) ICommandBuffer::set_graphics_pipeline_state(pso) ICommandBuffer::set_vertex_buffers(start_slot, views) / ICommandBuffer::set_index_buffer(view) / ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) / ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) ICommandBuffer::set_viewport(viewport) / ICommandBuffer::set_viewports(viewports) / ICommandBuffer::set_scissor_rect(rect) / ICommandBuffer::set_scissor_rects(rects) / ICommandBuffer::set_blend_factor(blend_factor) / ICommandBuffer::set_stencil_ref(stencil_ref) Compute commands Compute commands are commands used for computing tasks, they can only be recorded between ICommandBuffer::begin_compute_pass(desc) and ICommandBuffer::end_compute_pass() . Compute commands have two types: compute pipeline setup commands and the dispatch command. The following commands are compute pipeline setup commands: ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) ICommandBuffer::set_compute_pipeline_state(pso) ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets) The dispath command is: 1. ICommandBuffer::dispatch(thread_group_count_x, thread_group_count_y, thread_group_count_z) The compute pipeline behaves like a state machine: states set by ICommandBuffer::set_xxx stays in the state until changed by another set state call. All compute pipeline states are undefined at the beginning of one compute pass, the user should set all necessary states explicitly before she dispatches the compute task. All states will be lost at the end of the compute pass, the user should set such states again for one new compute pass. When setting compute pipeline states, the user should following the following rules: ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) and ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets) must be called after a valid compute pipeline layout is set by ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) . The following compute pipeline setup order is suggested: ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) ICommandBuffer::set_compute_pipeline_state(pso) ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) / ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets) Copy commands Copy commands are commands used for coping data between resources, they can only be recorded between ICommandBuffer::begin_compute_pass(desc) and ICommandBuffer::end_compute_pass() . The following commands are copy commands: copy_resource(dst, src) copy_buffer(dst, dst_offset, src, src_offset, copy_bytes) copy_texture(dst, dst_subresource, dst_x, dst_y, dst_z, src, src_subresource, src_x, src_y, src_z, copy_width, copy_height, copy_depth) copy_buffer_to_texture(dst, dst_subresource, dst_x, dst_y, dst_z, src, src_offset, src_row_pitch, src_slice_pitch, copy_width, copy_height, copy_depth) copy_texture_to_buffer(dst, dst_offset, dst_row_pitch, dst_slice_pitch, src, src_subresource, src_x, src_y, src_z, copy_width, copy_height, copy_depth) Copy passes do not have any state. The barrier command GPU engines are a highly pipelined architecture. When executing commands in command queues, the GPU engine will run multiple commands simultaneously to ensure every pieline stage of the GPU engine is fully occupied to improve performance. The driver only guarantees that commands submitted earier will start executing earier, but there is no guarantee of the finish order of such commands. This can cause problems if commands in the same command queue have dependencies that the later command must be executed after the previous command is fully finished. In modern graphics APIs, the user must emit barrier commands explicitly to synchronize such dependencies, so that the driver will block succeeding commands from executing until the specified previous pipeline stage is finished. In LunaSDK, barriers are specified by declaring resource barriers, and are submitted by ICommandBuffer::resource_barrier(buffer_barriers, texture_barriers) . One resource barrier declares one resource, and the state of resource before and after the barrier. The resource state describes the role the resource plays when being used by one GPU engine, possible resource states for buffers and textures are described by BufferStateFlag and TextureStateFlag , including: BufferStateFlag::indirect_argument BufferStateFlag::vertex_buffer BufferStateFlag::index_buffer BufferStateFlag::uniform_buffer_vs BufferStateFlag::shader_read_vs BufferStateFlag::uniform_buffer_ps BufferStateFlag::shader_read_ps BufferStateFlag::shader_write_ps BufferStateFlag::uniform_buffer_cs BufferStateFlag::shader_read_cs BufferStateFlag::shader_write_cs BufferStateFlag::copy_dest BufferStateFlag::copy_source TextureStateFlag::shader_read_vs TextureStateFlag::shader_read_ps TextureStateFlag::shader_write_ps TextureStateFlag::color_attachment_read TextureStateFlag::color_attachment_write TextureStateFlag::depth_stencil_attachment_read TextureStateFlag::depth_stencil_attachment_write TextureStateFlag::resolve_attachment TextureStateFlag::shader_read_cs TextureStateFlag::shader_write_cs TextureStateFlag::copy_dest TextureStateFlag::copy_source TextureStateFlag::present Multiple states can be bit-OR combined so long as they are compatible to each other, for example, the resource state can be TextureStateFlag::shader_read_vs | TextureStateFlag::shader_read_ps if the texture will be read by both vertex shader and pixel shader. A resource barrier tells the driver to wait for the before pipeline stage that uses the resource to finish before allowing the after pipeline state to access the resource, this barrier also deals the cache visibility so that the after pipeline state always have the latest resource data. Multiple resource barriers can be batched and submitted in one call, which is suggested so that the driver can handle all resource barriers in one physical barrier command. When specifying resource barriers, the before state of one resource barrier for one resource must match the after state of the last resource barrier for the same resource. RHI also tracks the resource state internally, so that in most cases the user can simple specify BufferStateFlag::automatic or TextureStateFlag::automatic as the before state of one resource, which tells RHI to read the internal state recorded for the resource on the last source barrier. The resource state tracking is valid even between multiple command buffers and multiple command queues. There are some rules that must comply when using barriers: One resource can only be used by one command queue at one time. If multiple command queues need to access the same resource, they must be synchronized using fences. See \"Multi-queues Synchronization\" section of \"Command Recording and Submission\" for the usage of fences. When using one resource that is previously used by another command queue, always submit a barrier before using the resource, even if the resource state is not changed. This is because different command queues may use different internal texture layouts and may have different cache visibility for the same resource state. Command buffers submitted earier to the command queue must be executed earier than command buffers submitted later if they access the same resource because the resource state tracking system updates resources' global states when submitting command buffers, so that different submission order will cause the track system's recorded state being inconsistent with the resource's real state. For barriers submitted within a render pass, the following additional rules must be complied, according to Vulkan specifications : Buffer barriers cannot be submitted. Texture barriers can only including textures used as attachments for the render pass.","title":"Recording Commands"},{"location":"manual/rhi/recording_commands/#recording-commands","text":"This section describes commands that can be added to one command buffer. In RHI, we have four kinds of commands: Pass begin/end commands. Render commands, which can only be added in render passes. Compute commands, which can only be added in compute passes. Copy command, which can only be added in copy passes. The barrier command. Profile commands.","title":"Recording Commands"},{"location":"manual/rhi/recording_commands/#pass-beginend-commands","text":"Passes are device-specific states (contexts) that is set up in order to perform a certain kind of tasks. For example, in order to draw primitives, the device need a render pass setup, so that it can prepare framebuffers, pipeline states and other states for the draw call. In RHI, we have three kinds of passes: render pass , compute pass and copy pass . All passes are opened by begin_xxx_pass , and are closed by end_xxx_pass , one command buffer can only have one open pass at one time, the user should close the last pass begin opening a new pass. Render passes are opened by ICommandBuffer::begin_render_pass(desc) , and are closed by ICommandBuffer::end_render_pass() . When beginning a new render pass, the user should provide a render pass descriptor ( RenderPassDesc ) which specifies a set of attachments and query heaps used for the render pass. Attachments are textures that are used to store the render result of the render pass, including: Color attachments: One render pass can specify up to 8 color attachments used for storing render results. Depth stencil attachments: Stores the depth stencil information of the render result and used for depth stencil testing during the draw process. Resolve attachments: If MSAA is enabled, the user can specify resolve attachments that stores the resolve result of color attachments automatically when the render pass ends. Currently, this is the only way to resolve MSAA textures. Query heaps can be used to query statistics during a render pass, including: Timestamp: Queries the GPU timestamp at the beginning and end of the render pass to measure the GPU time cost for the pass. Pipeline statistics: Queries the pipeline statistics information during the render pass, like how many time vertex shaders and pixel shaders are invoked, how many primitives are drawn, etc. Occlusion: Queries the number of pixels that pass depth/stencil test. All attachments and query heaps are bound to the render pass until ICommandBuffer::end_render_pass() is called. The user cannot change such bindings during a render pass. Compute passes are opened by ICommandBuffer::begin_compute_pass(desc) , and are closed by ICommandBuffer::end_compute_pass() . When beginning a new compute pass, the user can provide a compute pass descriptor ( ComputePassDesc ) which specifies query heaps used for the compute pass, including: Timestamp: Queries the GPU timestamp at the beginning and end of the compute pass to measure the GPU time cost for the pass. Pipeline statistics: Queries the number of compute shader invocations during the compute pass. Copy passes are opened by ICommandBuffer::begin_copy_pass(desc) , and and are closed by ICommandBuffer::end_copy_pass() . When beginning a new copy pass, the user can provide a copy pass descriptor ( CopyPassDesc ) which specifies query heaps used for the copy pass, which can query for GPU timestamps and beginning and end of the copy pass. All pipeline states must be valid only in a pass scope, when one pass is closed, all pipeline states will be invalidated and must be set again in the next pass. Such state includes: Pipeline layout objectss. Pipeline state objects. Descriptor sets. Vertex buffers and index buffers. Viewports and scissor rects. Blend factors. Stencil reference values.","title":"Pass begin/end commands"},{"location":"manual/rhi/recording_commands/#render-commands","text":"Render commands are commands used for rendering tasks, they can only be recorded between ICommandBuffer::begin_render_pass(desc) and ICommandBuffer::end_render_pass() . Render commands have three types: graphics pipeline setup commands, draw commands and occlusion query commands. The following commands are graphics pipeline setup commands: 1. ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) 1. ICommandBuffer::set_graphics_pipeline_state(pso) 1. ICommandBuffer::set_vertex_buffers(start_slot, views) 1. ICommandBuffer::set_index_buffer(view) 1. ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) 1. ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) 1. ICommandBuffer::set_viewport(viewport) 1. ICommandBuffer::set_viewports(viewports) 1. ICommandBuffer::set_scissor_rect(rect) 1. ICommandBuffer::set_scissor_rects(rects) 1. ICommandBuffer::set_blend_factor(blend_factor) 1. ICommandBuffer::set_stencil_ref(stencil_ref) The following commands are draw commands: 1. ICommandBuffer::draw(vertex_count, start_vertex_location) 1. ICommandBuffer::draw_indexed(index_count, start_index_location, base_vertex_location) 1. ICommandBuffer::draw_instanced(vertex_count_per_instance, instance_count, start_vertex_location, start_instance_location) 1. ICommandBuffer::draw_indexed_instanced(index_count_per_instance, instance_count, start_index_location, base_vertex_location, start_instance_location) The following commands are occlusion query commands: 1. ICommandBuffer::begin_occlusion_query(mode, index) 1. ICommandBuffer::end_occlusion_query(index) The graphics pipeline behaves like a state machine: states set by ICommandBuffer::set_xxx stays in the state until changed by another set state call. All graphics pipeline states are undefined at the beginning of one render pass, the user should set all necessary states explicitly before she issues the draw call. All states will be lost at the end of the render pass, the user should set such states again for one new render pass. When setting pipeline states, the user should following the following rules: ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) and ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) must be called after a valid graphics pipeline layout is set by ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) . The following graphics pipeline setup order is suggested: ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) ICommandBuffer::set_graphics_pipeline_state(pso) ICommandBuffer::set_vertex_buffers(start_slot, views) / ICommandBuffer::set_index_buffer(view) / ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) / ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) ICommandBuffer::set_viewport(viewport) / ICommandBuffer::set_viewports(viewports) / ICommandBuffer::set_scissor_rect(rect) / ICommandBuffer::set_scissor_rects(rects) / ICommandBuffer::set_blend_factor(blend_factor) / ICommandBuffer::set_stencil_ref(stencil_ref)","title":"Render commands"},{"location":"manual/rhi/recording_commands/#compute-commands","text":"Compute commands are commands used for computing tasks, they can only be recorded between ICommandBuffer::begin_compute_pass(desc) and ICommandBuffer::end_compute_pass() . Compute commands have two types: compute pipeline setup commands and the dispatch command. The following commands are compute pipeline setup commands: ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) ICommandBuffer::set_compute_pipeline_state(pso) ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets) The dispath command is: 1. ICommandBuffer::dispatch(thread_group_count_x, thread_group_count_y, thread_group_count_z) The compute pipeline behaves like a state machine: states set by ICommandBuffer::set_xxx stays in the state until changed by another set state call. All compute pipeline states are undefined at the beginning of one compute pass, the user should set all necessary states explicitly before she dispatches the compute task. All states will be lost at the end of the compute pass, the user should set such states again for one new compute pass. When setting compute pipeline states, the user should following the following rules: ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) and ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets) must be called after a valid compute pipeline layout is set by ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) . The following compute pipeline setup order is suggested: ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) ICommandBuffer::set_compute_pipeline_state(pso) ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) / ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets)","title":"Compute commands"},{"location":"manual/rhi/recording_commands/#copy-commands","text":"Copy commands are commands used for coping data between resources, they can only be recorded between ICommandBuffer::begin_compute_pass(desc) and ICommandBuffer::end_compute_pass() . The following commands are copy commands: copy_resource(dst, src) copy_buffer(dst, dst_offset, src, src_offset, copy_bytes) copy_texture(dst, dst_subresource, dst_x, dst_y, dst_z, src, src_subresource, src_x, src_y, src_z, copy_width, copy_height, copy_depth) copy_buffer_to_texture(dst, dst_subresource, dst_x, dst_y, dst_z, src, src_offset, src_row_pitch, src_slice_pitch, copy_width, copy_height, copy_depth) copy_texture_to_buffer(dst, dst_offset, dst_row_pitch, dst_slice_pitch, src, src_subresource, src_x, src_y, src_z, copy_width, copy_height, copy_depth) Copy passes do not have any state.","title":"Copy commands"},{"location":"manual/rhi/recording_commands/#the-barrier-command","text":"GPU engines are a highly pipelined architecture. When executing commands in command queues, the GPU engine will run multiple commands simultaneously to ensure every pieline stage of the GPU engine is fully occupied to improve performance. The driver only guarantees that commands submitted earier will start executing earier, but there is no guarantee of the finish order of such commands. This can cause problems if commands in the same command queue have dependencies that the later command must be executed after the previous command is fully finished. In modern graphics APIs, the user must emit barrier commands explicitly to synchronize such dependencies, so that the driver will block succeeding commands from executing until the specified previous pipeline stage is finished. In LunaSDK, barriers are specified by declaring resource barriers, and are submitted by ICommandBuffer::resource_barrier(buffer_barriers, texture_barriers) . One resource barrier declares one resource, and the state of resource before and after the barrier. The resource state describes the role the resource plays when being used by one GPU engine, possible resource states for buffers and textures are described by BufferStateFlag and TextureStateFlag , including: BufferStateFlag::indirect_argument BufferStateFlag::vertex_buffer BufferStateFlag::index_buffer BufferStateFlag::uniform_buffer_vs BufferStateFlag::shader_read_vs BufferStateFlag::uniform_buffer_ps BufferStateFlag::shader_read_ps BufferStateFlag::shader_write_ps BufferStateFlag::uniform_buffer_cs BufferStateFlag::shader_read_cs BufferStateFlag::shader_write_cs BufferStateFlag::copy_dest BufferStateFlag::copy_source TextureStateFlag::shader_read_vs TextureStateFlag::shader_read_ps TextureStateFlag::shader_write_ps TextureStateFlag::color_attachment_read TextureStateFlag::color_attachment_write TextureStateFlag::depth_stencil_attachment_read TextureStateFlag::depth_stencil_attachment_write TextureStateFlag::resolve_attachment TextureStateFlag::shader_read_cs TextureStateFlag::shader_write_cs TextureStateFlag::copy_dest TextureStateFlag::copy_source TextureStateFlag::present Multiple states can be bit-OR combined so long as they are compatible to each other, for example, the resource state can be TextureStateFlag::shader_read_vs | TextureStateFlag::shader_read_ps if the texture will be read by both vertex shader and pixel shader. A resource barrier tells the driver to wait for the before pipeline stage that uses the resource to finish before allowing the after pipeline state to access the resource, this barrier also deals the cache visibility so that the after pipeline state always have the latest resource data. Multiple resource barriers can be batched and submitted in one call, which is suggested so that the driver can handle all resource barriers in one physical barrier command. When specifying resource barriers, the before state of one resource barrier for one resource must match the after state of the last resource barrier for the same resource. RHI also tracks the resource state internally, so that in most cases the user can simple specify BufferStateFlag::automatic or TextureStateFlag::automatic as the before state of one resource, which tells RHI to read the internal state recorded for the resource on the last source barrier. The resource state tracking is valid even between multiple command buffers and multiple command queues. There are some rules that must comply when using barriers: One resource can only be used by one command queue at one time. If multiple command queues need to access the same resource, they must be synchronized using fences. See \"Multi-queues Synchronization\" section of \"Command Recording and Submission\" for the usage of fences. When using one resource that is previously used by another command queue, always submit a barrier before using the resource, even if the resource state is not changed. This is because different command queues may use different internal texture layouts and may have different cache visibility for the same resource state. Command buffers submitted earier to the command queue must be executed earier than command buffers submitted later if they access the same resource because the resource state tracking system updates resources' global states when submitting command buffers, so that different submission order will cause the track system's recorded state being inconsistent with the resource's real state. For barriers submitted within a render pass, the following additional rules must be complied, according to Vulkan specifications : Buffer barriers cannot be submitted. Texture barriers can only including textures used as attachments for the render pass.","title":"The barrier command"},{"location":"manual/rhi/resources/","text":"Resources Resources ( IResource ) are GPU-accessible memories that stores certain data that can be used for reading, writing and sampling by GPU. Resources have two types: buffers and textures . Buffer resources can contain arbitrary binary data, and is usually used for storing parameters, geometry data, material data and so on. Texture resrouces can only contain image data of certain formats, and support hardware data sampling using samplers. Memory types Memory type defines the memory properties of the resource, like which heap to allocate the memory for the resource, and the CPU access policy of the allocated memory. In RHI, we have three memory types: local , upload and readback . The local memory type is allocated on memory that is visible only to GPU. Such memory gains maximum GPU bandwidth, but cannot be accessed by CPU. On platforms with non-uniform memory architecture (NUMA), the local memory will be allocated on video memory, which cannot be accessed by CPU; in a platform with uniform memory architecture (UMA), the local memory will be allocated on system memory. While it is technically possible for CPU to access local memory on UMA, preventing such access gives the hardware and driver more rooms for optimizing GPU access efficiency. The upload memory type is allocated on system memory that is optimized for CPU writing. GPU cannot write to this memory and GPU reading from upload memory is slow. On NUMA platfroms, reading data from upload memory from GPU requires data transmission through PCI-Express bus, which is much slower than reading data in local memory from GPU. We recommend using upload memory only for uploading data to local memory or reading the data only once per CPU write. The readback memory type is allocated on system memory that is optimized for CPU reading. GPU writing to read back memory is slow, and the only operation allowed for GPU is to copy data to the memory. On NUMA platfroms, writing data to readback memory from GPU requires data transmission through PCI-Express bus, which is a slow operation. The user should choose the suitable memory type based on the use situation. Here are some basic principles: 1. If you need to create texture resources, use local memory. If you need to upload texture data from CPU side, use upload memory to copy data to the local memory. 1. If you don't need to access resource data from CPU, use local memory. 1. If you only need to upload data from CPU side once, like setting the initial data for static vertex and index buffers, use one local memory to store the data, then use one temporary upload memory to copy data to the local memory. 1. If you need to upload data from CPU side multiple times, but the data is read by GPU only once per CPU update, use upload memory. 1. If you need to upload data from CPU side multiple times, and the data will be read by GPU multiple times per CPU update, use one local memory resource for GPU access and one upload memory resource for CPU access, and copy data between two resources when needed. 1. If you need to read resource data from CPU side, use readback memory. Buffers Buffers are memory blocks that can store arbitrary binary data. Typically, you use buffers to: 1. Set uniform parameters that can be read by shaders using uniform buffers . 1. Store mesh geometries for rendering using vertex buffers and index buffers . 1. Pass array of structures (like model transform matrices, material parameters, etc.) using structured buffers . 1. Copy data between host memory and device-local memory using upload buffers and readback buffers . 1. Record GPU-generated draw and compute commands using indirect buffers . Buffers are described by BufferDesc , and are created by IDevice::new_buffer(memory_type, desc) . When creating buffers, the user must specify the memory type of the buffer, and one BufferDesc descriptor for the buffer. Properties for one buffer includes the size of the buffer and possible usages of the buffer. If one buffer is created using upload or readback memory type, the application can fetch one pointer to the buffer memory by calling IBuffer::map , and must release the pointer when the application no longer needs access to the buffer memory by calling IBuffer::unmap . Buffer usages Buffer usages specify the possible usages of one buffer. One buffer can have multiple usages, which can be specified using a bitwise OR combination of multiple BufferUsageFlag flags. The buffer usages include: copy_source : Allows this buffer to be bound as copy source. copy_dest : Allows this buffer to be bound as copy destination. uniform_buffer : Allows this buffer to be bound to a uniform buffer view. read_buffer : Allows this buffer to be bound to a read buffer view. read_write_buffer : Allows this buffer to be bound to a read-write buffer view. vertex_buffer : Allows this buffer to be bound as a vertex buffer. index_buffer : Allows this buffer to be bound as a index buffer. indirect_buffer : Allows this buffer to be bound as a buffer providing indirect draw arguments. All possible usages for one buffer must be specified when the buffer is created, one buffer cannot be Usage patterns Buffers themselves are scheme-less (or typeless), they can store arbitrary binary data, and it is up to the user how to interpret buffer data. Here we list some typeical usage patterns for buffers. Uniform buffer Uniform buffers are used to store uniform parameters that will be passed to all shader threads, they are set by the application and is read-only in shader code. To create a uniform buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::upload and BufferUsageFlag::uniform_buffer . The device has memory alignment requires for uniform buffers, which can be fetched by IDevice::get_uniform_buffer_data_alignment() . The buffer size for one uniform buffer must satisfy the alignment requires: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> usize alignment = device->get_uniform_buffer_data_alignment(); BufferDesc desc; desc.size = align_upper(sizeof(MyUniformBuffer), alignment); desc.usages = BufferUsageFlag::uniform_buffer; desc.flags = ResourceFlag::none; luexp(buffer, device->new_buffer(MemoryType::upload, desc)); You can also pack multiple uniform buffers into one big buffer. In such case, the offset and size of each uniform buffer must also satisfy alignment requirements for uniform buffers: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> usize alignment = device->get_uniform_buffer_data_alignment(); usize size = 0; for(auto& my_buffer : my_buffers) { my_buffer.uniform_buffer_offset = size; my_buffer.uniform_buffer_size = align_upper(my_buffer.data_size, alignment); size += my_buffer.uniform_buffer_size; } BufferDesc desc; desc.size = size; desc.usages = BufferUsageFlag::uniform_buffer; desc.flags = ResourceFlag::none; lulet(buffer, device->new_buffer(MemoryType::upload, desc)); When binding multiple uniform buffers in one IBuffer to descriptor sets, use BufferViewDesc::uniform_buffer(buffer, offset, size) to create proper buffer views for uniform buffers: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> #include <Luna/RHI/DescriptorSet.hpp> Ref<IDescriptorSet> ds = get_my_descriptor_set(); Ref<IBuffer> ub = get_my_uniform_buffer(); Vector<BufferViewDesc> buffer_views; for(auto& my_buffer : my_buffers) { BufferViewDesc view = BufferViewDesc::uniform_buffer(ub, my_buffer.uniform_buffer_offset, my_buffer.uniform_buffer_size); buffer_views.push_back(view); } WriteDescriptorSet write = WriteDescriptorSet::uniform_buffer_view_array(MY_UNIFORM_BUFFER_BINDING_SLOT, 0, {buffer_views.data(), buffer_views.size()}); luexp(ds->update_descriptors({&write, 1})); Vertex buffer and index buffer Vertex buffers and index buffers store vertex data of one geometry. To create a vertex buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::local and BufferUsageFlag::vertex_buffer | BufferUsageFlag::copy_dest . To create a index buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::local and BufferUsageFlag::index_buffer | BufferUsageFlag::copy_dest . The data of vertex buffers and index buffers can be uploaded using copy_resource_data(command_buffer, copies) : #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> #include <Luna/RHI/Utility.hpp> u64 vb_size = sizeof(MyVertex) * num_vertices; u64 ib_size = sizeof(u32) * num_indices; BufferDesc desc; desc.size = vb_size; desc.usages = BufferUsageFlag::vertex_buffer | BufferUsageFlag::copy_dest; desc.flags = ResourceFlag::none; lulet(vb, device->new_buffer(MemoryType::local, desc)); desc.size = ib_size; desc.usages = BufferUsageFlag::index_buffer | BufferUsageFlag::copy_dest; lulet(ib, device->new_buffer(MemoryType::local, desc)); CopyResourceData copies[2] = { CopyResourceData::write_buffer(vb, 0, my_vertex_data, vb_size), CopyResourceData::write_buffer(ib, 0, my_index_data, ib_size) }; luexp(copy_resource_data(get_copy_command_buffer(), {copies, 2})); Vertex buffers and index buffers are described by VertexBufferView and IndexBufferView , and are bound to the pipeline directly by calling ICommandBuffer::set_vertex_buffers(start_slot, views) and ICommandBuffer::set_index_buffer(view) : #include <Luna/RHI/CommandBuffer.hpp> ICommandBuffer* cmdbuf = get_render_command_buffer(); VertexBufferView vb_view = VertexBufferView(vb, 0, sizeof(MyVertex) * num_vertices, sizeof(MyVertex)); cmdbuf->set_vertex_buffers(0, {&vb_view, 1}); IndexBufferView ib_view = IndexBufferView(ib, 0, sizeof(u32) * num_indices, Format::r32_uint); cmdbuf->set_index_buffer(ib_view); Structured buffers Structured buffers can be used to store one array of structures, enabling shader code to index (read and write) any element in the buffer. Such buffers can be useful to store large-sized array like the model-to-world matrices for all meshes, the material parameters for all materials of the same type, etc. To create a structured buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::local or MemoryType::upload , depends on your update frequency, and BufferUsageFlag::read_buffer if you only need to read the buffer data from shader code, or BufferUsageFlag::read_write_buffer if you need to read and write buffer data from shader code. #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> BufferDesc desc; desc.size = sizeof(MyBufferElement) * num_elements; desc.usages = BufferUsageFlag::read_buffer; desc.flags = ResourceFlag::none; luexp(buffer, device->new_buffer(MemoryType::upload, desc)); To bind one structured buffer to the descriptor set, use BufferViewDesc::structured_buffer(buffer, first_element, element_count, element_size) to create a view for the buffer: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> #include <Luna/RHI/DescriptorSet.hpp> Ref<IDescriptorSet> ds = get_my_descriptor_set(); Ref<IBuffer> buffer = get_my_buffer(); BufferViewDesc buffer_view = BufferViewDesc::structured_buffer(buffer, 0, num_elements, sizeof(MyBufferElement)); WriteDescriptorSet write = WriteDescriptorSet::read_buffer_view(MY_STRUCTURED_BUFFER_BINDING_SLOT, buffer_view); luexp(ds->update_descriptors({&write, 1})); Textures Textures are memory blocks that store 1D, 2D or 3D image data, and support hardware data sampling using samplers. Typically, you use textures to: 1. Store images loaded from files to use them in rendering or computing. 1. Store the render result of one render pass. 1. Store the depth information of the scene, which will be used in depth and stencil testing. 1. Store the intermediate render result in a multi-pass render pipeline. Textures are described by TextureDesc , and are created by IDevice::new_texture(memory_type, desc, optimized_clear_value) . When creating textures, the user must specify one TextureDesc descriptor for the texture. Currently, textures can only be created in local memory, so memory_type should always by MemoryType::local when creating textures. The user can also specify one optional optimized clear value for one texture, which may improve performance on some hardware when the texture is cleared using the same clear value as the specified. Texture usages Texture usages specify the possible usages of one texture. One texture can have multiple usages, which can be specified using a bitwise OR combination of multiple TextureUsageFlag flags. The texture usages include: copy_source : Allows this texture to be bound as copy source. copy_dest : Allows this texture to be bound as copy destination. read_texture : Allows this texture to be bound to a read texture view. read_write_texture : Allows this texture to be bound to a read-write texture view. color_attachment : Allows this texture to be bound as color attachment. depth_stencil_attachment : Allows this texture to be bound as depth stencil attachment. resolve_attachment : Allows this texture to be bound to a resolve attachment. cube : Allows this texture to be bound to a texture cube view. Texture types and dimensions Texture types identify the type of the texture, including: TextureType::tex1d : 1-dimensional texture, which represents a vector of pixels. TextureType::tex2d : 2-dimensional texture, which represents a 2D matrix of pixels. TextureType::tex3d : 3-dimensional texture, which represents a 3D matrix of pixels. Textures have three dimensions of sizes: width , height and depth : 1. For 1D textures, only width is available, height and depth must always be 1. 1. For 2D textures, both width and height are available, depth must always be 1. 1. For 3D textures, width, height and depth are available. Pixel format One texture also have a particular pixel format, which is identified by Format enumeration. Most formats are formed by a combination of the following three parts: 1. Number of color channels. One pixel may have one to four color channels, identified as r , g , b and a . 1. The bit width of every color channel. One pixel may have 8 to 64 bits per channel. 1. The number format of every color channel. One pixel may have the following number formats: 1. uint : unsigned integer. 1. sing : signed integer. 1. unorm : unsigned normalized integer that maps the unsigned integer to [0.0, 1.0]. For example, if every channel have 8 bits, then the value range [0, 255] is mapped to [0.0, 1.0] in shader automatically. 1. snorm : signed normalized integer that maps the signed integer to [-1.0, 1.0]. For example, if every channel have 8 bits, then the value range [-128, 127] is mapped to [-1.0, 1.0] in shader automatically. 1. float : floating-point number. For exmaple: 1. Format::rgba8_unorm represents a 4-channels pixel format, where every channel stores one 8-bit unsigned integer that will be mapped to [0.0, 1.0] in shader. 1. Format::rgba16_float represents a 4-channels pixel format, where every channel stores one 16-bit floating-point number (half-precision). 1. Format::rg32_float represents a 2-channels pixel format, where every channel stores one 32-bit floating-point number (single-precision). There are also some special formats: Formats begin with d like Format::d16_unorm , Format::d32_float , etc. are special formats used for depth stencil textures. Formats ends with _srgb are sRGB formats, the hardware will perform sRGB to linear color conversion when reading data from such formats. Some formats may reorder color channels, like Format::bgra8_unorm . Such formats are usually used for special cases like back buffers, where hardware has special requirements for the format that can be used for presenting the render results. The color channels will always be reordered to rgba implicitly when used in shaders. Some formats are compressed formats like BC, ASTC, etc. They uses pixel compression techniques to reduce texture file size and the memory consumption when being loaded. Compressed formats often has special requirements for texture dimensions sizes. For example, block compression (BC) format series only works on 2D textures, and requires the width and height of the texture being multiple of 4. Such formats will be hardware-uncompressed automatically when being sampled in shader. Mipmap Mipmapping is a computer graphics technology that reduces aliasing artifacts when the texture is sampled in a lower resolution than the texture's original resolution. Such artifacts is usually called Moir\u00e9 pattern . When mipmapping is used, textures will be stored as as a sequence of sub-textures. The original texture is the first sub-texture in the sequence (called mip level 0 ), and every succeeding sub-texture in the sequence is a coarse representation of the previous sub-texture. In particular, for the mip level N sub-texture in the sequence, we have: tex[N].width = ceil(tex[N-1].width / 2.0) tex[N].height = ceil(tex[N-1].height / 2.0) tex[N].depth = ceil(tex[N-1].depth / 2.0) The user may control the number of sub-textures in the mipmap sequence by setting mip_levels . If this is 0 , the system will generate a full mipmap chain for the texture, which repeats the half-divide process until the last sub-texture in the mipmap sequence has width, height and depth all equal to 1 . Texture array One 1D and 2D texture resource may contain multiple textures, which forms a texture array. The texture size, pixel format, usages and other properties apply to all textures in the texture array. If mipmaping is used, each texture in the texture array will have its independent mipmap chain. One texture array is bound to the pipeline as a single resource, and the user can access each texture of the texture array independently in shader code. Subresources Subresources are sub-textures that belongs to one texture resource. One texture resource may have mipmap subresources and/or array subresources, the total number of subresources one texture resource have are mip_levels * array_size . The following figure shows one 8x8 texture resource with 4 mip levels and 3 array elements, which counts to 12 subresources in total. To index one subresource, the user should pass the mip index and array index of the subresource. Every subresource in one texture can be indexed and manipulated independently. Usage patterns Here we list some typeical usage patterns for textures. Color attachments and depth stencil attachments Textures can be used as color attachments and depth stencil attachments for render passes. To create one texture used as color attachment, add TextureUsageFlag::color_attachment usage flag to texture usages. To create one texture used as depth stencil attachment, choose one depth format for the texture and add TextureUsageFlag::depth_stencil_attachment usage flag to the texture usages. Attachments usually have both mip_levels and array_size set to 1 . To bind attachments to render passes, firstly set textures in RenderPassDesc , then call ICommandBuffer::begin_render_pass(desc) with the render pass descriptor. Attachments will be bound to the render pass until ICommandBuffer::end_render_pass() is called. Static textures Static textures store data loaded from image files, such texture is usually used for texturing models in the scene. To create one static texture, firstly add TextureUsageFlag::read_texture and TextureUsageFlag::copy_dest usage flags to texture usages. mip_levels is usually set to 0 to generate a full mipmap chain for such texture. After the texture is created, use copy_resource_data(command_buffer, copies) or upload buffers to upload texture data to the mip 0 of the texture. After the texture is created, we need to generate mipmaps for the texture. This can be done by using a compute shader to downsample from a detailed mip to a coarse mip.","title":"Resources"},{"location":"manual/rhi/resources/#resources","text":"Resources ( IResource ) are GPU-accessible memories that stores certain data that can be used for reading, writing and sampling by GPU. Resources have two types: buffers and textures . Buffer resources can contain arbitrary binary data, and is usually used for storing parameters, geometry data, material data and so on. Texture resrouces can only contain image data of certain formats, and support hardware data sampling using samplers.","title":"Resources"},{"location":"manual/rhi/resources/#memory-types","text":"Memory type defines the memory properties of the resource, like which heap to allocate the memory for the resource, and the CPU access policy of the allocated memory. In RHI, we have three memory types: local , upload and readback . The local memory type is allocated on memory that is visible only to GPU. Such memory gains maximum GPU bandwidth, but cannot be accessed by CPU. On platforms with non-uniform memory architecture (NUMA), the local memory will be allocated on video memory, which cannot be accessed by CPU; in a platform with uniform memory architecture (UMA), the local memory will be allocated on system memory. While it is technically possible for CPU to access local memory on UMA, preventing such access gives the hardware and driver more rooms for optimizing GPU access efficiency. The upload memory type is allocated on system memory that is optimized for CPU writing. GPU cannot write to this memory and GPU reading from upload memory is slow. On NUMA platfroms, reading data from upload memory from GPU requires data transmission through PCI-Express bus, which is much slower than reading data in local memory from GPU. We recommend using upload memory only for uploading data to local memory or reading the data only once per CPU write. The readback memory type is allocated on system memory that is optimized for CPU reading. GPU writing to read back memory is slow, and the only operation allowed for GPU is to copy data to the memory. On NUMA platfroms, writing data to readback memory from GPU requires data transmission through PCI-Express bus, which is a slow operation. The user should choose the suitable memory type based on the use situation. Here are some basic principles: 1. If you need to create texture resources, use local memory. If you need to upload texture data from CPU side, use upload memory to copy data to the local memory. 1. If you don't need to access resource data from CPU, use local memory. 1. If you only need to upload data from CPU side once, like setting the initial data for static vertex and index buffers, use one local memory to store the data, then use one temporary upload memory to copy data to the local memory. 1. If you need to upload data from CPU side multiple times, but the data is read by GPU only once per CPU update, use upload memory. 1. If you need to upload data from CPU side multiple times, and the data will be read by GPU multiple times per CPU update, use one local memory resource for GPU access and one upload memory resource for CPU access, and copy data between two resources when needed. 1. If you need to read resource data from CPU side, use readback memory.","title":"Memory types"},{"location":"manual/rhi/resources/#buffers","text":"Buffers are memory blocks that can store arbitrary binary data. Typically, you use buffers to: 1. Set uniform parameters that can be read by shaders using uniform buffers . 1. Store mesh geometries for rendering using vertex buffers and index buffers . 1. Pass array of structures (like model transform matrices, material parameters, etc.) using structured buffers . 1. Copy data between host memory and device-local memory using upload buffers and readback buffers . 1. Record GPU-generated draw and compute commands using indirect buffers . Buffers are described by BufferDesc , and are created by IDevice::new_buffer(memory_type, desc) . When creating buffers, the user must specify the memory type of the buffer, and one BufferDesc descriptor for the buffer. Properties for one buffer includes the size of the buffer and possible usages of the buffer. If one buffer is created using upload or readback memory type, the application can fetch one pointer to the buffer memory by calling IBuffer::map , and must release the pointer when the application no longer needs access to the buffer memory by calling IBuffer::unmap .","title":"Buffers"},{"location":"manual/rhi/resources/#buffer-usages","text":"Buffer usages specify the possible usages of one buffer. One buffer can have multiple usages, which can be specified using a bitwise OR combination of multiple BufferUsageFlag flags. The buffer usages include: copy_source : Allows this buffer to be bound as copy source. copy_dest : Allows this buffer to be bound as copy destination. uniform_buffer : Allows this buffer to be bound to a uniform buffer view. read_buffer : Allows this buffer to be bound to a read buffer view. read_write_buffer : Allows this buffer to be bound to a read-write buffer view. vertex_buffer : Allows this buffer to be bound as a vertex buffer. index_buffer : Allows this buffer to be bound as a index buffer. indirect_buffer : Allows this buffer to be bound as a buffer providing indirect draw arguments. All possible usages for one buffer must be specified when the buffer is created, one buffer cannot be","title":"Buffer usages"},{"location":"manual/rhi/resources/#usage-patterns","text":"Buffers themselves are scheme-less (or typeless), they can store arbitrary binary data, and it is up to the user how to interpret buffer data. Here we list some typeical usage patterns for buffers.","title":"Usage patterns"},{"location":"manual/rhi/resources/#uniform-buffer","text":"Uniform buffers are used to store uniform parameters that will be passed to all shader threads, they are set by the application and is read-only in shader code. To create a uniform buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::upload and BufferUsageFlag::uniform_buffer . The device has memory alignment requires for uniform buffers, which can be fetched by IDevice::get_uniform_buffer_data_alignment() . The buffer size for one uniform buffer must satisfy the alignment requires: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> usize alignment = device->get_uniform_buffer_data_alignment(); BufferDesc desc; desc.size = align_upper(sizeof(MyUniformBuffer), alignment); desc.usages = BufferUsageFlag::uniform_buffer; desc.flags = ResourceFlag::none; luexp(buffer, device->new_buffer(MemoryType::upload, desc)); You can also pack multiple uniform buffers into one big buffer. In such case, the offset and size of each uniform buffer must also satisfy alignment requirements for uniform buffers: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> usize alignment = device->get_uniform_buffer_data_alignment(); usize size = 0; for(auto& my_buffer : my_buffers) { my_buffer.uniform_buffer_offset = size; my_buffer.uniform_buffer_size = align_upper(my_buffer.data_size, alignment); size += my_buffer.uniform_buffer_size; } BufferDesc desc; desc.size = size; desc.usages = BufferUsageFlag::uniform_buffer; desc.flags = ResourceFlag::none; lulet(buffer, device->new_buffer(MemoryType::upload, desc)); When binding multiple uniform buffers in one IBuffer to descriptor sets, use BufferViewDesc::uniform_buffer(buffer, offset, size) to create proper buffer views for uniform buffers: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> #include <Luna/RHI/DescriptorSet.hpp> Ref<IDescriptorSet> ds = get_my_descriptor_set(); Ref<IBuffer> ub = get_my_uniform_buffer(); Vector<BufferViewDesc> buffer_views; for(auto& my_buffer : my_buffers) { BufferViewDesc view = BufferViewDesc::uniform_buffer(ub, my_buffer.uniform_buffer_offset, my_buffer.uniform_buffer_size); buffer_views.push_back(view); } WriteDescriptorSet write = WriteDescriptorSet::uniform_buffer_view_array(MY_UNIFORM_BUFFER_BINDING_SLOT, 0, {buffer_views.data(), buffer_views.size()}); luexp(ds->update_descriptors({&write, 1}));","title":"Uniform buffer"},{"location":"manual/rhi/resources/#vertex-buffer-and-index-buffer","text":"Vertex buffers and index buffers store vertex data of one geometry. To create a vertex buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::local and BufferUsageFlag::vertex_buffer | BufferUsageFlag::copy_dest . To create a index buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::local and BufferUsageFlag::index_buffer | BufferUsageFlag::copy_dest . The data of vertex buffers and index buffers can be uploaded using copy_resource_data(command_buffer, copies) : #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> #include <Luna/RHI/Utility.hpp> u64 vb_size = sizeof(MyVertex) * num_vertices; u64 ib_size = sizeof(u32) * num_indices; BufferDesc desc; desc.size = vb_size; desc.usages = BufferUsageFlag::vertex_buffer | BufferUsageFlag::copy_dest; desc.flags = ResourceFlag::none; lulet(vb, device->new_buffer(MemoryType::local, desc)); desc.size = ib_size; desc.usages = BufferUsageFlag::index_buffer | BufferUsageFlag::copy_dest; lulet(ib, device->new_buffer(MemoryType::local, desc)); CopyResourceData copies[2] = { CopyResourceData::write_buffer(vb, 0, my_vertex_data, vb_size), CopyResourceData::write_buffer(ib, 0, my_index_data, ib_size) }; luexp(copy_resource_data(get_copy_command_buffer(), {copies, 2})); Vertex buffers and index buffers are described by VertexBufferView and IndexBufferView , and are bound to the pipeline directly by calling ICommandBuffer::set_vertex_buffers(start_slot, views) and ICommandBuffer::set_index_buffer(view) : #include <Luna/RHI/CommandBuffer.hpp> ICommandBuffer* cmdbuf = get_render_command_buffer(); VertexBufferView vb_view = VertexBufferView(vb, 0, sizeof(MyVertex) * num_vertices, sizeof(MyVertex)); cmdbuf->set_vertex_buffers(0, {&vb_view, 1}); IndexBufferView ib_view = IndexBufferView(ib, 0, sizeof(u32) * num_indices, Format::r32_uint); cmdbuf->set_index_buffer(ib_view);","title":"Vertex buffer and index buffer"},{"location":"manual/rhi/resources/#structured-buffers","text":"Structured buffers can be used to store one array of structures, enabling shader code to index (read and write) any element in the buffer. Such buffers can be useful to store large-sized array like the model-to-world matrices for all meshes, the material parameters for all materials of the same type, etc. To create a structured buffer, call IDevice::new_buffer(memory_type, desc) with MemoryType::local or MemoryType::upload , depends on your update frequency, and BufferUsageFlag::read_buffer if you only need to read the buffer data from shader code, or BufferUsageFlag::read_write_buffer if you need to read and write buffer data from shader code. #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> BufferDesc desc; desc.size = sizeof(MyBufferElement) * num_elements; desc.usages = BufferUsageFlag::read_buffer; desc.flags = ResourceFlag::none; luexp(buffer, device->new_buffer(MemoryType::upload, desc)); To bind one structured buffer to the descriptor set, use BufferViewDesc::structured_buffer(buffer, first_element, element_count, element_size) to create a view for the buffer: #include <Luna/RHI/Device.hpp> #include <Luna/RHI/Buffer.hpp> #include <Luna/RHI/DescriptorSet.hpp> Ref<IDescriptorSet> ds = get_my_descriptor_set(); Ref<IBuffer> buffer = get_my_buffer(); BufferViewDesc buffer_view = BufferViewDesc::structured_buffer(buffer, 0, num_elements, sizeof(MyBufferElement)); WriteDescriptorSet write = WriteDescriptorSet::read_buffer_view(MY_STRUCTURED_BUFFER_BINDING_SLOT, buffer_view); luexp(ds->update_descriptors({&write, 1}));","title":"Structured buffers"},{"location":"manual/rhi/resources/#textures","text":"Textures are memory blocks that store 1D, 2D or 3D image data, and support hardware data sampling using samplers. Typically, you use textures to: 1. Store images loaded from files to use them in rendering or computing. 1. Store the render result of one render pass. 1. Store the depth information of the scene, which will be used in depth and stencil testing. 1. Store the intermediate render result in a multi-pass render pipeline. Textures are described by TextureDesc , and are created by IDevice::new_texture(memory_type, desc, optimized_clear_value) . When creating textures, the user must specify one TextureDesc descriptor for the texture. Currently, textures can only be created in local memory, so memory_type should always by MemoryType::local when creating textures. The user can also specify one optional optimized clear value for one texture, which may improve performance on some hardware when the texture is cleared using the same clear value as the specified.","title":"Textures"},{"location":"manual/rhi/resources/#texture-usages","text":"Texture usages specify the possible usages of one texture. One texture can have multiple usages, which can be specified using a bitwise OR combination of multiple TextureUsageFlag flags. The texture usages include: copy_source : Allows this texture to be bound as copy source. copy_dest : Allows this texture to be bound as copy destination. read_texture : Allows this texture to be bound to a read texture view. read_write_texture : Allows this texture to be bound to a read-write texture view. color_attachment : Allows this texture to be bound as color attachment. depth_stencil_attachment : Allows this texture to be bound as depth stencil attachment. resolve_attachment : Allows this texture to be bound to a resolve attachment. cube : Allows this texture to be bound to a texture cube view.","title":"Texture usages"},{"location":"manual/rhi/resources/#texture-types-and-dimensions","text":"Texture types identify the type of the texture, including: TextureType::tex1d : 1-dimensional texture, which represents a vector of pixels. TextureType::tex2d : 2-dimensional texture, which represents a 2D matrix of pixels. TextureType::tex3d : 3-dimensional texture, which represents a 3D matrix of pixels. Textures have three dimensions of sizes: width , height and depth : 1. For 1D textures, only width is available, height and depth must always be 1. 1. For 2D textures, both width and height are available, depth must always be 1. 1. For 3D textures, width, height and depth are available.","title":"Texture types and dimensions"},{"location":"manual/rhi/resources/#pixel-format","text":"One texture also have a particular pixel format, which is identified by Format enumeration. Most formats are formed by a combination of the following three parts: 1. Number of color channels. One pixel may have one to four color channels, identified as r , g , b and a . 1. The bit width of every color channel. One pixel may have 8 to 64 bits per channel. 1. The number format of every color channel. One pixel may have the following number formats: 1. uint : unsigned integer. 1. sing : signed integer. 1. unorm : unsigned normalized integer that maps the unsigned integer to [0.0, 1.0]. For example, if every channel have 8 bits, then the value range [0, 255] is mapped to [0.0, 1.0] in shader automatically. 1. snorm : signed normalized integer that maps the signed integer to [-1.0, 1.0]. For example, if every channel have 8 bits, then the value range [-128, 127] is mapped to [-1.0, 1.0] in shader automatically. 1. float : floating-point number. For exmaple: 1. Format::rgba8_unorm represents a 4-channels pixel format, where every channel stores one 8-bit unsigned integer that will be mapped to [0.0, 1.0] in shader. 1. Format::rgba16_float represents a 4-channels pixel format, where every channel stores one 16-bit floating-point number (half-precision). 1. Format::rg32_float represents a 2-channels pixel format, where every channel stores one 32-bit floating-point number (single-precision). There are also some special formats: Formats begin with d like Format::d16_unorm , Format::d32_float , etc. are special formats used for depth stencil textures. Formats ends with _srgb are sRGB formats, the hardware will perform sRGB to linear color conversion when reading data from such formats. Some formats may reorder color channels, like Format::bgra8_unorm . Such formats are usually used for special cases like back buffers, where hardware has special requirements for the format that can be used for presenting the render results. The color channels will always be reordered to rgba implicitly when used in shaders. Some formats are compressed formats like BC, ASTC, etc. They uses pixel compression techniques to reduce texture file size and the memory consumption when being loaded. Compressed formats often has special requirements for texture dimensions sizes. For example, block compression (BC) format series only works on 2D textures, and requires the width and height of the texture being multiple of 4. Such formats will be hardware-uncompressed automatically when being sampled in shader.","title":"Pixel format"},{"location":"manual/rhi/resources/#mipmap","text":"Mipmapping is a computer graphics technology that reduces aliasing artifacts when the texture is sampled in a lower resolution than the texture's original resolution. Such artifacts is usually called Moir\u00e9 pattern . When mipmapping is used, textures will be stored as as a sequence of sub-textures. The original texture is the first sub-texture in the sequence (called mip level 0 ), and every succeeding sub-texture in the sequence is a coarse representation of the previous sub-texture. In particular, for the mip level N sub-texture in the sequence, we have: tex[N].width = ceil(tex[N-1].width / 2.0) tex[N].height = ceil(tex[N-1].height / 2.0) tex[N].depth = ceil(tex[N-1].depth / 2.0) The user may control the number of sub-textures in the mipmap sequence by setting mip_levels . If this is 0 , the system will generate a full mipmap chain for the texture, which repeats the half-divide process until the last sub-texture in the mipmap sequence has width, height and depth all equal to 1 .","title":"Mipmap"},{"location":"manual/rhi/resources/#texture-array","text":"One 1D and 2D texture resource may contain multiple textures, which forms a texture array. The texture size, pixel format, usages and other properties apply to all textures in the texture array. If mipmaping is used, each texture in the texture array will have its independent mipmap chain. One texture array is bound to the pipeline as a single resource, and the user can access each texture of the texture array independently in shader code.","title":"Texture array"},{"location":"manual/rhi/resources/#subresources","text":"Subresources are sub-textures that belongs to one texture resource. One texture resource may have mipmap subresources and/or array subresources, the total number of subresources one texture resource have are mip_levels * array_size . The following figure shows one 8x8 texture resource with 4 mip levels and 3 array elements, which counts to 12 subresources in total. To index one subresource, the user should pass the mip index and array index of the subresource. Every subresource in one texture can be indexed and manipulated independently.","title":"Subresources"},{"location":"manual/rhi/resources/#usage-patterns_1","text":"Here we list some typeical usage patterns for textures.","title":"Usage patterns"},{"location":"manual/rhi/resources/#color-attachments-and-depth-stencil-attachments","text":"Textures can be used as color attachments and depth stencil attachments for render passes. To create one texture used as color attachment, add TextureUsageFlag::color_attachment usage flag to texture usages. To create one texture used as depth stencil attachment, choose one depth format for the texture and add TextureUsageFlag::depth_stencil_attachment usage flag to the texture usages. Attachments usually have both mip_levels and array_size set to 1 . To bind attachments to render passes, firstly set textures in RenderPassDesc , then call ICommandBuffer::begin_render_pass(desc) with the render pass descriptor. Attachments will be bound to the render pass until ICommandBuffer::end_render_pass() is called.","title":"Color attachments and depth stencil attachments"},{"location":"manual/rhi/resources/#static-textures","text":"Static textures store data loaded from image files, such texture is usually used for texturing models in the scene. To create one static texture, firstly add TextureUsageFlag::read_texture and TextureUsageFlag::copy_dest usage flags to texture usages. mip_levels is usually set to 0 to generate a full mipmap chain for such texture. After the texture is created, use copy_resource_data(command_buffer, copies) or upload buffers to upload texture data to the mip 0 of the texture. After the texture is created, we need to generate mipmaps for the texture. This can be done by using a compute shader to downsample from a detailed mip to a coarse mip.","title":"Static textures"},{"location":"manual/rhi/shader_resource_binding/","text":"Shader Resource Binding Shader resources are resources that can be read/written by shader codes. Shader resources have the following types: Uniform buffer, which is a IBuffer that stores constants that can be read by shaders. Read buffer, which is a IBuffer that stores array of structures that can be read by shaders. Read write buffer, which is a IBuffer that stores array of structures that can be read and written by shaders. Read texture, which is a ITexture that can be sampled or read by shaders. Read write texture, which is a ITexture that can be sampled, read and written by shaders. Descriptor sets and descriptor set layouts Shader resources are not bound to the pipeline directly, instead, they should be bound to a descriptor set ( IDescriptorSet ) firstly, then all resources referred by one descriptor set is bound to the pipeline in one call by ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) or ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) . To create a descriptor set, the user should firstly create one descriptor set layout object ( IDescriptorSetLayout ). The descriptor set layout object describes the type and format of each descriptors in the descriptor set. In order to create one descriptor set layout object, the user should fill DescriptorSetLayoutDesc descriptor first, then call IDevice::new_descriptor_set_layout(desc) , passing the descriptor object. One DescriptorSetLayoutDesc describes several bindings, every binding describes one or an array of resources of the same type that can be accessed by shaders as one parameter entry. One binding is represented by DescriptorSetLayoutBinding , and contains the following properties: binding_slot : The binding number of this binding. Every binding should have one unique binding number. Binding numbers for bindings in the same descriptor set do not need to be continuous, but must be incremental. num_descs : The number of descriptors of this binding. The binding number range [binding_slot, binding_slot + num_descs) is occupied by this binding and cannot overlap with the binding number ranges of other bindings. type : The type of descriptors of this binding. All descriptors in the same binding must have the same type. texture_view_type : The texture view type of descriptors of this binding if type is read_texture_view or read_write_texture_view . All descriptors in the same binding must have the same texture view type. shader_visibility_flags : Specify shaders that have access to resources of this binding. After one descriptor set layout object is created, the user can use this object to create descriptor set objects by calling IDevice::new_descriptor_set(desc) . When creating descriptor set objects, the user should fill one DescriptorSetDesc descriptor object, which is basically only stores one pointer to the descriptor set layout object being used. Unbound descriptor sets In normal cases, the number of descriptors for each binding must be determined when creating descriptor set layout objects. However, if DeviceFeature::unbound_descriptor_array is supported, the number of descriptors of the last binding can be uncertain when creating the descriptor set layout. This allows the user to perform some advanced resource binding techniques, for example, allocate one big descriptor set to bind all resources that might be used in rendering, and select resources in shader code so that meshes using different materials can be rendered without switching descriptor sets, such feature is usually called bindless rendering and is crucial for implemeting GPU-driven rendering. To create one variable descriptor set layout, specify DescriptorSetLayoutFlag::variable_descriptors when creating the descriptor set layout. In such case, num_descs of the last binding specifies the maximum number of descriptors that can be allocated. When creating descriptor sets from one variable descriptor set layout, the user should set DescriptorSetDesc::num_variable_descriptors to a non-zero value, which is the real number of descriptors allocated for the last binding. When using unbound descriptor sets, the shader code does not know the real number of descriptors of the last binding, the user should ensure that the shader code does not index one descriptor that is out of real descriptor array range. Updating descriptor sets After creating descriptor sets, the user can write data to descriptors in descriptor sets. Updating descriptors in descriptor sets are done by IDescriptorSet::update_descriptors(writes) . The user may update multiple descriptors in multiple bindings in one update call, which is described by an array of WriteDescriptorSet structures passed to the update call. Every WriteDescriptorSet structure describes one continuous range of descriptors in the same DescriptorSetLayoutBinding . Based on the type of descriptors to be updated, the user should attach the descriptor array pointer to buffer_views , texture_views or samplers , and set the array size to num_descs . Buffer view descriptor For descriptors with DescriptorType::uniform_buffer_view , DescriptorType::read_buffer_view and DescriptorType::read_write_buffer_view types, buffer view descriptors ( BufferViewDesc ) are used to update descriptors' data. One buffer view descriptor can restrain shader to access only one portion of the buffer, so that multiple data sections can be packed into one buffer and viewed by different view descriptors. Uniform buffer For uniform buffers, the user should use BufferViewDesc::first_element to specify the byte offset from the beginning of the buffer data to the first byte to be used, and BufferViewDesc::element_size to specify the size of the uniform buffer data to be used. The offset and size of one uniform data must satisfy hardware alignment requirements, which can be fetched by IDevice::get_uniform_buffer_data_alignment() . The user may use BufferViewDesc::uniform_buffer(buffer, offset, size) static constructor to create one BufferViewDesc for one uniform buffer descriptor quickly. Structured buffer For read buffers and read-write buffers, the user should use BufferViewDesc::element_size to specify the size of each element in the buffer, BufferViewDesc::first_element to specify the index of the first element to be used, and BufferViewDesc::element_count to specify the number of elements to be used. The user may use BufferViewDesc::structured_buffer(buffer, first_element, element_count, element_size) static constructor to create one BufferViewDesc for one read buffer/read-write buffer descriptor quickly. Texture view descriptor For descriptors with DescriptorType::read_texture_view and DescriptorType::read_write_texture_view types, texture view descriptors ( TextureViewDesc ) are used to update descriptors' data. One texture view descriptor can restrain shader to access only a certain range of subresources of the texture, so that different subresources of one texture may be bound to the same or different pipeline using different texture views. Texture view type TextureViewDesc::type specifies the texture view type, which has the following options: Option Texture type Array Multisample Cube tex1d 1D texture No No No tex2d 2D texture No No No tex2dms 2D texture No Yes No tex3d 3D texture No No No texcube 2D texture No No Yes tex1darray 1D texture Yes No No tex2darray 2D texture Yes No No tex2dmsarray 2D texture Yes Yes No texcubearray 2D texture Yes No Yes The texture view type of one texture view must be compatible with the viewing texture. For example, you cannot bind one 2D texture with TextureViewType::tex1d texture view. If you don't know the exact texture view type to use, you can specify TextureViewType::unspecified to let the system to choose one shitable texture view type based on the binding texture and view settings. Texture view format TextureViewDesc::format tells the pipeline how to interpret data for one texture. When supported by the backend, one texture view may specify one format that is different than the native format of the binding texture, which will let the driver to reinterpret texture data when accessing textures. If format reinterpreting is not supported by the driver, the user must specify the same format for both texture and texture view. The texture view format can be Format::unknown , which tells the system to use the binding texture's native format as the texture view format. Mip and array slice TextureViewDesc::mip_slice and TextureViewDesc::mip_size specifies the mip range [mip\\_slice, mip\\_slice + mip\\_size) that will be bind to the pipeline. After specified, TextureViewDesc::mip_slice becomes the mip level 0 in shader code. TextureViewDesc::mip_size must be 1 for tex2dms and tex2dmsarray views, and views used for read-write texture descriptors. TextureViewDesc::mip_size may be U32_MAX , which tells the system to use all available mips since TextureViewDesc::mip_slice . TextureViewDesc::array_slice and TextureViewDesc::array_size specifies the array range [array\\_slice, array\\_slice + array\\_size) that will be bind to the pipeline. After specified, TextureViewDesc::array_slice becomes the first array element in shader code. TextureViewDesc::array_slice must be 0 for non-array texture views, TextureViewDesc::array_size must be: * 1 for tex1d , tex2d , tex2dms and tex3d views. * 6 for texcube views. * times of 6 for texcubearray views. TextureViewDesc::array_size may be U32_MAX , which tells the system to use all available array elements since TextureViewDesc::array_slice . Static constructors The user may use the following static constructors to declare texture views of different types quickly: * TextureViewDesc::tex1d(texture, format, mip_slice, mip_size) * TextureViewDesc::tex1darray(texture, format, mip_slice, mip_size, array_slice, array_size) * TextureViewDesc::tex2d(texture, format, mip_slice, mip_size) * TextureViewDesc::tex2darray(texture, format, mip_slice, mip_size, array_slice, array_size) * TextureViewDesc::tex2dms(texture, format) * TextureViewDesc::tex2dmsarray(texture, format, array_slice, array_size) * TextureViewDesc::tex3d(texture, format, mip_slice, mip_size) * TextureViewDesc::texcube(texture, format, mip_slice, mip_size) * TextureViewDesc::texcubearray(texture, format, mip_slice, mip_size, array_slice, array_size) Sampler descriptor For descriptors with DescriptorType::sampler type, sampler descriptors ( SamplerDesc ) are used to update descriptors' data. One sampler descriptor describes sampling configurations that shaders can use to sample textures. Pipeline layouts Pipeline layouts ( IPipelineLayout ) describes the descriptor sets binding layout for one graphics or compute pipeline. Before descriptor sets are attached to one pipeline, its pipeline layout must be set firstly by ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) or ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) . To create one pipeline layout, the user should fill one pipeline layout descriptor object ( PipelineLayoutDesc ), and pass the object to IDevice::new_pipeline_layout(desc) . When configuring PipelineLayoutDesc , the user should specify the number of descriptor sets that will be attached to the pipeline, and the descriptor set layout of every descriptor set. The user can also use PipelineLayoutFlag to control shaders and stages that can access bound resources, dening shaders and stages access to resources may improve performance on some hardwares. Binding descriptor sets Once descriptors in descriptor sets are updated, the user can bind descriptor sets to pipelines so that all resources and configurations stored in descriptor sets are used in succeeding draw or dispatch calls. Binding descriptor sets to pipelines are achieved via ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) or ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) for graphics pipelines, and ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) or ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets) for compute pipelines. Compatible pipeline layout must be set to the pipelines before binding descriptor sets. After one descriptor set is bound to one pipeline, the user cannot update descriptors in the descriptor set or bind the same descriptor set to another pipeline until the command buffer is finished executing or reset. If one pipeline have multiple descriptor sets, every descriptor set can be bound independently using dedicated binding calls, and descriptor sets bound to the pipeline stays bound until changed by another binding call, or the render or compute pass is closed.","title":"Shader Resource Binding"},{"location":"manual/rhi/shader_resource_binding/#shader-resource-binding","text":"Shader resources are resources that can be read/written by shader codes. Shader resources have the following types: Uniform buffer, which is a IBuffer that stores constants that can be read by shaders. Read buffer, which is a IBuffer that stores array of structures that can be read by shaders. Read write buffer, which is a IBuffer that stores array of structures that can be read and written by shaders. Read texture, which is a ITexture that can be sampled or read by shaders. Read write texture, which is a ITexture that can be sampled, read and written by shaders.","title":"Shader Resource Binding"},{"location":"manual/rhi/shader_resource_binding/#descriptor-sets-and-descriptor-set-layouts","text":"Shader resources are not bound to the pipeline directly, instead, they should be bound to a descriptor set ( IDescriptorSet ) firstly, then all resources referred by one descriptor set is bound to the pipeline in one call by ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) or ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) . To create a descriptor set, the user should firstly create one descriptor set layout object ( IDescriptorSetLayout ). The descriptor set layout object describes the type and format of each descriptors in the descriptor set. In order to create one descriptor set layout object, the user should fill DescriptorSetLayoutDesc descriptor first, then call IDevice::new_descriptor_set_layout(desc) , passing the descriptor object. One DescriptorSetLayoutDesc describes several bindings, every binding describes one or an array of resources of the same type that can be accessed by shaders as one parameter entry. One binding is represented by DescriptorSetLayoutBinding , and contains the following properties: binding_slot : The binding number of this binding. Every binding should have one unique binding number. Binding numbers for bindings in the same descriptor set do not need to be continuous, but must be incremental. num_descs : The number of descriptors of this binding. The binding number range [binding_slot, binding_slot + num_descs) is occupied by this binding and cannot overlap with the binding number ranges of other bindings. type : The type of descriptors of this binding. All descriptors in the same binding must have the same type. texture_view_type : The texture view type of descriptors of this binding if type is read_texture_view or read_write_texture_view . All descriptors in the same binding must have the same texture view type. shader_visibility_flags : Specify shaders that have access to resources of this binding. After one descriptor set layout object is created, the user can use this object to create descriptor set objects by calling IDevice::new_descriptor_set(desc) . When creating descriptor set objects, the user should fill one DescriptorSetDesc descriptor object, which is basically only stores one pointer to the descriptor set layout object being used.","title":"Descriptor sets and descriptor set layouts"},{"location":"manual/rhi/shader_resource_binding/#unbound-descriptor-sets","text":"In normal cases, the number of descriptors for each binding must be determined when creating descriptor set layout objects. However, if DeviceFeature::unbound_descriptor_array is supported, the number of descriptors of the last binding can be uncertain when creating the descriptor set layout. This allows the user to perform some advanced resource binding techniques, for example, allocate one big descriptor set to bind all resources that might be used in rendering, and select resources in shader code so that meshes using different materials can be rendered without switching descriptor sets, such feature is usually called bindless rendering and is crucial for implemeting GPU-driven rendering. To create one variable descriptor set layout, specify DescriptorSetLayoutFlag::variable_descriptors when creating the descriptor set layout. In such case, num_descs of the last binding specifies the maximum number of descriptors that can be allocated. When creating descriptor sets from one variable descriptor set layout, the user should set DescriptorSetDesc::num_variable_descriptors to a non-zero value, which is the real number of descriptors allocated for the last binding. When using unbound descriptor sets, the shader code does not know the real number of descriptors of the last binding, the user should ensure that the shader code does not index one descriptor that is out of real descriptor array range.","title":"Unbound descriptor sets"},{"location":"manual/rhi/shader_resource_binding/#updating-descriptor-sets","text":"After creating descriptor sets, the user can write data to descriptors in descriptor sets. Updating descriptors in descriptor sets are done by IDescriptorSet::update_descriptors(writes) . The user may update multiple descriptors in multiple bindings in one update call, which is described by an array of WriteDescriptorSet structures passed to the update call. Every WriteDescriptorSet structure describes one continuous range of descriptors in the same DescriptorSetLayoutBinding . Based on the type of descriptors to be updated, the user should attach the descriptor array pointer to buffer_views , texture_views or samplers , and set the array size to num_descs .","title":"Updating descriptor sets"},{"location":"manual/rhi/shader_resource_binding/#buffer-view-descriptor","text":"For descriptors with DescriptorType::uniform_buffer_view , DescriptorType::read_buffer_view and DescriptorType::read_write_buffer_view types, buffer view descriptors ( BufferViewDesc ) are used to update descriptors' data. One buffer view descriptor can restrain shader to access only one portion of the buffer, so that multiple data sections can be packed into one buffer and viewed by different view descriptors.","title":"Buffer view descriptor"},{"location":"manual/rhi/shader_resource_binding/#uniform-buffer","text":"For uniform buffers, the user should use BufferViewDesc::first_element to specify the byte offset from the beginning of the buffer data to the first byte to be used, and BufferViewDesc::element_size to specify the size of the uniform buffer data to be used. The offset and size of one uniform data must satisfy hardware alignment requirements, which can be fetched by IDevice::get_uniform_buffer_data_alignment() . The user may use BufferViewDesc::uniform_buffer(buffer, offset, size) static constructor to create one BufferViewDesc for one uniform buffer descriptor quickly.","title":"Uniform buffer"},{"location":"manual/rhi/shader_resource_binding/#structured-buffer","text":"For read buffers and read-write buffers, the user should use BufferViewDesc::element_size to specify the size of each element in the buffer, BufferViewDesc::first_element to specify the index of the first element to be used, and BufferViewDesc::element_count to specify the number of elements to be used. The user may use BufferViewDesc::structured_buffer(buffer, first_element, element_count, element_size) static constructor to create one BufferViewDesc for one read buffer/read-write buffer descriptor quickly.","title":"Structured buffer"},{"location":"manual/rhi/shader_resource_binding/#texture-view-descriptor","text":"For descriptors with DescriptorType::read_texture_view and DescriptorType::read_write_texture_view types, texture view descriptors ( TextureViewDesc ) are used to update descriptors' data. One texture view descriptor can restrain shader to access only a certain range of subresources of the texture, so that different subresources of one texture may be bound to the same or different pipeline using different texture views.","title":"Texture view descriptor"},{"location":"manual/rhi/shader_resource_binding/#texture-view-type","text":"TextureViewDesc::type specifies the texture view type, which has the following options: Option Texture type Array Multisample Cube tex1d 1D texture No No No tex2d 2D texture No No No tex2dms 2D texture No Yes No tex3d 3D texture No No No texcube 2D texture No No Yes tex1darray 1D texture Yes No No tex2darray 2D texture Yes No No tex2dmsarray 2D texture Yes Yes No texcubearray 2D texture Yes No Yes The texture view type of one texture view must be compatible with the viewing texture. For example, you cannot bind one 2D texture with TextureViewType::tex1d texture view. If you don't know the exact texture view type to use, you can specify TextureViewType::unspecified to let the system to choose one shitable texture view type based on the binding texture and view settings.","title":"Texture view type"},{"location":"manual/rhi/shader_resource_binding/#texture-view-format","text":"TextureViewDesc::format tells the pipeline how to interpret data for one texture. When supported by the backend, one texture view may specify one format that is different than the native format of the binding texture, which will let the driver to reinterpret texture data when accessing textures. If format reinterpreting is not supported by the driver, the user must specify the same format for both texture and texture view. The texture view format can be Format::unknown , which tells the system to use the binding texture's native format as the texture view format.","title":"Texture view format"},{"location":"manual/rhi/shader_resource_binding/#mip-and-array-slice","text":"TextureViewDesc::mip_slice and TextureViewDesc::mip_size specifies the mip range [mip\\_slice, mip\\_slice + mip\\_size) that will be bind to the pipeline. After specified, TextureViewDesc::mip_slice becomes the mip level 0 in shader code. TextureViewDesc::mip_size must be 1 for tex2dms and tex2dmsarray views, and views used for read-write texture descriptors. TextureViewDesc::mip_size may be U32_MAX , which tells the system to use all available mips since TextureViewDesc::mip_slice . TextureViewDesc::array_slice and TextureViewDesc::array_size specifies the array range [array\\_slice, array\\_slice + array\\_size) that will be bind to the pipeline. After specified, TextureViewDesc::array_slice becomes the first array element in shader code. TextureViewDesc::array_slice must be 0 for non-array texture views, TextureViewDesc::array_size must be: * 1 for tex1d , tex2d , tex2dms and tex3d views. * 6 for texcube views. * times of 6 for texcubearray views. TextureViewDesc::array_size may be U32_MAX , which tells the system to use all available array elements since TextureViewDesc::array_slice .","title":"Mip and array slice"},{"location":"manual/rhi/shader_resource_binding/#static-constructors","text":"The user may use the following static constructors to declare texture views of different types quickly: * TextureViewDesc::tex1d(texture, format, mip_slice, mip_size) * TextureViewDesc::tex1darray(texture, format, mip_slice, mip_size, array_slice, array_size) * TextureViewDesc::tex2d(texture, format, mip_slice, mip_size) * TextureViewDesc::tex2darray(texture, format, mip_slice, mip_size, array_slice, array_size) * TextureViewDesc::tex2dms(texture, format) * TextureViewDesc::tex2dmsarray(texture, format, array_slice, array_size) * TextureViewDesc::tex3d(texture, format, mip_slice, mip_size) * TextureViewDesc::texcube(texture, format, mip_slice, mip_size) * TextureViewDesc::texcubearray(texture, format, mip_slice, mip_size, array_slice, array_size)","title":"Static constructors"},{"location":"manual/rhi/shader_resource_binding/#sampler-descriptor","text":"For descriptors with DescriptorType::sampler type, sampler descriptors ( SamplerDesc ) are used to update descriptors' data. One sampler descriptor describes sampling configurations that shaders can use to sample textures.","title":"Sampler descriptor"},{"location":"manual/rhi/shader_resource_binding/#pipeline-layouts","text":"Pipeline layouts ( IPipelineLayout ) describes the descriptor sets binding layout for one graphics or compute pipeline. Before descriptor sets are attached to one pipeline, its pipeline layout must be set firstly by ICommandBuffer::set_graphics_pipeline_layout(pipeline_layout) or ICommandBuffer::set_compute_pipeline_layout(pipeline_layout) . To create one pipeline layout, the user should fill one pipeline layout descriptor object ( PipelineLayoutDesc ), and pass the object to IDevice::new_pipeline_layout(desc) . When configuring PipelineLayoutDesc , the user should specify the number of descriptor sets that will be attached to the pipeline, and the descriptor set layout of every descriptor set. The user can also use PipelineLayoutFlag to control shaders and stages that can access bound resources, dening shaders and stages access to resources may improve performance on some hardwares.","title":"Pipeline layouts"},{"location":"manual/rhi/shader_resource_binding/#binding-descriptor-sets","text":"Once descriptors in descriptor sets are updated, the user can bind descriptor sets to pipelines so that all resources and configurations stored in descriptor sets are used in succeeding draw or dispatch calls. Binding descriptor sets to pipelines are achieved via ICommandBuffer::set_graphics_descriptor_set(index, descriptor_set) or ICommandBuffer::set_graphics_descriptor_sets(start_index, descriptor_sets) for graphics pipelines, and ICommandBuffer::set_compute_descriptor_set(index, descriptor_set) or ICommandBuffer::set_compute_descriptor_sets(start_index, descriptor_sets) for compute pipelines. Compatible pipeline layout must be set to the pipelines before binding descriptor sets. After one descriptor set is bound to one pipeline, the user cannot update descriptors in the descriptor set or bind the same descriptor set to another pipeline until the command buffer is finished executing or reset. If one pipeline have multiple descriptor sets, every descriptor set can be bound independently using dedicated binding calls, and descriptor sets bound to the pipeline stays bound until changed by another binding call, or the render or compute pass is closed.","title":"Binding descriptor sets"}]}